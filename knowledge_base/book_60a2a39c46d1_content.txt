Copyright
Copyright	©	2017	by	Kevin	Mitnick
Foreword	copyright	©	2017	by	Mikko	Hypponen
Cover	design	by	Julianna	Lee
Author	photograph	by	Tolga	Katas
Cover	copyright	©	2017	by	Hachette	Book	Group,	Inc.
Hachette	Book	Group	supports	the	right	to	free	expression	and	the	value	of
copyright.	The	purpose	of	copyright	is	to	encourage	writers	and	artists	to
produce	the	creative	works	that	enrich	our	culture.
The	scanning,	uploading,	and	distribution	of	this	book	without	permission	is	a
theft	of	the	author’s	intellectual	property.	If	you	would	like	permission	to	use
material	from	the	book	(other	than	for	review	purposes),	please	contact
permissions@hbgusa.com.	Thank	you	for	your	support	of	the	author’s	rights.
Little,	Brown	and	Company
Hachette	Book	Group
1290	Avenue	of	the	Americas,	New	York,	NY	10104
littlebrown.com
twitter.com/littlebrown
facebook.com/littlebrownandcompany
First	ebook	edition:	February	2017
Little,	Brown	and	Company	is	a	division	of	Hachette	Book	Group,	Inc.	The
Little,	Brown	name	and	logo	are	trademarks	of	Hachette	Book	Group,	Inc.
The	publisher	is	not	responsible	for	websites	(or	their	content)	that	are	not
owned	by	the	publisher.

The	Hachette	Speakers	Bureau	provides	a	wide	range	of	authors	for	speaking
events.	To	find	out	more,	go	to	hachettespeakersbureau.com	or	call	(866)	376-
6591.
ISBN	978-0-316-38049-2
E3-20161223-JV-PC

Contents
Cover
Title	Page
Copyright
Dedication
Foreword	by	Mikko	Hypponen
Introduction
	|	Time	to	Disappear
Chapter	One
	|	Your	Password	Can	Be	Cracked!
Chapter	Two
	|	Who	Else	Is	Reading	Your	E-mail?
Chapter	Three
	|	Wiretapping	101
Chapter	Four
	|	If	You	Don’t	Encrypt,	You’re	Unequipped
Chapter	Five
	|	Now	You	See	Me,	Now	You	Don’t
Chapter	Six
	|	Every	Mouse	Click	You	Make,	I’ll	Be	Watching	You
Chapter	Seven
	|	Pay	Up	or	Else!
Chapter	Eight
	|	Believe	Everything,	Trust	Nothing
Chapter	Nine
	|	You	Have	No	Privacy?	Get	Over	It!
Chapter	Ten
	|	You	Can	Run	but	Not	Hide
Chapter	Eleven
	|	Hey,	KITT,	Don’t	Share	My	Location
Chapter	Twelve
	|	The	Internet	of	Surveillance
Chapter	Thirteen
	|	Things	Your	Boss	Doesn’t	Want	You	to	Know
Chapter	Fourteen
	|	Obtaining	Anonymity	Is	Hard	Work
Chapter	Fifteen
	|	The	FBI	Always	Gets	Its	Man
Chapter	Sixteen
	|	Mastering	the	Art	of	Invisibility

Acknowledgments
About	the	Authors
Books	by	Kevin	Mitnick
Notes
Newsletters

To	my	loving	mother,	Shelly
Jaffe,
and	my	grandmother	Reba
Vartanian

Foreword	by	Mikko	Hypponen
A	couple	of	months	ago
,	I	met	up	with	an	old	friend	who	I	hadn’t	seen
since	high	school.	We	went	for	a	cup	of	coffee	to	catch	up	on	what	each	of	us
had	been	doing	for	the	past	decades.	He	told	me	about	his	work	of	distributing
and	supporting	various	types	of	modern	medical	devices,	and	I	explained	how
I’ve	spent	the	last	twenty-five	years	working	with	Internet	security	and	privacy.
My	friend	let	out	a	chuckle	when	I	mentioned	online	privacy.	“That	sounds	all
fine	and	dandy,”	he	said,	“but	I’m	not	really	worried.	After	all,	I’m	not	a
criminal,	and	I’m	not	doing	anything	bad.	I	don’t	care	if	somebody	looks	at
what	I’m	doing	online.”
Listening	to	my	old	friend,	and	his	explanation	on	why	privacy	does	not
matter	to	him,	I	was	saddened.	I	was	saddened	because	I’ve	heard	these
arguments	before,	many	times.	I	hear	them	from	people	who	think	they	have
nothing	to	hide.	I	hear	them	from	people	who	think	only	criminals	need	to
protect	themselves.	I	hear	them	from	people	who	think	only	terrorists	use
encryption.	I	hear	them	from	people	who	think	we	don’t	need	to	protect	our
rights.	But	we	do	need	to	protect	our	rights.	And	privacy	does	not	just	affect
our	rights,	it	
is
	a	human	right.	In	fact,	privacy	is	recognized	as	a	fundamental
human	right	in	the	1948	United	Nations	Universal	Declaration	of	Human
Rights.
If	our	privacy	needed	protection	in	1948,	it	surely	needs	it	much	more
today.	After	all,	we	are	the	first	generation	in	human	history	that	can	be
monitored	at	such	a	precise	level.	We	can	be	monitored	digitally	throughout
our	lives.	Almost	all	of	our	communications	can	be	seen	one	way	or	another.
We	even	carry	small	tracking	devices	on	us	all	the	time—we	just	don’t	call
them	tracking	devices,	we	call	them	smartphones.

Online	monitoring	can	see	what	books	we	buy	and	what	news	articles	we
read—even	which	parts	of	the	articles	are	most	interesting	to	us.	It	can	see
where	we	travel	and	who	we	travel	with.	And	online	monitoring	knows	if	you
are	sick,	or	sad,	or	horny.	Much	of	the	monitoring	that	is	done	today	compiles
this	data	to	make	money.	Companies	that	offer	free	services	somehow	convert
those	free	services	into	billions	of	dollars	of	revenue—nicely	illustrating	just
how	valuable	it	is	to	profile	Internet	users	in	mass	scale.	However,	there’s	also
more	targeted	monitoring:	the	kind	of	monitoring	done	by	government
agencies,	domestic	or	foreign.
Digital	communication	has	made	it	possible	for	governments	to	do	bulk
surveillance.	But	it	has	also	enabled	us	to	protect	ourselves	better.	We	can
protect	ourselves	with	tools	like	encryption,	by	storing	our	data	in	safe	ways,
and	by	following	basic	principles	of	operations	security	(OPSEC).	We	just
need	a	guide	on	how	to	do	it	right.
Well,	the	guide	you	need	is	right	here	in	your	hands.	I’m	really	happy	Kevin
took	the	time	to	write	down	his	knowledge	on	the	art	of	invisibility.	After	all,
he	knows	a	thing	or	two	about	staying	invisible.	This	is	a	great	resource.	Read
it	and	use	the	knowledge	to	your	advantage.	Protect	yourself	and	protect	your
rights.
Back	at	the	cafeteria,	after	I	had	finished	coffee	with	my	old	friend,	we
parted	ways.	I	wished	him	well,	but	I	still	sometimes	think	about	his	words:	“I
don’t	care	if	somebody	looks	at	what	I’m	doing	online.”	You	might	not	have
anything	to	hide,	my	friend.	But	you	have	everything	to	protect.
Mikko	Hypponen	is	the	chief	research	officer	of	F-Secure.	He’s	the	only	living
person	who	has	spoken	at	both	DEF	CON	and	TED	conferences.

INTRODUCTION
Time	to	Disappear
Almost	two	years	to	the
	day	after	Edward	Joseph	Snowden,	a
contractor	for	Booz	Allen	Hamilton,	first	disclosed	his	cache	of	secret
material	taken	from	the	National	Security	Agency	(NSA),	HBO	comedian	John
Oliver	went	to	Times	Square	in	New	York	City	to	survey	people	at	random	for
a	segment	of	his	show	on	privacy	and	surveillance.	His	questions	were	clear.
Who	is	Edward	Snowden?	What	did	he	do?
1
In	the	interview	clips	Oliver	aired,	no	one	seemed	to	know.	Even	when
people	said	they	recalled	the	name,	they	couldn’t	say	exactly	what	Snowden	had
done	(or	why).	After	becoming	a	contractor	for	the	NSA,	Edward	Snowden
copied	thousands	of	top	secret	and	classified	documents	that	he	subsequently
gave	to	reporters	so	they	could	make	them	public	around	the	world.	Oliver
could	have	ended	his	show’s	segment	about	surveillance	on	a	depressing	note
—after	years	of	media	coverage,	no	one	in	America	really	seemed	to	care
about	domestic	spying	by	the	government—but	the	comedian	chose	another
tack.	He	flew	to	Russia,	where	Snowden	now	lives	in	exile,	for	a	one-on-one
interview.
2
The	first	question	Oliver	put	to	Snowden	in	Moscow	was:	What	did	you
hope	to	accomplish?	Snowden	answered	that	he	wanted	to	
show	the	world	what
the	NSA	was	doing—collecting	data	on	almost	everyone.	When	Oliver	showed
him	the	interviews	from	Times	Square,	in	which	one	person	after	another
professed	not	to	know	who	Snowden	was,	his	response	was,	“Well,	you	can’t
have	everyone	well	informed.”

Why	aren’t	we	more	informed	when	it	comes	to	the	privacy	issues	that
Snowden	and	others	have	raised?	Why	don’t	we	seem	to	care	that	a
government	agency	is	wiretapping	our	phone	calls,	our	e-mails,	and	even	our
text	messages?	Probably	because	the	NSA,	by	and	large,	doesn’t	directly	affect
the	lives	of	most	of	us—at	least	not	in	a	tangible	way,	as	an	intrusion	that	we
can	
feel
.
But	as	Oliver	also	discovered	in	Times	Square	that	day,	Americans	do	care
about	privacy	when	it	hits	home.	In	addition	to	asking	questions	about
Snowden,	he	asked	general	questions	about	privacy.	For	example,	when	he
asked	how	they	felt	about	a	secret	(but	made-up)	government	program	that
records	images	of	naked	people	whenever	the	images	are	sent	over	the
Internet,	the	response	among	New	Yorkers	was	also	universal—except	this
time	everyone	opposed	it,	emphatically.	One	person	even	admitted	to	having
recently	sent	such	a	photo.
Everyone	interviewed	in	the	Times	Square	segment	agreed	that	people	in
the	United	States	should	be	able	to	share	anything—even	a	photo	of	a	penis—
privately	over	the	Internet.	Which	was	Snowden’s	basic	point.
It	turns	out	that	the	fake	government	program	that	records	naked	pictures	is
less	far-fetched	than	you	might	imagine.	As	Snowden	explained	to	Oliver	in
their	interview,	because	companies	like	Google	have	servers	physically
located	all	over	the	world,	even	a	simple	message	(perhaps	including	nudity)
between	a	husband	and	wife	within	the	same	US	city	might	first	bounce	off	a
foreign	server.	Since	that	data	leaves	the	United	States,	even	for	a	nanosecond,
the	NSA	could,	thanks	to	the	Patriot	Act,	collect	and	archive	that	text	or	e-mail
(including	the	indecent	photo)	because	it	technically	entered	
the	United	States
from	a	foreign	source	at	the	moment	when	it	was	captured.	Snowden’s	point:
average	Americans	are	being	caught	up	in	a	post-9/11	dragnet	that	was	initially
designed	to	stop	foreign	terrorists	but	that	now	spies	on	practically	everyone.
You	would	think,	given	the	constant	news	about	data	breaches	and	surveillance
campaigns	by	the	government,	that	we’d	be	much	more	outraged.	You	would
think	that	given	how	fast	this	happened—in	just	a	handful	of	years—we’d	be
reeling	from	the	shock	and	marching	in	the	streets.	Actually,	the	opposite	is
true.	Many	of	us,	even	many	readers	of	this	book,	now	accept	to	at	least	some
degree	the	fact	that	everything	we	do—all	our	phone	calls,	our	texts,	our	e-
mails,	our	social	media—can	be	seen	by	others.
And	that’s	disappointing.

Perhaps	you	have	broken	no	laws.	You	live	what	you	think	is	an	average
and	quiet	life,	and	you	feel	you	are	unnoticed	among	the	crowds	of	others
online	today.	Trust	me:	even	you	are	not	invisible.	At	least	not	yet.
I	enjoy	magic,	and	some	might	argue	that	sleight	of	hand	is	necessary	for
computer	hacking.	One	popular	magic	trick	is	to	make	an	object	invisible.	The
secret,	however,	is	that	the	object	does	not	physically	disappear	or	actually
become	invisible.	The	object	always	remains	in	the	background,	behind	a
curtain,	up	a	sleeve,	in	a	pocket,	whether	we	can	see	it	or	not.
The	same	is	true	of	the	many	personal	details	about	each	and	every	one	of
us	that	are	currently	being	collected	and	stored,	often	without	our	noticing.
Most	of	us	simply	don’t	know	how	easy	it	is	for	others	to	view	these	details
about	us	or	even	where	to	look.	And	because	
we
	don’t	see	this	information,	we
might	believe	that	we	are	invisible	to	our	exes,	our	parents,	our	schools,	our
bosses,	and	even	our	governments.
The	problem	is	that	if	you	know	where	to	look,	all	that	information	is
available	to	just	about	anyone.
Whenever	I	speak	before	large	crowds—no	matter	the	size	of	the	room—I
usually	have	one	person	who	challenges	me	on	this	fact.	After	one	such	event	I
was	challenged	by	a	very	skeptical	reporter.
I	remember	we	were	seated	at	a	private	table	in	a	hotel	bar	in	a	large	US
city	when	the	reporter	said	she’d	never	been	a	victim	of	a	data	breach.	Given
her	youth,	she	said	she	had	relatively	few	assets	to	her	name,	hence	few
records.	She	never	put	personal	details	into	any	of	her	stories	or	her	personal
social	media—she	kept	it	professional.	She	considered	herself	invisible.	So	I
asked	her	for	permission	to	find	her	Social	Security	number	and	any	other
personal	details	online.	Reluctantly	she	agreed.
With	her	seated	nearby	I	logged	in	to	a	site,	one	that	is	reserved	for	private
investigators.	I	qualify	as	the	latter	through	my	work	investigating	hacking
incidents	globally.	I	already	knew	her	name,	so	I	asked	where	she	lived.	This	I
could	have	found	on	the	Internet	as	well,	on	another	site,	if	she	hadn’t	told	me.
In	a	couple	of	minutes	I	knew	her	Social	Security	number,	her	city	of	birth,
and	even	her	mother’s	maiden	name.	I	also	knew	all	the	places	she’d	ever
called	home	and	all	the	phone	numbers	she’d	ever	used.	Staring	at	the	screen,
with	a	surprised	look	on	her	face,	she	confirmed	that	all	the	information	was
more	or	less	true.
The	site	I	used	is	restricted	to	vetted	companies	or	individuals.	It	charges	a

low	fee	per	month	plus	additional	costs	for	any	information	lookups,	and	from
time	to	time	it	will	audit	me	to	find	out	whether	I	have	a	legitimate	purpose	for
conducting	a	particular	search.
But	similar	information	about	anyone	can	be	found	for	a	small	lookup	fee.
And	it’s	perfectly	legal.
Have	you	ever	filled	out	an	online	form,	submitted	information	to	a	school
or	organization	that	puts	its	information	online,	or	had	a	
legal	case	posted	to
the	Internet?	If	so,	you	have	volunteered	personal	information	to	a	third	party
that	may	do	with	the	information	what	it	pleases.	Chances	are	that	some—if	not
all—of	that	data	is	now	online	and	available	to	companies	that	make	it	their
business	to	collect	every	bit	of	personal	information	off	the	Internet.	The
Privacy	Rights	Clearinghouse	lists	more	than	130	companies	that	collect
personal	information	(whether	or	not	it’s	accurate)	about	you.
3
And	then	there’s	the	data	that	you	don’t	volunteer	online	but	that	is
nonetheless	being	harvested	by	corporations	and	governments—information
about	whom	we	e-mail,	text,	and	call;	what	we	search	for	online;	what	we	buy,
either	in	a	brick-and-mortar	or	an	online	store;	and	where	we	travel,	on	foot	or
by	car.	The	volume	of	data	collected	about	each	and	every	one	of	us	is
growing	exponentially	each	day.
You	may	think	you	don’t	need	to	worry	about	this.	Trust	me:	you	do.	I	hope
that	by	the	end	of	this	book	you	will	be	both	well-informed	and	prepared
enough	to	do	something	about	it.
The	fact	is	that	we	live	with	an	illusion	of	privacy,	and	we	probably	have	been
living	this	way	for	decades.
At	a	certain	point,	we	might	find	ourselves	uncomfortable	with	how	much
access	our	government,	our	employers,	our	bosses,	our	teachers,	and	our
parents	have	into	our	personal	lives.	But	since	that	access	has	been	gained
gradually,	since	we’ve	embraced	each	small	digital	convenience	without
resisting	its	impact	on	our	privacy,	it	becomes	increasingly	hard	to	turn	back
the	clock.	Besides,	who	among	us	wants	to	give	up	our	toys?
The	danger	of	living	within	a	digital	surveillance	state	isn’t	so	much	that	the
data	is	being	collected	(there’s	little	we	can	do	about	that)	but	
what	is	done	with
the	data
	once	it	is	collected.
Imagine	what	an	overzealous	prosecutor	could	do	with	the	large	dossier	of
raw	data	points	available	on	you,	perhaps	going	back	several	
years.	Data	today,
sometimes	collected	out	of	context,	will	live	forever.	Even	US	Supreme	Court

justice	Stephen	Breyer	agrees	that	it	is	“difficult	for	anyone	to	know,	in
advance,	just	when	a	particular	set	of	statements	might	later	appear	(to	a
prosecutor)	to	be	relevant	to	some	such	investigation.”
4
	In	other	words,	a
picture	of	you	drunk	that	someone	posted	on	Facebook	might	be	the	least	of
your	concerns.
You	may	think	you	have	nothing	to	hide,	but	do	you	know	that	for	sure?	In	a
well-argued	opinion	piece	in	
Wired,
	respected	security	researcher	Moxie
Marlinspike	points	out	that	something	as	simple	as	being	in	possession	of	a
small	lobster	is	actually	a	federal	crime	in	the	United	States.
5
	“It	doesn’t	matter
if	you	bought	it	at	a	grocery	store,	if	someone	else	gave	it	to	you,	if	it’s	dead
or	alive,	if	you	found	it	after	it	died	of	natural	causes,	or	even	if	you	killed	it
while	acting	in	self-defense.	You	can	go	to	jail	because	of	a	lobster.”
6
	The
point	here	is	there	are	many	minor,	unenforced	laws	that	you	could	be
breaking	without	knowing	it.	Except	now	there’s	a	data	trail	to	prove	it	just	a
few	taps	away,	available	to	any	person	who	wants	it.
Privacy	is	complex.	It	is	not	a	one-size-fits-all	proposition.	We	all	have
different	reasons	for	sharing	some	information	about	ourselves	freely	with
strangers	and	keeping	other	parts	of	our	lives	private.	Maybe	you	simply	don’t
want	your	significant	other	reading	your	personal	stuff.	Maybe	you	don’t	want
your	employer	to	know	about	your	private	life.	Or	maybe	you	really	do	fear
that	a	government	agency	is	spying	on	you.
These	are	very	different	scenarios,	so	no	one	recommendation	offered	here
is	going	to	fit	them	all.	Because	we	hold	complicated	and	therefore	very
different	attitudes	toward	privacy,	I’ll	guide	you	through	what’s	important—
what’s	happening	today	with	surreptitious	data	collection—and	let	you	decide
what	works	for	your	own	life.
If	anything,	this	book	will	make	you	aware	of	ways	to	be	private	within	the
digital	world	and	offer	solutions	that	you	may	or	may	not	
choose	to	adopt.
Since	privacy	is	a	personal	choice,	degrees	of	invisibility,	too,	will	vary	by
individual.
In	this	book	I’ll	make	the	case	that	each	and	every	one	of	us	is	being
watched,	at	home	and	out	in	the	world—as	you	walk	down	the	street,	sit	at	a
café,	or	drive	down	the	highway.	Your	computer,	your	phone,	your	car,	your
home	alarm	system,	even	your	refrigerator	are	all	potential	points	of	access
into	your	private	life.
The	good	news	is,	in	addition	to	scaring	you,	I’m	also	going	to	show	you

what	to	do	about	the	lack	of	privacy—a	situation	that	has	become	the	norm.
In	this	book,	you’ll	learn	how	to:
	encrypt	and	send	a	secure	e-mail
	protect	your	data	with	good	password	management
	hide	your	true	IP	address	from	places	you	visit
	obscure	your	computer	from	being	tracked
	defend	your	anonymity
	and	much	more
Now,	get	ready	to	master	the	art	of	invisibility.

CHAPTER	ONE
Your	Password	Can	Be	Cracked!
Jennifer	Lawrence	was	having	a
	rough	Labor	Day	weekend.	The
Academy	Award	winner	was	one	of	several	celebrities	who	woke	one	morning
in	2014	to	find	that	their	most	private	pictures—many	of	which	showed	them
in	the	nude—were	being	splashed	about	on	the	Internet.
Take	a	moment	to	mentally	scan	all	the	images	that	are	currently	stored	on
your	computer,	phone,	and	e-mail.	Sure,	many	of	them	are	perfectly	benign.
You’d	be	fine	with	the	whole	world	seeing	the	sunsets,	the	cute	family
snapshots,	maybe	even	the	jokey	bad-hair-day	selfie.	But	would	you	be
comfortable	sharing	each	and	every	one	of	them?	How	would	you	feel	if	they
suddenly	all	appeared	online?	Maybe	not	all	our	personal	photos	are	salacious,
but	they’re	still	records	of	private	moments.	We	should	be	able	to	decide
whether,	when,	and	how	to	share	them,	yet	with	cloud	services	the	choice	may
not	always	be	ours.
The	Jennifer	Lawrence	story	dominated	the	slow	Labor	Day	weekend	news
cycle	in	2014.	It	was	part	of	an	event	called	theFappening,	a	huge	leak	of	nude
and	nearly	nude	photographs	of	Rihanna,	Kate	Upton,	Kaley	Cuoco,	Adrianne
Curry,	and	almost	three	hundred	other	celebrities,	most	of	them	women,	whose
cell-phone	images	
had	somehow	been	remotely	accessed	and	shared.	While
some	people	were,	predictably,	interested	in	seeing	these	photos,	for	many	the
incident	was	an	unsettling	reminder	that	the	same	thing	could	have	happened	to
them.

So	how	did	someone	get	access	to	those	private	images	of	Jennifer
Lawrence	and	others?
Since	all	the	celebrities	used	iPhones,	early	speculation	centered	on	a
massive	data	breach	affecting	Apple’s	iCloud	service,	a	cloud-storage	option
for	iPhone	users.	As	your	physical	device	runs	out	of	memory,	your	photos,
new	files,	music,	and	games	are	instead	stored	on	a	server	at	Apple,	usually	for
a	small	monthly	fee.	Google	offers	a	similar	service	for	Android.
Apple,	which	almost	never	comments	in	the	media	on	security	issues,
denied	any	fault	on	their	end.	The	company	issued	a	statement	calling	the
incident	a	“very	targeted	attack	on	user	names,	passwords,	and	security
questions”	and	added	that	“none	of	the	cases	we	have	investigated	has	resulted
from	any	breach	in	any	of	Apple’s	systems	including	iCloud	or	Find	my
iPhone.”
1
The	photos	first	started	appearing	on	a	hacker	forum	well	known	for
posting	compromised	photos.
2
	Within	that	forum	you	can	find	active
discussions	of	the	digital	forensic	tools	used	for	surreptitiously	obtaining	such
photos.	Researchers,	investigators,	and	law	enforcement	use	these	tools	to
access	data	from	devices	or	the	cloud,	usually	following	a	crime.	And	of
course	the	tools	have	other	uses	as	well.
One	of	the	tools	openly	discussed	on	the	forum,	Elcomsoft	Phone	Password
Breaker,	or	EPPB,	is	intended	to	enable	law	enforcement	and	government
agencies	to	access	iCloud	accounts	and	is	sold	publicly.	It	is	just	one	of	many
tools	out	there,	but	it	appears	to	be	the	most	popular	on	the	forum.	EPPB
requires	that	users	have	the	target’s	iCloud	username	and	password
information	first.	For	people	using	this	forum,	however,	obtaining	iCloud
usernames	and	passwords	is	not	a	problem.	It	so	happened	that	over	that
holiday	weekend	in	2014,	
someone	posted	to	a	popular	online	code	repository
(Github)	a	tool	called	iBrute,	a	password-hacking	mechanism	specifically
designed	for	acquiring	iCloud	credentials	from	just	about	anyone.
Using	iBrute	and	EPPB	together,	someone	could	impersonate	a	victim	and
download	a	full	backup	of	that	victim’s	cloud-stored	iPhone	data	onto	another
device.	This	capability	is	useful	when	you	upgrade	your	phone,	for	example.	It
is	also	valuable	to	an	attacker,	who	then	can	see	everything	you’ve	ever	done
on	your	mobile	device.	This	yields	much	more	information	than	just	logging
in	to	a	victim’s	iCloud	account.
Jonathan	Zdziarski,	a	forensics	consultant	and	security	researcher,	told
Wired
	that	his	examination	of	the	leaked	photos	from	Kate	Upton,	for	example,

was	consistent	with	the	use	of	iBrute	and	EPPB.	Having	access	to	a	restored
iPhone	backup	gives	an	attacker	lots	of	personal	information	that	might	later
be	useful	for	blackmail.
3
In	October	2016,	Ryan	Collins,	a	thirty-six-year-old	from	Lancaster,
Pennsylvania,	was	sentenced	to	eighteen	months	in	prison	for	“unauthorized
access	to	a	protected	computer	to	obtain	information”	related	to	the	hack.	He
was	charged	with	illegal	access	to	over	one	hundred	Apple	and	Google	e-mail
accounts.
4
To	protect	your	iCloud	and	other	online	accounts,	you	must	set	a	strong
password.	That’s	obvious.	Yet	in	my	experience	as	a	penetration	tester	(pen
tester)—someone	who	is	paid	to	hack	into	computer	networks	and	find
vulnerabilities—I	find	that	many	people,	even	executives	at	large	corporations,
are	lazy	when	it	comes	to	passwords.	Consider	that	the	CEO	of	Sony
Entertainment,	Michael	Lynton,	used	“sonyml3”	as	his	domain	account
password.	It’s	no	wonder	his	e-mails	were	hacked	and	spread	across	the
Internet	since	the	attackers	had	administrative	access	to	most	everything	within
the	company.
Beyond	your	work-related	passwords	are	those	passwords	that	protect	your
most	personal	accounts.	Choosing	a	hard-to-guess	password	won’t	
prevent
hacking	tools	such	as	oclHashcat	(a	password-cracking	tool	that	leverages
graphics	processing	units—or	GPUs—for	high-speed	cracking)	from	possibly
cracking	your	password,	but	it	will	make	the	process	slow	enough	to
encourage	an	attacker	to	move	on	to	an	easier	target.
It’s	a	fair	guess	that	some	of	the	passwords	exposed	during	the	July	2015
Ashley	Madison	hack	are	certainly	being	used	elsewhere,	including	on	bank
accounts	and	even	work	computers.	From	the	lists	of	11	million	Ashley
Madison	passwords	posted	online,	the	most	common	were	“123456,”
“12345,”	“password,”	“DEFAULT,”	“123456789,”	“qwerty,”	“12345678,”
“abc123,”	and	“1234567.”
5
	If	you	see	one	of	your	own	passwords	here,
chances	are	you	are	vulnerable	to	a	data	breach,	as	these	common	terms	are
included	in	most	password-cracking	tool	kits	available	online.	You	can	always
check	the	site	www.haveibeenpwned.com	to	see	if	your	account	has	been
compromised	in	the	past.
In	the	twenty-first	century,	we	can	do	better.	And	I	mean	
much
	better,	with
longer	and	much	more	complex	configurations	of	letters	and	numbers.	That
may	sound	hard,	but	I	will	show	you	both	an	automatic	and	a	manual	way	to	do

this.
The	easiest	approach	is	to	forgo	the	creation	of	your	own	passwords	and
simply	automate	the	process.	There	are	several	digital	password	managers	out
there.	Not	only	do	they	store	your	passwords	within	a	locked	vault	and	allow
one-click	access	when	you	need	them,	they	also	generate	new	and	really
strong,	unique	passwords	for	each	site	when	you	need	them.
Be	aware,	though,	of	two	problems	with	this	approach.	One	is	that	password
managers	use	one	master	password	for	access.	If	someone	happens	to	infect
your	computer	with	malware	that	steals	the	password	database	and	your	master
password	through	keylogging—when	the	malware	records	every	keystroke
you	make—it’s	game	over.	That	person	will	then	have	access	to	all	your
passwords.	During	my	pen-testing	engagements,	I	sometimes	replace	the
password	manager	with	a	modified	version	that	transmits	the	master	password
to	us	(when	the	password	manager	is	open-source).	This	is	done	after	we	gain
admin	access	to	the	client’s	network.	We	then	go	after	all	the	privileged
passwords.	In	other	words,	we	will	use	password	managers	as	a	back	door	to
get	the	keys	to	the	kingdom.
The	other	problem	is	kind	of	obvious:	If	you	lose	the	master	password,	you
lose	all	your	passwords.	Ultimately,	this	is	okay,	as	you	can	always	perform	a
password	reset	on	each	site,	but	that	would	be	a	huge	hassle	if	you	have	a	lot	of
accounts.
Despite	these	flaws,	the	following	tips	should	be	more	than	adequate	to	keep
your	passwords	secure.
First,	strong	passphrases,	not	passwords,	should	be	long—at	least	twenty	to
twenty-five	characters.	Random	characters—ek5iogh#skf&skd—work	best.
Unfortunately	the	human	mind	has	trouble	remembering	random	sequences.	So
use	a	password	manager.	Using	a	password	manager	is	far	better	than
choosing	your	own.	I	prefer	open-source	password	managers	like	Password
Safe	and	KeePass	that	only	store	data	locally	on	your	computer.
Another	important	rule	for	good	passwords	is	never	use	the	same	password
for	two	different	accounts.	That’s	hard.	Today	we	have	passwords	on	just	about
everything.	So	have	a	password	manager	generate	and	store	strong,	unique
passwords	for	you.
Even	if	you	have	a	strong	password,	technology	can	still	be	used	to	defeat
you.	There	are	password-guessing	programs	such	as	John	the	Ripper,	a	free
open-source	program	that	anyone	can	download	and	that	works	within
configuration	parameters	set	by	the	user.
6
	For	example,	a	user	might	specify

how	many	characters	to	try,	whether	to	use	special	symbols,	whether	to	include
foreign	language	sets,	and	so	on.	John	the	Ripper	and	other	password	hackers
are	able	to	permute	the	password	letters	using	rule	sets	that	are	extremely
effective	at	cracking	passwords.	This	simply	means	it	tries	every	possible
combination	of	numbers,	letters,	and	symbols	within	the	parameters	until	it	is
successful	at	cracking	your	password.	Fortunately,	most	of	
us	aren’t	up	against
nation-states	with	virtually	unlimited	time	and	resources.	More	likely	we’re	up
against	a	spouse,	a	relative,	or	someone	we	really	pissed	off	who,	when	faced
with	a	twenty-five-character	password,	won’t	have	the	time	or	resources	to
successfully	crack	it.
Let’s	say	you	want	to	create	your	passwords	the	old-fashioned	way	and	that
you’ve	chosen	some	really	strong	passwords.	Guess	what?	It’s	okay	to	write
them	down.	Just	don’t	write	“Bank	of	America:	4the1sttimein4ever*.”	That
would	be	too	obvious.	Instead	replace	the	name	of	your	bank	(for	example)
with	something	cryptic,	such	as	“Cookie	Jar”	(because	some	people	once	hid
their	money	in	cookie	jars)	and	follow	it	with	“4the1st.”	Notice	I	didn’t
complete	the	phrase.	You	don’t	need	to.	You	know	the	rest	of	the	phrase.	But
someone	else	might	not.
Anyone	finding	this	printed-out	list	of	incomplete	passwords	should	be
sufficiently	confused—at	least	at	first.	Interesting	story:	I	was	at	a	friend’s
house—a	very	well-known	Microsoft	employee—and	during	dinner	we	were
discussing	the	security	of	passwords	with	his	wife	and	child.	At	one	point	my
friend’s	wife	got	up	and	went	to	the	refrigerator.	She	had	written	down	all	her
passwords	on	a	single	piece	of	paper	and	stuck	it	to	the	appliance’s	door	with	a
magnet.	My	friend	just	shook	his	head,	and	I	grinned	widely.	Writing	down
passwords	might	not	be	a	perfect	solution,	but	neither	is	forgetting	that	rarely
used	strong	password.
Some	websites—such	as	your	banking	website—lock	out	users	after	several
failed	password	attempts,	usually	three.	Many	sites,	however,	still	do	not	do
this.	But	even	if	a	site	does	lock	a	person	out	after	three	failed	attempts,	that
isn’t	how	the	bad	guys	use	John	the	Ripper	or	oclHashcat.	(Incidentally,
oclHashcat	distributes	the	hacking	process	over	multiple	GPUs	and	is	much
more	powerful	than	John	the	Ripper.)	Also,	hackers	don’t	actually	try	every
single	possible	password	on	a	live	site.
Let’s	say	there	has	been	a	data	breach,	and	included	within	the	
data	dump
are	usernames	and	passwords.	But	the	passwords	retrieved	from	the	data

breach	are	mere	gibberish.
How	does	that	help	anyone	break	into	your	account?
Whenever	you	type	in	a	password,	whether	it	is	to	unlock	your	laptop	or	an
online	service—that	password	is	put	through	a	one-way	algorithm	known	as	a
hash	function.	It	is	not	the	same	as	encryption.	Encryption	is	two-way:	you	can
encrypt	and	decrypt	as	long	as	you	have	a	key.	A	hash	is	a	fingerprint
representing	a	particular	string	of	characters.	In	theory,	one-way	algorithms
can’t	be	reversed—or	at	least	not	easily.
What	is	stored	in	the	password	database	on	your	traditional	PC,	your
mobile	device,	or	your	cloud	account	is	not	MaryHadALittleLamb123$	but	its
hash	value,	which	is	a	sequence	of	numbers	and	letters.	The	sequence	is	a	token
that	represents	your	password.
7
It	is	the	password	hashes,	not	the	passwords	themselves,	that	are	stored	in
the	protected	memory	of	our	computers	and	can	be	obtained	from	a
compromise	of	targeted	systems	or	leaked	in	data	breaches.	Once	an	attacker
has	obtained	these	password	hashes,	the	hacker	can	use	a	variety	of	publicly
available	tools,	such	as	John	the	Ripper	or	oclHashcat,	to	crack	the	hashes	and
obtain	the	actual	password,	either	through	brute	force	(trying	every	possible
alphanumeric	combination)	or	trying	each	word	in	a	word	list,	such	as	a
dictionary.	Options	available	in	John	the	Ripper	and	oclHashcat	allow	the
attacker	to	modify	the	words	tried	against	numerous	rule	sets,	for	example	the
rule	set	called	leetspeak—a	system	for	replacing	letters	with	numbers,	as	in
“k3v1n	m17n1ck.”	This	rule	will	change	all	passwords	to	various	leetspeak
permutations.	Using	these	methods	to	crack	passwords	is	much	more	effective
than	simple	brute	force.	The	simplest	and	most	common	passwords	are	easily
cracked	first,	then	more	complex	passwords	are	cracked	over	time.	The	length
of	time	it	takes	depends	on	several	factors.	Using	a	password-cracking	tool
together	with	your	breached	username	and	
hashed	password,	hackers	may	be
able	to	access	one	or	more	of	your	accounts	by	trying	that	password	on
additional	sites	connected	to	your	e-mail	address	or	other	identifier.
In	general,	the	more	characters	in	your	password,	the	longer	it	will	take
password-guessing	programs	such	as	John	the	Ripper	to	run	through	all	the
possible	variations.	As	computer	processors	get	faster,	the	length	of	time	it
takes	to	calculate	all	the	possible	six-character	and	even	eight-character
passwords	is	becoming	a	lot	shorter,	too.	That’s	why	I	recommend	using
passwords	of	twenty-five	characters	or	more.
After	you	create	strong	passwords—and	many	of	them—never	give	them

out.	That	seems	painfully	obvious,	but	surveys	in	London	and	other	major
cities	show	that	people	have	traded	their	passwords	in	exchange	for	something
as	trivial	as	a	pen	or	a	piece	of	chocolate.
8
A	friend	of	mine	once	shared	his	Netflix	password	with	a	girlfriend.	It	made
sense	at	the	time.	There	was	the	immediate	gratification	of	letting	her	choose	a
movie	for	them	to	watch	together.	But	trapped	within	Netflix’s	recommended-
movie	section	were	all	his	“because	you	watched…”	movies,	including	movies
he	had	watched	with	past	girlfriends.	
The	Sisterhood	of	the	Traveling	Pants,
	for
instance,	is	not	a	film	he	would	have	ordered	himself,	and	his	girlfriend	knew
this.
Of	course,	everyone	has	exes.	You	might	even	be	suspicious	if	you	dated
someone	who	didn’t.	But	no	girlfriend	wants	to	be	confronted	with	evidence	of
those	who	have	gone	before	her.
If	you	password-protect	your	online	services,	you	should	also	password-
protect	your	individual	devices.	Most	of	us	have	laptops,	and	many	of	us	still
have	desktops.	You	may	be	home	alone	now,	but	what	about	those	dinner	guests
coming	later?	Why	take	a	chance	that	one	of	them	could	access	your	files,
photos,	and	games	just	by	sitting	at	your	desk	and	moving	the	mouse?	Another
Netflix	cautionary	tale:	back	in	the	days	when	Netflix	primarily	sent	out	
DVDs,
I	knew	a	couple	who	got	pranked.	During	a	party	at	their	house,	they’d	left
their	browser	open	to	their	Netflix	account.	Afterward,	the	couple	found	that	all
sorts	of	raunchy	B-and	C-list	movies	had	been	added	to	their	queue—but	only
after	they’d	received	more	than	one	of	these	films	in	the	mail.
It’s	even	more	important	to	protect	yourself	with	passwords	at	the	office.
Think	of	all	those	times	you’re	called	away	from	your	desk	into	an	impromptu
meeting.	Someone	could	walk	by	your	desk	and	see	the	spreadsheet	for	the
next	quarter’s	budget.	Or	all	the	e-mails	sitting	in	your	inbox.	Or	worse,	unless
you	have	a	password-protected	screen	saver	that	kicks	in	after	a	few	seconds	of
inactivity,	whenever	you’re	away	from	your	desk	for	an	extended	period—out
to	lunch	or	at	a	long	meeting—someone	could	sit	down	and	write	an	e-mail
and	send	it	as	you.	Or	even	alter	the	next	quarter’s	budget.
There	are	creative	new	methods	to	preventing	this,	like	screen-locking
software	that	uses	Bluetooth	to	verify	if	you	are	near	your	computer.	In	other
words,	if	you	go	to	the	bathroom	and	your	mobile	phone	goes	out	of
Bluetooth	range	of	the	computer,	the	screen	is	immediately	locked.	There	are
also	versions	that	use	a	Bluetooth	device	like	a	wristband	or	smartwatch	and

will	do	the	same	thing.
Creating	passwords	to	protect	online	accounts	and	services	is	one	thing,	but	it’s
not	going	to	help	you	if	someone	gains	physical	possession	of	your	device,
especially	if	you’ve	left	those	online	accounts	open.	So	if	you	password-
protect	only	one	set	of	devices,	it	should	be	your	mobile	devices,	because	these
are	the	most	vulnerable	to	getting	lost	or	stolen.	Yet	
Consumer	Reports
	found
that	34	percent	of	Americans	don’t	protect	their	mobile	devices	with	any
security	measures	at	all,	such	as	locking	the	screen	with	a	simple	four-digit
PIN.
9
In	2014	a	Martinez,	California,	police	officer	confessed	to	stealing	nude
photos	from	the	cell	phone	of	a	DUI	suspect,	a	clear	violation	of	the	Fourth
Amendment,	which	is	part	of	the	Constitution’s	Bill	of	
Rights.
10
	Specifically,
the	Fourth	Amendment	prohibits	unreasonable	searches	and	seizures	without	a
warrant	issued	by	a	judge	and	supported	by	probable	cause—law	enforcement
officers	have	to	state	why	they	want	access	to	your	phone,	for	instance.
If	you	haven’t	already	password-protected	your	mobile	device,	take	a
moment	now	and	do	so.	Seriously.
There	are	three	common	ways	to	lock	your	phone—whether	it’s	an
Android	or	iOS	or	something	else.	The	most	familiar	is	a	passcode—a
sequence	of	numbers	that	you	enter	in	a	specific	order	to	unlock	your	phone.
Don’t	settle	for	the	number	of	digits	the	phone	recommends.	Go	into	your
settings	and	manually	configure	the	passcode	to	be	stronger—seven	digits	if
you	want	(like	an	old	phone	number	from	your	childhood.)	Certainly	use	more
than	just	four.
Some	mobile	devices	allow	you	to	choose	a	text-based	passcode,	such	as
the	examples	we	created	
here
.	Again,	choose	at	least	seven	characters.	Modern
mobile	devices	display	both	number	and	letter	keys	on	the	same	screen,
making	it	easier	to	switch	back	and	forth	between	them.
Another	lock	option	is	visual.	Since	2008,	Android	phones	have	been
equipped	with	something	called	Android	lock	patterns	(ALPs).	Nine	dots
appear	on	the	screen,	and	you	connect	them	in	any	order	you	want;	that
connecting	sequence	becomes	your	passcode.	You	might	think	this	ingenious
and	that	the	sheer	range	of	possible	combinations	makes	your	sequence
unbreakable.	But	at	the	Passwords-Con	conference	in	2015,	researchers
reported	that—human	nature	being	what	it	is—participants	in	a	study	availed
themselves	of	just	a	few	possible	patterns	out	of	the	140,704	possible

combinations	on	ALP.
11
	And	what	were	those	predictable	patterns?	Often	the
first	letter	of	the	user’s	name.	The	study	also	found	that	people	tended	to	use
the	dots	in	the	middle	and	not	in	the	remote	four	corners.	Consider	that	the	next
time	you	set	an	ALP.
Finally	there’s	the	biometric	lock.	Apple,	Samsung,	and	other	
popular
manufacturers	currently	allow	customers	the	option	of	using	a	fingerprint
scanner	to	unlock	their	phones.	Be	aware	that	these	are	not	foolproof.	After	the
release	of	Touch	ID,	researchers—perhaps	expecting	Apple	to	have	improved
upon	the	current	crop	of	fingerprint	scanners	already	on	the	market—were
surprised	to	find	that	several	old	methods	of	defeating	fingerprint	scanners
still	work	on	the	iPhone.	These	include	capturing	a	fingerprint	off	of	a	clean
surface	using	baby	powder	and	clear	adhesive	tape.
Other	phones	use	the	built-in	camera	for	facial	recognition	of	the	owner.
This,	too,	can	be	defeated	by	holding	up	a	high-resolution	photograph	of	the
owner	in	front	of	the	camera.
In	general,	biometrics	by	themselves	are	vulnerable	to	attacks.	Ideally
biometrics	should	be	used	as	just	one	authenticating	factor.	Swipe	your
fingertip	or	smile	for	the	camera,	then	enter	a	PIN	or	passcode.	That	should
keep	your	mobile	device	secure.
What	if	you	created	a	strong	password	but	didn’t	write	it	down?	Password
resets	are	a	godsend	when	you	absolutely	can’t	access	an	infrequently	used
account.	But	they	can	also	be	low-hanging	fruit	for	would-be	attackers.	Using
the	clues	we	leave	in	the	form	of	social	media	profiles	all	over	the	Internet,
hackers	can	gain	access	to	our	e-mail—and	other	services—simply	by
resetting	our	passwords.
One	attack	that	has	been	in	the	press	involves	obtaining	the	target’s	last	four
digits	of	his	or	her	credit	card	number,	and	then	using	that	as	proof	of	identity
when	calling	in	to	a	service	provider	to	change	the	authorized	e-mail	address.
That	way,	the	attacker	can	reset	the	password	on	his	or	her	own	without	the
legitimate	owner	knowing.
Back	in	2008	a	student	at	the	University	of	Tennessee,	David	Kernell,
decided	to	see	whether	he	could	access	then	vice	presidential	candidate	Sarah
Palin’s	personal	Yahoo	e-mail	account.
12
	Kernell	could	have	guessed	various
passwords,	but	access	to	the	account	
might	have	been	locked	after	a	few	failed
tries.	Instead	he	used	the	password	reset	function,	a	process	he	later	described
as	“easy.”
13

I’m	sure	we’ve	all	received	strange	e-mails	from	friends	and	associates
containing	links	to	porn	sites	in	foreign	countries	only	to	learn	later	that	our
friends’	e-mail	accounts	had	been	taken	over.	These	e-mail	takeovers	often
occur	because	the	passwords	guarding	the	accounts	are	not	strong.	Either
someone	learned	the	password—through	a	data	breach—or	the	attacker	used
the	password	reset	function.
When	first	setting	up	an	account	such	as	an	e-mail	or	even	a	bank	account,
you	may	have	been	asked	what	are	usually	labeled	as	security	questions.
Typically	there	are	three	of	them.	Often	there	are	drop-down	menus	listing
suggested	questions,	so	you	can	choose	which	ones	you	want	to	answer.
Usually	they	are	really	obvious.
Where	were	you	born?	Where	did	you	go	to	high	school?	Or	college?	And
the	old	favorite,	your	mother’s	maiden	name,	which	apparently	has	been	in	use
as	a	security	question	since	at	least	1882.
14
	As	I’ll	discuss	below,	companies
can	and	do	scan	the	Internet	and	collect	personal	information	that	makes
answering	these	basic	security	questions	a	piece	of	cake.	A	person	can	spend	a
few	minutes	on	the	Internet	and	have	a	good	chance	of	being	able	to	answer	all
the	security	questions	of	a	given	individual.
Only	recently	have	these	security	questions	improved	somewhat.	For
example,	“What	is	the	state	where	your	brother-in-law	was	born?”	is	pretty
distinct,	though	answering	these	“good”	questions	correctly	can	carry	its	own
risks,	which	I’ll	get	to	in	a	minute.	But	many	so-called	security	questions	are
still	too	easy,	such	as	“What	is	your	father’s	hometown?”
In	general,	when	setting	these	security	questions,	try	to	avoid	the	most
obvious	suggestions	available	from	the	drop-down	menu.	Even	if	the	site
includes	only	basic	security	questions,	be	creative.	No	one	says	you	have	to
provide	straightforward	answers.	You	can	be	clever	
about	it.	For	example,	as
far	as	your	streaming	video	service	is	concerned,	maybe	tutti-frutti	is	your	new
favorite	color.	Who	would	guess	that?	It	is	a	color,	right?	What	you	provide	as
the	answer	becomes	the	“correct”	answer	to	that	security	question.
Whenever	you	do	provide	creative	answers,	be	sure	to	write	down	both	the
question	and	the	answer	and	put	them	in	a	safe	place	(or	simply	use	a	password
manager	to	store	your	questions	and	answers).	There	may	be	a	later	occasion
when	you	need	to	talk	to	technical	support,	and	a	representative	might	ask	you
one	of	the	security	questions.	Have	a	binder	handy	or	keep	a	card	in	your
wallet	(or	memorize	and	consistently	use	the	same	set	of	responses)	to	help
you	remember	that	“In	a	hospital”	is	the	correct	answer	to	the	question	“Where

were	you	born?”	This	simple	obfuscation	would	thwart	someone	who	later	did
their	Internet	research	on	you	and	tried	a	more	reasonable	response,	such	as
“Columbus,	Ohio.”
There	are	additional	privacy	risks	in	answering	very	specific	security
questions	honestly:	you	are	giving	out	more	personal	information	than	is
already	out	there.	For	example,	the	honest	answer	to	“What	state	was	your
brother-in-law	born	in?”	can	then	be	sold	by	the	site	you	gave	that	answer	to
and	perhaps	combined	with	other	information	or	used	to	fill	in	missing
information.	For	example,	from	the	brother-in-law	answer	one	can	infer	that
you	are	or	were	married	and	that	your	partner,	or	your	ex,	has	a	sibling	who	is
either	a	man	or	married	to	a	man	born	in	the	state	you	provided.	That’s	a	lot	of
additional	information	from	a	simple	answer.	On	the	other	hand,	if	you	don’t
have	a	brother-in-law,	go	ahead	and	answer	the	question	creatively,	perhaps	by
answering	“Puerto	Rico.”	That	should	confuse	anyone	trying	to	build	a	profile
on	you.	The	more	red	herrings	you	provide,	the	more	you	become	invisible
online.
When	answering	these	relatively	uncommon	questions,	always	consider
how	valuable	the	site	is	to	you.	For	example,	you	might	trust	your	bank	to	have
this	additional	personal	information	but	not	your	
streaming	video	service.
Also	consider	what	the	site’s	privacy	policy	might	be:	look	for	language	that
says	or	suggests	that	it	might	sell	the	information	it	collects	to	third	parties.
The	password	reset	for	Sarah	Palin’s	Yahoo	e-mail	account	required	her
birth	date,	zip	code,	and	the	answer	to	the	security	question	“Where	did	you
meet	your	husband?”	Palin’s	birth	date	and	zip	code	could	easily	be	found
online	(at	the	time,	Palin	was	the	governor	of	Alaska).	The	security	question
took	a	bit	more	work,	but	the	answer	to	it,	too,	was	accessible	to	Kernell.	Palin
gave	many	interviews	in	which	she	stated	repeatedly	that	her	husband	was	her
high	school	sweetheart.	That,	it	turns	out,	was	the	correct	answer	to	her
security	question:	“High	school.”
By	guessing	the	answer	to	Palin’s	security	question,	Kernell	was	able	to
reset	her	Yahoo	Mail	password	to	one	that	he	controlled.	This	allowed	him	to
see	all	her	personal	Yahoo	e-mails.	A	screenshot	of	her	inbox	was	posted	on	a
hacker	website.	Palin	herself	was	locked	out	of	her	e-mail	until	she	reset	the
password.
15
What	Kernell	did	was	illegal,	a	violation	of	the	Computer	Fraud	and	Abuse
Act.	Specifically,	he	was	found	guilty	on	two	counts:	anticipatory	obstruction
of	justice	by	destruction	of	records,	a	felony,	and	gaining	unauthorized	access

to	a	computer,	a	misdemeanor.	He	was	sentenced	in	2010	to	one	year	and	one
day	in	prison	plus	three	years	of	supervised	release.
16
If	your	e-mail	account	has	been	taken	over,	as	Palin’s	was,	first	you	will
need	to	change	your	password	using	(yes,	you	guessed	it)	the	password	reset
option.	Make	this	new	password	a	stronger	password,	as	I	suggested	above.
Second,	check	the	Sent	box	to	see	exactly	what	was	sent	in	your	name.	You
might	see	a	spam	message	that	was	sent	to	multiple	parties,	even	your	entire
contacts	list.	Now	you	know	why	your	friends	have	been	sending	you	spam	for
all	these	years—someone	hacked	their	e-mail	accounts.
Also	check	to	see	whether	anyone	has	added	himself	to	your	
account.
Earlier	we	talked	about	mail	forwarding	with	regard	to	multiple	e-mail
accounts.	Well,	an	attacker	who	gains	access	to	your	e-mail	service	could	also
have	all	your	e-mail	forwarded	to	his	account.	You	would	still	see	your	e-mail
normally,	but	the	attacker	would	see	it	as	well.	If	someone	has	added	himself	to
your	account,	delete	this	forwarding	e-mail	address	immediately.
Passwords	and	PINs	are	part	of	the	security	solution,	but	we’ve	just	seen	that
these	can	be	guessed.	Even	better	than	complex	passwords	are	two-factor
authentication	methods.	In	fact,	in	response	to	Jennifer	Lawrence	and	other
celebrities	having	their	nude	photos	plastered	over	the	Internet,	Apple	instituted
two-factor	authentication,	or	2FA,	for	its	iCloud	services.
What	is	2FA?
When	attempting	to	authenticate	a	user,	sites	or	applications	look	for	at	least
two	of	three	things.	Typically	these	are	something	you	have,	something	you
know,	and	something	you	are.	Something	you	have	can	be	a	magnetic	stripe	or
chip-embedded	credit	or	debit	card.	Something	you	know	is	often	a	PIN	or	an
answer	to	a	security	question.	And	something	you	are	encompasses	biometrics
—fingerprint	scanning,	facial	recognition,	voice	recognition,	and	so	on.	The
more	of	these	you	have,	the	surer	you	can	be	that	the	user	is	who	she	says	she
is.
If	this	sounds	like	new	technology,	it’s	not.	For	more	than	forty	years	most
of	us	have	been	performing	2FA	without	realizing	it.
Whenever	you	use	an	ATM,	you	perform	2FA.	How	is	that	possible?	You
have	a	bank-issued	card	(that’s	something	you	have)	and	a	PIN	(that’s
something	you	know).	When	you	put	them	together,	the	unmanned	ATM	out	on
the	street	knows	that	you	want	access	to	the	account	identified	on	the	card.	In
some	countries,	there	are	additional	means	of	authentication	at	ATMs,	such	as

facial	recognition	and	a	palm	print.	This	is	called	multifactor	authentication
(MFA).
Something	similar	is	possible	online.	Many	financial	and	health-care
institutions,	as	well	as	commercial	e-mail	and	social	media	accounts,	allow
you	to	choose	2FA.	In	this	case,	the	something	you	know	is	your	password,	and
the	something	you	have	is	your	cell	phone.	Using	the	phone	to	access	these
sites	is	considered	“out	of	band”	because	the	phone	is	not	connected	to	the
computer	you	are	using.	But	if	you	have	2FA	enabled,	an	attacker	should	not	be
able	to	access	your	2FA-protected	accounts	without	having	your	mobile	device
in	hand.
Say	you	use	Gmail.	To	enable	2FA	you	will	be	asked	to	input	your	cell-
phone	number	on	the	Gmail	site.	To	verify	your	identity,	Google	will	then	send
an	SMS	code	of	six	digits	to	your	phone.	By	subsequently	inputting	that	code
on	the	Gmail	site,	you	have	just	verified	that	this	computer	and	that	cell-phone
number	are	connected.
After	that,	if	someone	tries	to	change	the	password	on	your	account	from	a
new	computer	or	device,	a	text	message	will	be	sent	to	your	phone.	Only	when
the	correct	verification	code	is	entered	on	the	website	will	any	change	to	your
account	be	saved.
There’s	a	wrinkle	to	that,	though.	According	to	researchers	at	Symantec,	if
you	do	send	an	SMS	to	confirm	your	identity,	someone	who	happens	to	know
your	cell-phone	number	can	do	a	bit	of	social	engineering	and	steal	your	2FA-
protected	password	reset	code	if	you	are	not	paying	close	attention.
17
Say	I	want	to	take	over	your	e-mail	account	and	don’t	know	your	password.
I	do	know	your	cell-phone	number	because	you’re	easy	to	find	through
Google.	I	can	go	to	the	reset	page	for	your	e-mail	service	and	request	a
password	reset,	which,	because	you	enabled	two-factor	authentication,	will
result	in	an	SMS	code	being	sent	to	your	phone.	So	far,	so	good,	right?	Hang
on.
A	recent	attack	on	a	phone	used	by	political	activist	DeRay	Mckesson
showed	how	the	bad	guys	could	trick	your	mobile	operator	to	do	a	SIM
swap.
18
	In	other	words,	the	attacker	could	hijack	your	cellular	
service	and	then
receive	your	SMS	messages—for	example,	the	SMS	code	from	Google	to
reset	Mckesson’s	Gmail	account	that	was	protected	with	two-factor
authentication.	This	is	much	more	likely	than	fooling	someone	into	reading	off
his	or	her	SMS	message	with	a	new	password.	Although	that	is	still	possible,
and	involves	social	engineering.

Because	I	won’t	see	the	verification	code	sent	by	your	e-mail	provider	to
your	phone,	I’ll	need	to	pretend	to	be	someone	else	in	order	to	get	it	from	you.
Just	seconds	before	you	receive	the	actual	SMS	from,	say,	Google,	I	as	the
attacker	can	send	a	one-time	SMS,	one	that	says:	“Google	has	detected	unusual
activity	on	your	account.	Please	respond	with	the	code	sent	to	your	mobile
device	to	stop	unauthorized	activity.”
You	will	see	that	yes,	indeed,	you	just	got	an	SMS	text	from	Google
containing	a	legitimate	verification	code,	and	so	you	might,	if	you	are	not
being	careful,	simply	reply	to	me	in	a	message	and	include	the	code.	I	would
then	have	less	than	sixty	seconds	to	enter	the	verification	code.	Now	I	have
what	I	need	to	enter	on	the	password	reset	page	and,	after	changing	your
password,	take	over	your	e-mail	account.	Or	any	other	account.
Since	SMS	codes	are	not	encrypted	and	can	be	obtained	in	the	way	I	just
described,	an	even	more	secure	2FA	method	is	to	download	the	Google
Authenticator	app	from	Google	Play	or	the	iTunes	app	store	for	use	with	an
iPhone.	This	app	will	generate	a	unique	access	code	on	the	app	itself	each	time
you	want	to	visit	a	site	that	requires	2FA—so	there’s	no	SMS	to	be	sent.	This
app-generated	six-digit	code	is	synced	with	the	site’s	authentication	mechanism
used	to	grant	access	to	the	site.	However,	Google	Authenticator	stores	your
one-time	password	seed	in	the	Apple	Keychain	with	a	setting	for	“This	Device
Only.”	That	means	if	you	back	up	your	iPhone	and	restore	to	a	
different
	device
because	you	are	upgrading	or	replacing	a	lost	phone,	your	Google
Authenticator	codes	will	not	be	transferred	and	it’s	a	huge	
hassle	to	reset	them.
It’s	always	a	good	idea	to	print	out	the	emergency	codes	in	case	you	end	up
switching	physical	devices.	Other	apps	like	1Password	allow	you	to	back	up
and	restore	your	one-time	password	seeds	so	you	don’t	have	this	problem.
Once	you	have	registered	a	device,	as	long	as	you	continue	to	log	in	to	the
site	from	that	device,	you	will	be	prompted	for	a	new	access	code	unless	you
specifically	check	the	box	(if	available)	to	trust	the	computer	for	thirty	days,
even	if	you	take	your	laptop	or	phone	to	another	location.	However,	if	you	use
another	device—say,	you	borrow	your	spouse’s	computer—then	you	will	be
asked	for	additional	authentication.	Needless	to	say,	if	you’re	using	2FA,
always	have	your	cell	phone	handy.
Given	all	these	precautions,	you	might	wonder	what	advice	I	give	to	people
who	are	conducting	any	type	of	financial	transaction	online.
For	about	$100	a	year	you	can	get	antivirus	and	firewall	protection	for	up

to	three	computers	under	your	control.	The	trouble	is	that	when	you’re	surfing
the	Web,	you	might	load	into	your	browser	a	banner	ad	that	contains	malware.
Or	maybe	you	open	your	e-mail,	and	one	of	the	e-mails	contains	malware.	One
way	or	another	you	are	going	to	get	your	computer	infected	if	it	regularly
touches	the	Internet,	and	your	antivirus	product	may	not	catch	everything	that’s
out	there.
So	I	recommend	you	spend	around	$200	to	get	yourself	a	Chromebook.	I
like	iPads,	but	they’re	expensive.	The	Chromebook	is	as	close	to	an	easy-to-
use	tablet	as	an	iPad	is,	and	it	costs	much	less.
My	point	is	that	you	need	to	have	a	secondary	device	that	you	use
exclusively	for	financial	stuff—perhaps	even	medical	stuff	as	well.	No	apps
can	be	installed	unless	you	first	register	with	a	Gmail	account—this	will	limit
you	to	opening	the	browser	to	surf	the	Internet.
Then,	if	you	haven’t	already	done	so,	activate	2FA	on	the	site	so	
that	it
recognizes	the	Chromebook.	Once	you’ve	completed	your	banking	or	health-
care	business,	put	the	Chromebook	away	until	the	next	time	you	have	to
balance	your	checkbook	or	arrange	a	doctor’s	appointment.
This	seems	like	a	hassle.	It	is.	It	replaces	the	convenience	of	anytime
banking	with	
almost
	anytime	banking.	But	the	result	is	that	you	are	far	less
likely	to	have	someone	messing	around	with	your	banking	and	credit
information.	If	you	use	the	Chromebook	only	for	the	two	or	three	apps	you
install,	and	if	you	bookmark	the	banking	or	health-care	websites	and	visit	no
others,	it	is	very	unlikely	that	you	will	have	a	Trojan	or	some	other	form	of
malware	residing	on	your	machine.
So	we’ve	established	that	you	need	to	create	strong	passwords	and	not	share
them.	You	need	to	turn	on	2FA	whenever	possible.	In	the	next	few	chapters
we’ll	look	at	how	common	day-to-day	interactions	can	leave	digital
fingerprints	everywhere	and	what	you	can	do	to	protect	your	privacy.

CHAPTER	TWO
Who	Else	Is	Reading	Your	E-mail?
If	you’re	like	me
,	one	of	the	first	things	you	do	in	the	morning	is	check
your	e-mail.	And,	if	you’re	like	me,	you	also	wonder	who	else	has	read	your
e-mail.	That’s	not	a	paranoid	concern.	If	you	use	a	Web-based	e-mail	service
such	as	Gmail	or	Outlook	365,	the	answer	is	kind	of	obvious	and	frightening.
Even	if	you	delete	an	e-mail	the	moment	you	read	it	on	your	computer	or
mobile	phone,	that	doesn’t	necessarily	erase	the	content.	There’s	still	a	copy	of
it	somewhere.	Web	mail	is	cloud-based,	so	in	order	to	be	able	to	access	it	from
any	device	anywhere,	at	any	time,	there	have	to	be	redundant	copies.	If	you	use
Gmail,	for	example,	a	copy	of	every	e-mail	sent	and	received	through	your
Gmail	account	is	retained	on	various	servers	worldwide	at	Google.	This	is
also	true	if	you	use	e-mail	systems	provided	by	Yahoo,	Apple,	AT&T,
Comcast,	Microsoft,	or	even	your	workplace.	Any	e-mails	you	send	can	also
be	inspected,	at	any	time,	by	the	hosting	company.	Allegedly	this	is	to	filter	out
malware,	but	the	reality	is	that	third	parties	can	and	do	access	our	e-mails	for
other,	more	sinister	and	self-serving,	reasons.
In	principle,	most	of	us	would	never	stand	for	anyone	except	the	intended
recipient	reading	our	mail.	There	are	laws	protecting	printed	mail	delivered
through	the	US	Postal	Service,	and	laws	protecting	stored	content	such	as	e-
mail.	Yet	in	practice,	we	usually	know	and	probably	accept	that	there’s	a	certain

trade-off	involved	in	the	ease	of	communication	e-mail	affords.	We	know	that
Yahoo	(among	others)	offers	a	free	Web-mail	service,	and	we	know	that	Yahoo
makes	the	majority	of	its	money	from	advertising.	Perhaps	we’ve	not	realized
exactly	how	the	two	might	be	connected	and	how	that	might	affect	our	privacy.
One	day,	Stuart	Diamond,	a	resident	of	Northern	California,	did.	He
realized	that	the	ads	he	saw	in	the	upper-right-hand	corner	of	his	Yahoo	Mail
client	were	not	random;	they	were	based	on	the	contents	of	the	e-mails	he	had
been	sending	and	receiving.	For	example,	if	I	mentioned	in	an	e-mail	an
upcoming	speaking	trip	to	Dubai,	the	ads	I	might	see	in	my	e-mail	account
would	suggest	airlines,	hotels,	and	things	to	do	while	in	the	United	Arab
Emirates.
This	practice	is	usually	carefully	spelled	out	in	the	terms	of	service	that
most	of	us	agreed	to	but	probably	never	read.	Nobody	wants	to	see	ads	that
have	nothing	to	do	with	our	individual	interests,	right?	And	as	long	as	the	e-
mail	travels	between	Yahoo	account	holders,	it	seems	reasonable	that	the
company	would	be	able	to	scan	the	contents	of	those	e-mails	in	order	to	target
ads	to	us	and	maybe	block	malware	and	spam,	which	is	unwanted	e-mail.
However,	Diamond,	along	with	David	Sutton,	also	from	Northern
California,	began	to	notice	that	the	contents	of	e-mails	sent	to	and	received
from	addresses	
outside
	Yahoo	also	influenced	the	ad	selection	presented	to
them.	That	suggested	that	the	company	was	intercepting	and	reading	
all
	their	e-
mail,	not	just	those	sent	to	and	from	its	own	servers.
Based	on	the	patterns	they	observed,	the	two	filed	a	class-action	lawsuit	in
2012	against	Yahoo	on	behalf	of	its	275	million	account	
holders,	citing
concerns	around	what	is	essentially	equivalent	to	illegal	wiretapping	by	the
company.
Did	that	end	the	scanning?	No.
In	a	class-action	suit,	there	is	a	period	of	discovery	and	response	from	both
parties.	In	this	case	that	initial	phase	lasted	nearly	three	years.	In	June	of	2015,
a	judge	in	San	Jose,	California,	ruled	that	the	men	had	sufficient	grounds	for
their	class-action	suit	to	proceed	and	that	people	who	sent	or	received	Yahoo
Mail	since	October	2,	2011,	when	the	men	filed	their	initial	request,	could	join
in	the	lawsuit	under	the	Stored	Communications	Act.	Additionally,	a	class	of
non–Yahoo	Mail	account	holders	living	in	California	may	also	sue	under	that
state’s	Invasion	of	Privacy	Act.	That	case	is	still	pending.
In	defending	itself	against	another	e-mail-scanning	lawsuit,	this	one	filed
early	in	2014,	Google	accidentally	published	information	about	its	e-mail

scanning	process	in	a	court	hearing,	then	quickly	attempted	and	failed	to	have
that	information	redacted	or	removed.	The	case	involved	the	question	of
precisely	what	was	scanned	or	read	by	Google.	According	to	the	plaintiffs	in
the	case,	which	included	several	large	media	companies,	including	the	owners
of	
USA	Today,
	Google	realized	at	some	point	that	by	scanning	only	the	contents
of	the	inbox,	they	were	missing	a	lot	of	potentially	useful	content.	This	suit
alleged	that	Google	shifted	from	scanning	only	archived	e-mail,	which	resides
on	the	Google	server,	to	scanning	all	Gmail	still	in	transit,	whether	it	was	sent
from	an	iPhone	or	a	laptop	while	the	user	was	sitting	in	Starbucks.
Sometimes	companies	have	even	tried	to	secretly	scan	e-mails	for	their
own	purposes.	One	well-known	instance	of	this	happened	at	Microsoft,	which
suffered	a	huge	backlash	when	it	revealed	that	it	had	scanned	the	inbox	of	a
Hotmail	user	who	was	suspected	of	having	pirated	a	copy	of	the	company’s
software.	As	a	result	of	this	disclosure,	Microsoft	has	said	it	will	let	law
enforcement	handle	such	investigations	in	the	future.
These	practices	aren’t	limited	to	your	private	e-mail.	If	you	send	
e-mail
through	your	work	network,	your	company’s	IT	department	may	also	be
scanning	and	archiving	your	communications.	It	is	up	to	the	IT	staff	or	their
managers	whether	to	let	any	flagged	e-mail	pass	through	their	servers	and
networks	or	involve	law	enforcement.	This	includes	e-mails	that	contain	trade
secrets	or	questionable	material	such	as	pornography.	It	also	includes	scanning
e-mail	for	malware.	If	your	IT	staff	is	scanning	and	archiving	your	e-mails,
they	should	remind	you	each	time	you	log	in	what	their	policy	is—although
most	companies	do	not.
While	most	of	us	may	tolerate	having	our	e-mails	scanned	for	malware,
and	perhaps	some	of	us	tolerate	scanning	for	advertising	purposes,	the	idea	of
third	parties	reading	our	correspondence	and	acting	on	specific	contents	found
within	specific	e-mails	is	downright	disturbing.	(Except,	of	course,	when	it
comes	to	child	pornography.
1
)
So	whenever	you	write	an	e-mail,	no	matter	how	inconsequential,	and	even
if	you	delete	it	from	your	inbox,	remember	that	there’s	an	excellent	chance	that
a	copy	of	those	words	and	images	will	be	scanned	and	will	live	on—maybe	not
forever,	but	for	a	good	long	while.	(Some	companies	may	have	short	retention
policies,	but	it’s	safe	to	assume	that	most	companies	keep	e-mail	for	a	long
time.)
Now	that	you	know	the	government	and	corporations	are	reading	your	e-
mails,	the	least	you	can	do	is	make	it	much	harder	for	them	to	do	so.

Most	web-based	e-mail	services	use	encryption	when	the	e-mail	is	in	transit.
However,	when	some	services	transmit	mail	between	Mail	Transfer	Agents
(MTAs),	they	may	not	be	using	encryption,	thus	your	message	is	in	the	open.
For	example,	within	the	workplace	a	boss	may	have	access	to	the	company	e-
mail	system.	To	become	invisible	you	will	need	to	encrypt	your	messages—
that	is,	lock	them	so	that	only	the	recipients	can	unlock	and	read	them.	What	is
encryption?	It	is	a	code.
A	very	simple	encryption	example—a	Caesar	cipher,	say—substitutes	each
letter	for	another	one	a	certain	number	of	positions	away	in	the	alphabet.	If	that
number	is	2,	for	example,	then	using	a	Caesar	cipher,	
a
	becomes	
c,	c
	becomes
e,	z
	becomes	
b
,	and	so	forth.	Using	this	offset-by-two	encryption	scheme,
“Kevin	Mitnick”	becomes	“Mgxkp	Okvpkem.”
2
Most	encryption	systems	used	today	are,	of	course,	much	stronger	than	any
basic	Caesar	cipher.	Therefore	they	should	be	much	harder	to	break.	One	thing
that’s	true	about	all	forms	of	encryption	is	that	they	require	a	key,	which	is
used	as	a	password	to	lock	and	open	the	encrypted	message.	Symmetrical
encryption	means	that	the	same	key	is	used	both	to	lock	and	unlock	the
encrypted	message.	Symmetrical	keys	are	hard	to	share,	however,	when	two
parties	are	unknown	to	each	other	or	physically	far	apart,	as	they	are	on	the
Internet.
Most	e-mail	encryption	actually	uses	what’s	called	asymmetrical
encryption.	That	means	I	generate	two	keys:	a	private	key	that	stays	on	my
device,	which	I	never	share,	and	a	public	key	that	I	post	freely	on	the	Internet.
The	two	keys	are	different	yet	mathematically	related.
For	example:	Bob	wants	to	send	Alice	a	secure	e-mail.	He	finds	Alice’s
public	key	on	the	Internet	or	obtains	it	directly	from	Alice,	and	when	sending	a
message	to	her	encrypts	the	message	with	her	key.	This	message	will	stay
encrypted	until	Alice—and	only	Alice—uses	a	passphrase	to	unlock	her	private
key	and	unlock	the	encrypted	message.
So	how	would	encrypting	the	contents	of	your	e-mail	work?
The	most	popular	method	of	e-mail	encryption	is	PGP,	which	stands	for
“Pretty	Good	Privacy.”	It	is	not	free.	It	is	a	product	of	the	Symantec
Corporation.	But	its	creator,	Phil	Zimmermann,	also	authored	an	open-source
version,	OpenPGP,	which	is	free.	And	a	
third	option,	GPG	(GNU	Privacy
Guard),	created	by	Werner	Koch,	is	also	free.	The	good	news	is	that	all	three
are	interoperational.	That	means	that	no	matter	which	version	of	PGP	you	use,
the	basic	functions	are	the	same.

When	Edward	Snowden	first	decided	to	disclose	the	sensitive	data	he’d	copied
from	the	NSA,	he	needed	the	assistance	of	like-minded	people	scattered	around
the	world.	Paradoxically,	he	needed	to	get	off	the	grid	while	still	remaining
active	on	the	Internet.	He	needed	to	become	invisible.
Even	if	you	don’t	have	state	secrets	to	share,	you	might	be	interested	in
keeping	your	e-mails	private.	Snowden’s	experience	and	that	of	others
illustrate	that	it	isn’t	easy	to	do	that,	but	it	is	possible,	with	proper	diligence.
Snowden	used	his	personal	account	through	a	company	called	Lavabit	to
communicate	with	others.	But	e-mail	is	not	point-to-point,	meaning	that	a
single	e-mail	might	hit	several	servers	around	the	world	before	landing	in	the
intended	recipient’s	inbox.	Snowden	knew	that	whatever	he	wrote	could	be	read
by	anyone	who	intercepted	the	e-mail	anywhere	along	its	journey.
So	he	had	to	perform	a	complicated	maneuver	to	establish	a	truly	secure,
anonymous,	and	fully	encrypted	means	of	communication	with	privacy
advocate	and	filmmaker	Laura	Poitras,	who	had	recently	finished	a
documentary	about	the	lives	of	whistle-blowers.	Snowden	wanted	to	establish
an	encrypted	exchange	with	Poitras,	except	only	a	few	people	knew	her	public
key.	She	didn’t	make	her	public	key	very	public.
To	find	her	public	key,	Snowden	had	to	reach	out	to	a	third	party,	Micah
Lee	of	the	Electronic	Frontier	Foundation,	a	group	that	supports	privacy
online.	Lee’s	public	key	was	available	online	and,	according	to	the	account
published	on	the	
Intercept,
	an	online	publication,	he	
had	Poitras’s	public	key,
but	he	first	needed	to	check	to	see	if	she	would	permit	him	to	share	it.	She
would.
3
At	this	point	neither	Lee	nor	Poitras	had	any	idea	who	wanted	her	public
key;	they	only	knew	that	someone	did.	Snowden	had	used	a	different	account,
not	his	personal	e-mail	account,	to	reach	out.	But	if	you	don’t	use	PGP	often,
you	may	forget	to	include	your	PGP	key	on	important	e-mails	now	and	again,
and	that	is	what	happened	to	Snowden.	He	had	forgotten	to	include	his	own
public	key	so	Lee	could	reply.
With	no	secure	way	to	contact	this	mystery	person,	Lee	was	left	with	no
choice	but	to	send	a	plain-text,	unencrypted	e-mail	back	to	Snowden	asking	for
his	public	key,	which	he	provided.
Once	again	Lee,	a	trusted	third	party,	had	to	be	brought	into	the	situation.	I
can	tell	you	from	personal	experience	that	it	is	very	important	to	verify	the
identity	of	the	person	with	whom	you	are	having	a	secure	conversation,
preferably	through	a	mutual	friend—and	make	sure	you	are	communicating

with	that	friend	and	not	someone	else	in	disguise.
I	know	how	important	this	is	because	I’ve	been	the	poser	before,	in	a
situation	where	it	worked	to	my	advantage	that	the	other	party	didn’t	question
my	real	identity	or	the	public	key	I	sent.	I	once	wanted	to	communicate	with
Neill	Clift,	a	graduate	student	in	organic	chemistry	at	the	University	of	Leeds,
in	England,	who	was	very	skilled	at	finding	security	vulnerabilities	in	the
Digital	Equipment	Corporation’s	VMS	operating	system.	I	wanted	Clift	to	send
me	all	the	security	holes	that	he’d	reported	to	DEC.	For	that	I	needed	him	to
think	that	I	actually	worked	for	DEC.
I	started	by	posing	as	someone	named	Dave	Hutchins	and	sending	Clift	a
spoofed	message	from	him.	I	had	previously	called	Clift	pretending	to	be
Derrell	Piper	from	VMS	engineering,	so	I	(posing	as	Hutchins)	wrote	in	my	e-
mail	that	Piper	wanted	to	exchange	e-mails	with	Clift	about	a	project.	In	going
through	DEC’s	e-mail	
system,	I	already	knew	that	Clift	and	the	real	Piper	had
previously	e-mailed	each	other,	so	this	new	request	wouldn’t	sound	all	that
odd.	I	then	sent	an	e-mail	spoofing	Piper’s	real	e-mail	address.
To	further	convince	Clift	this	was	all	on	the	up-and-up,	I	even	suggested
that	he	use	PGP	encryption	so	that	someone	like	Kevin	Mitnick	wouldn’t	be
able	to	read	the	e-mails.	Soon	Clift	and	“Piper”	were	exchanging	public	keys
and	encrypting	communications—communications	that	I,	as	Piper,	could	read.
Clift’s	mistake	was	in	not	questioning	the	identity	of	Piper	himself.	Similarly,
when	you	receive	an	unsolicited	phone	call	from	your	bank	asking	for	your
Social	Security	number	or	account	information,	you	should	always	hang	up
and	call	the	bank	yourself—you	never	know	who	is	on	the	other	side	of	the
phone	call	or	e-mail.
Given	the	importance	of	the	secrets	they	were	about	to	share,	Snowden	and
Poitras	could	not	use	their	regular	e-mail	addresses.	Why	not?	Their	personal
e-mail	accounts	contained	unique	associations—such	as	specific	interests,	lists
of	contacts—that	could	identify	each	of	them.	Instead	Snowden	and	Poitras
decided	to	create	new	e-mail	addresses.
The	only	problem	was,	how	would	they	know	each	other’s	new	e-mail
addresses?	In	other	words,	if	both	parties	were	totally	anonymous,	how	would
they	know	who	was	who	and	whom	they	could	trust?	How	could	Snowden,	for
example,	rule	out	the	possibility	that	the	NSA	or	someone	else	wasn’t	posing	as
Poitras’s	new	e-mail	account?	Public	keys	are	long,	so	you	can’t	just	pick	up	a
secure	phone	and	read	out	the	characters	to	the	other	person.	You	need	a	secure
e-mail	exchange.

By	enlisting	Micah	Lee	once	again,	both	Snowden	and	Poitras	could	anchor
their	trust	in	someone	when	setting	up	their	new	and	anonymous	e-mail
accounts.	Poitras	first	shared	her	new	public	key	with	Lee.	But	PGP	encryption
keys	themselves	are	rather	long	(not	quite	pi	length,	but	they	are	long),	and,
again,	what	if	someone	were	
watching	his	e-mail	account	as	well?	So	Lee	did
not	use	the	actual	key	but	instead	a	forty-character	abbreviation	(or	a
fingerprint)	of	Poitras’s	public	key.	This	he	posted	to	a	public	site—Twitter.
Sometimes	in	order	to	become	invisible	you	have	to	use	the	visible.
Now	Snowden	could	anonymously	view	Lee’s	tweet	and	compare	the
shortened	key	to	the	message	he	received.	If	the	two	didn’t	match,	Snowden
would	know	not	to	trust	the	e-mail.	The	message	might	have	been
compromised.	Or	he	might	be	talking	instead	to	the	NSA.
In	this	case,	the	two	matched.
Now	several	orders	removed	from	who	they	were	online—and	where	they
were	in	the	world—Snowden	and	Poitras	were	almost	ready	to	begin	their
secure	anonymous	e-mail	communication.	Snowden	finally	sent	Poitras	an
encrypted	e-mail	identifying	himself	only	as	“Citizenfour.”	This	signature
became	the	title	of	her	Academy	Award–winning	documentary	about	his
privacy	rights	campaign.
That	might	seem	like	the	end—now	they	could	communicate	securely	via
encrypted	e-mail—but	it	wasn’t.	It	was	just	the	beginning.
In	the	wake	of	the	2015	terrorist	attacks	in	Paris,	there	was	discussion	from
various	governments	about	building	in	back	doors	or	other	ways	for	those	in
government	to	decrypt	encrypted	e-mail,	text,	and	phone	messages—ostensibly
from	foreign	terrorists.	This	would,	of	course,	defeat	the	purpose	of
encryption.	But	governments	actually	don’t	need	to	see	the	encrypted	contents
of	your	e-mail	to	know	whom	you	are	communicating	with	and	how	often,	as
we	will	see.
As	I	mentioned	before,	the	purpose	of	encryption	is	to	encode	your
message	so	that	only	someone	with	the	correct	key	can	later	decode	it.	Both	the
strength	of	the	mathematical	operation	and	the	length	of	the	encryption	key
determine	how	easy	it	is	for	someone	without	a	key	to	crack	your	code.
Encryption	algorithms	in	use	today	are	public.	You	want	that.
4
	Be	afraid	of
encryption	algorithms	that	are	proprietary	and	not	public.	Public	algorithms
have	been	vetted	for	weakness—meaning	people	have	been	purposely	trying	to
break	them.	Whenever	one	of	the	public	algorithms	becomes	weak	or	is

cracked,	it	is	retired,	and	newer,	stronger	algorithms	are	used	instead.	The
older	algorithms	still	exist,	but	their	use	is	strongly	discouraged.
The	keys	are	(more	or	less)	under	your	control,	and	so,	as	you	might
guess,	their	management	is	very	important.	If	you	generate	an	encryption	key,
you—and	no	one	else—will	have	the	key	stored	on	your	device.	If	you	let	a
company	perform	the	encryption,	say,	in	the	cloud,	then	that	company	might
also	keep	the	key	after	he	or	she	shares	it	with	you.	The	real	concern	is	that	this
company	may	also	be	compelled	by	court	order	to	share	the	key	with	law
enforcement	or	a	government	agency,	with	or	without	a	warrant.	You	will	need
to	read	the	privacy	policy	for	each	service	you	use	for	encryption	and
understand	who	owns	the	keys.
When	you	encrypt	a	message—an	e-mail,	text,	or	phone	call—use	end-to-
end	encryption.	That	means	your	message	stays	unreadable	until	it	reaches	its
intended	recipient.	With	end-to-end	encryption,	only	you	and	your	recipient
have	the	keys	to	decode	the	message.	Not	the	telecommunications	carrier,
website	owner,	or	app	developer—the	parties	that	law	enforcement	or
government	will	ask	to	turn	over	information	about	you.	How	do	you	know
whether	the	encryption	service	you	are	using	is	end-to-end	encryption?	Do	a
Google	search	for	“end-to-end	encryption	voice	call.”	If	the	app	or	service
doesn’t	use	end-to-end	encryption,	then	choose	another.
If	all	this	sounds	complicated,	that’s	because	it	is.	But	there	are	PGP	plug-
ins	for	the	Chrome	and	Firefox	Internet	browsers	that	make	encryption	easier.
One	is	Mailvelope,	which	neatly	handles	the	public	and	private	encryption	keys
of	PGP.	Simply	type	in	a	passphrase,	
which	will	be	used	to	generate	the	public
and	private	keys.	Then	whenever	you	write	a	Web-based	e-mail,	select	a
recipient,	and	if	the	recipient	has	a	public	key	available,	you	will	then	have	the
option	to	send	that	person	an	encrypted	message.
5
Even	if	you	encrypt	your	e-mail	messages	with	PGP,	a	small	but	information-
rich	part	of	your	message	is	still	readable	by	just	about	anyone.	In	defending
itself	from	the	Snowden	revelations,	the	US	government	stated	repeatedly	that
it	doesn’t	capture	the	actual	contents	of	our	e-mails,	which	in	this	case	would
be	unreadable	with	PGP	encryption.	Instead,	the	government	said	it	collects
only	the	e-mail’s	metadata.
What	is	e-mail	metadata?	It	is	the	information	in	the	To	and	From	fields	as
well	as	the	IP	addresses	of	the	various	servers	that	handle	the	e-mail	from
origin	to	recipient.	It	also	includes	the	subject	line,	which	can	sometimes	be

very	revealing	as	to	the	encrypted	contents	of	the	message.	Metadata,	a	legacy
from	the	early	days	of	the	Internet,	is	still	included	on	every	e-mail	sent	and
received,	but	modern	e-mail	readers	hide	this	information	from	display.
6
PGP,	no	matter	what	“flavor”	you	use,	does	not	encrypt	the	metadata—the
To	and	From	fields,	the	subject	line,	and	the	time-stamp	information.	This
remains	in	plain	text,	whether	it	is	visible	to	you	or	not.	Third	parties	will	still
be	able	to	see	the	metadata	of	your	encrypted	message;	they’ll	know	that	on
such-and-such	a	date	you	sent	an	e-mail	to	someone,	that	two	days	later	you
sent	another	e-mail	to	that	same	person,	and	so	on.
That	might	sound	okay,	since	the	third	parties	are	not	actually	reading	the
content,	and	you	probably	don’t	care	about	the	mechanics	of	how	those	e-mails
traveled—the	various	server	addresses	and	the	time	stamps—but	you’d	be
surprised	by	how	much	can	be	learned	from	the	e-mail	path	and	the	frequency
of	e-mails	alone.
Back	in	the	’90s,	before	I	went	on	the	run	from	the	FBI,	I	
performed	what	I
called	a	metadata	analysis	on	various	phone	records.	I	began	this	process	by
hacking	into	PacTel	Cellular,	a	cellular	provider	in	Los	Angeles,	to	obtain	the
call	detail	records	(CDRs)	of	anyone	who	called	an	informant	whom	the	FBI
was	using	to	obtain	information	about	my	activities.
CDRs	are	very	much	like	the	metadata	I’m	talking	about	here;	they	show	the
time	a	phone	call	was	made,	the	number	dialed,	the	length	of	the	call,	and	the
number	of	times	a	particular	number	was	called—all	very	useful	information.
By	searching	through	the	calls	that	were	being	placed	through	PacTel
Cellular	to	the	informant’s	landline,	I	was	able	to	obtain	a	list	of	the	cell-phone
numbers	of	the	people	who	called	him.	Upon	analysis	of	the	callers’	billing
records,	I	was	able	to	identify	those	callers	as	members	of	the	FBI’s	white-
collar	crime	squad,	operating	out	of	the	Los	Angeles	office.	Sure	enough,
some	of	the	numbers	each	individual	dialed	were	internal	to	the	Los	Angeles
office	of	the	FBI,	the	US	attorney’s	office,	and	other	government	offices.	Some
of	those	calls	were	quite	long.	And	quite	frequent.
Whenever	they	moved	the	informant	to	a	new	safe	house,	I	was	able	to
obtain	the	landline	number	of	the	safe	house	because	the	agents	would	call	it
after	trying	to	reach	the	informant	on	his	pager.	Once	I	had	the	landline
number	for	the	informant,	I	was	also	able	to	obtain	the	physical	address
through	social	engineering—that	is,	by	pretending	to	be	someone	at	Pacific
Bell,	the	company	that	provided	the	service	at	the	safe	house.
Social	engineering	is	a	hacking	technique	that	uses	manipulation,	deception,

and	influence	to	get	a	human	target	to	comply	with	a	request.	Often	people	are
tricked	into	giving	up	sensitive	information.	In	this	case,	I	knew	the	internal
numbers	at	the	phone	company,	and	I	pretended	to	be	a	field	technician	who
spoke	the	correct	terminology	and	lingo,	which	was	instrumental	in	obtaining
sensitive	information.
So	while	recording	the	metadata	in	an	e-mail	is	not	the	same	as	
capturing
the	actual	content,	it	is	nonetheless	intrusive	from	a	privacy	perspective.
If	you	look	at	the	metadata	from	any	recent	e-mail	you’ll	see	the	IP
addresses	of	the	servers	that	passed	your	e-mail	around	the	world	before	it
reached	its	target.	Each	server—like	each	person	who	accesses	the	Internet—
has	a	unique	IP	address,	a	numerical	value	that	is	calculated	using	the	country
where	you	are	located	and	who	your	Internet	provider	is.	Blocks	of	IP
addresses	are	set	aside	for	various	countries,	and	each	provider	has	its	own
sub-block,	and	this	is	further	subdivided	by	type	of	service—dial-up,	cable,	or
mobile.	If	you	purchased	a	static	IP	address	it	will	be	associated	with	your
subscriber	account	and	home	address,	otherwise	your	external	IP	address	will
be	generated	from	a	pool	of	addresses	assigned	to	your	Internet	service
provider.	For	example,	a	sender—someone	sending	you	an	email—might	have
the	IP	address	27.126.148.104,	which	is	located	in	Victoria,	Australia.
Or	it	could	be	175.45.176.0,	which	is	one	of	North	Korea’s	IP	addresses.	If
it	is	the	latter,	then	your	e-mail	account	might	be	flagged	for	government
review.	Someone	in	the	US	government	might	want	to	know	why	you’re
communicating	with	someone	from	North	Korea,	even	if	the	subject	line	reads
“Happy	Birthday.”
By	itself,	you	still	might	not	think	the	server	address	is	very	interesting.	But
the	frequency	of	contact	can	tell	you	a	lot.	Additionally,	if	you	identify	each
element—the	sender	and	the	receiver	and	their	locations—you	can	start	to	infer
what’s	really	going	on.	For	example,	the	metadata	associated	with	phone	calls
—the	duration,	the	time	of	day	they’re	made,	and	so	on—can	tell	you	a	lot
about	a	person’s	mental	health.	A	10:00	p.m.	call	to	a	domestic	violence	hotline
lasting	ten	minutes	or	a	midnight	call	from	the	Brooklyn	Bridge	to	a	suicide
prevention	hotline	lasting	twenty	minutes	can	be	very	revealing.	An	app
developed	at	Dartmouth	College	matches	patterns	of	stress,	depression,	and
loneliness	in	user	data.	This	user	activity	has	also	been	correlated	with	student
grades.
7
Still	don’t	see	the	danger	in	having	your	e-mail	metadata	exposed?	A
program	created	at	MIT	called	Immersion	will	visually	map	the	relationships

between	the	senders	and	receivers	of	all	the	e-mail	you	have	stored	in	your	e-
mail	account	just	by	using	the	metadata.	The	tool	is	a	way	to	visually	quantify
who	matters	to	you	most.	The	program	even	includes	a	sliding	time	scale,	so
you	can	see	how	the	people	you	know	rise	and	fall	in	importance	to	you	over
time.	Although	you	might	think	you	understand	your	relationships,	seeing	them
graphically	represented	can	be	a	sobering	experience.	You	might	not	realize
how	often	you	e-mail	someone	you	don’t	really	know	or	how	little	you	e-mail
someone	you	know	very	well.	With	the	Immersion	tool	you	can	choose
whether	to	upload	the	data,	and	you	can	also	delete	the	information	once	it	has
been	graphed.
8
According	to	Snowden,	our	e-mail,	text,	and	phone	metadata	is	being
collected	by	the	NSA	and	other	agencies.	But	the	government	can’t	collect
metadata	from	everyone—or	can	it?	Technically,	no.	However,	there’s	been	a
sharp	rise	in	“legal”	collection	since	2001.
Authorized	under	the	US	Foreign	Intelligence	Surveillance	Act	of	1978
(FISA),	the	US	Foreign	Intelligence	Surveillance	Court	(known	as	FISC,	or	the
FISA	Court)	oversees	all	requests	for	surveillance	warrants	against	foreign
individuals	within	the	United	States.	On	the	surface	it	seems	reasonable	that	a
court	order	would	stand	between	law	enforcement	and	an	individual.	The
reality	is	somewhat	different.	In	2012	alone,	1,856	requests	were	presented,
and	1,856	requests	were	approved,	suggesting	that	the	process	today	is	largely
a	rubber-stamp	approval	operation	for	the	US	government.
9
	After	the	FISA
Court	grants	a	request,	law	enforcement	can	compel	private	corporations	to
turn	over	all	their	data	on	you—that	is,	if	they	haven’t	already	done	so.
To	become	truly	invisible	in	the	digital	world	you	will	need	to	do	more	than
encrypt	your	messages.	You	will	need	to:
Remove	your	true	IP	address
:	This	is	your	point	of	connection	to	the
Internet,	your	fingerprint.	It	can	show	where	you	are	(down	to	your
physical	address)	and	what	provider	you	use.
Obscure	your	hardware	and	software
:	When	you	connect	to	a	website
online,	a	snapshot	of	the	hardware	and	software	you’re	using	may	be
collected	by	the	site.	There	are	tricks	that	can	be	used	to	find	out	if	you
have	particular	software	installed,	such	as	Adobe	Flash.	The	browser
software	tells	a	website	what	operating	system	you’re	using,	what

version	of	that	operating	system	you	have,	and	sometimes	what	other
software	you	have	running	on	your	desktop	at	the	time.
Defend	your	anonymity
:	Attribution	online	is	hard.	Proving	that	you	were
at	the	keyboard	when	an	event	occurred	is	difficult.	However,	if	you
walk	in	front	of	a	camera	before	going	online	at	Starbucks,	or	if	you
just	bought	a	latte	at	Starbucks	with	your	credit	card,	these	actions	can
be	linked	to	your	online	presence	a	few	moments	later.
As	we’ve	learned,	every	time	you	connect	to	the	Internet,	there’s	an	IP	address
associated	with	that	connection.
10
	This	is	problematic	if	you’re	trying	to	be
invisible	online:	you	might	change	your	name	(or	not	give	it	at	all),	but	your	IP
address	will	still	reveal	where	you	are	in	the	world,	what	provider	you	use,	and
the	identity	of	the	person	paying	for	the	Internet	service	(which	may	or	may
not	be	you).	All	these	pieces	of	information	are	included	within	the	e-mail
metadata	and	can	later	be	used	to	identify	you	uniquely.	Any	communication,
whether	it’s	e-mail	or	not,	can	be	used	to	identify	you	based	on	the	Internal
Protocol	(IP)	address	that’s	assigned	to	the	router	you	are	using	while	you	are
at	home,	work,	or	a	friend’s	place.
IP	addresses	in	e-mails	can	of	course	be	forged.	Someone	might	use	a
proxy	address—not	his	or	her	real	IP	address	but	someone	
else’s—so	that	an	e-
mail	appears	to	originate	from	another	location.	A	proxy	is	like	a	foreign-
language	translator—you	speak	to	the	translator,	and	the	translator	speaks	to
the	foreign-language	speaker—only	the	message	remains	exactly	the	same.
The	point	here	is	that	someone	might	use	a	proxy	from	China	or	even
Germany	to	evade	detection	on	an	e-mail	that	really	comes	from	North	Korea.
Instead	of	hosting	your	own	proxy,	you	can	use	a	service	known	as	an
anonymous	remailer,	which	will	mask	your	e-mail’s	IP	address	for	you.	An
anonymous	remailer	simply	changes	the	e-mail	address	of	the	sender	before
sending	the	message	to	its	intended	recipient.	The	recipient	can	respond	via	the
remailer.	That’s	the	simplest	version.
There	are	also	variations.	Some	type	I	and	type	II	remailers	do	not	allow
you	to	respond	to	e-mails;	they	are	simply	one-way	correspondence.	Type	III,
or	Mixminion,	remailers	do	offer	a	full	suite	of	services:	responding,
forwarding,	and	encryption.	You	will	need	to	find	out	which	service	your
remailer	supplies	if	you	choose	this	method	of	anonymous	correspondence.
One	way	to	mask	your	IP	address	is	to	use	the	onion	router	(Tor),	which	is
what	Snowden	and	Poitras	did.

Developed	by	the	US	Naval	Research	Laboratory	in	2004	as	a	way	for
military	personnel	to	conduct	searches	without	exposing	their	physical
locations,	the	Tor	open-source	program	has	since	been	expanded.	Tor	is
designed	to	be	used	by	people	living	in	harsh	regimes	as	a	way	to	avoid
censorship	of	popular	media	and	services	and	to	prevent	anyone	from	tracking
what	search	terms	they	use.	Tor	remains	free	and	can	be	used	by	anyone,
anywhere—even	you.
How	does	Tor	work?	It	upends	the	usual	model	for	accessing	a	website.
Usually	when	you	go	online	you	open	an	Internet	browser	and	type	in	the
name	of	the	site	you	want	to	visit.	A	request	goes	out	to	that	site,	and
milliseconds	later	a	response	comes	back	to	your	
browser	with	the	website
page.	The	website	knows—based	on	the	IP	address—who	the	service	provider
is,	and	sometimes	even	where	in	the	world	you	are	located,	based	on	where	the
service	provider	is	located	or	the	latency	of	the	hops	from	your	device	to	the
site.	For	example,	if	your	device	says	it	is	in	the	United	States,	but	the	time	and
number	of	hops	your	request	takes	to	reach	its	destination	suggest	you	are
somewhere	else	in	the	world,	some	sites—gaming	sites,	in	particular—will
detect	that	as	possible	fraud.
When	you	use	Tor,	the	direct	line	between	you	and	your	target	website	is
obscured	by	additional	nodes,	and	every	ten	seconds	the	chain	of	nodes
connecting	you	to	whatever	site	you	are	looking	at	changes	without	disruption
to	you.	The	various	nodes	that	connect	you	to	a	site	are	like	layers	within	an
onion.	In	other	words,	if	someone	were	to	backtrack	from	the	destination
website	and	try	to	find	you,	they’d	be	unable	to	because	the	path	would	be
constantly	changing.	Unless	your	entry	point	and	your	exit	point	become
associated	somehow,	your	connection	is	considered	anonymous.
When	you	use	Tor,	your	request	to	open	a	page—say,	mitnicksecurity.com
—is	not	sent	directly	to	that	server	but	first	to	another	Tor	node.	And	just	to
make	things	even	more	complicated,	that	node	then	passes	the	request	to
another	node,	which	finally	connects	to	mitnicksecurity.com.	So	there’s	an
entry	node,	a	node	in	the	middle,	and	an	exit	node.	If	I	were	to	look	at	who	was
visiting	my	company	site,	I	would	only	see	the	IP	address	and	information
from	the	exit	node,	the	last	in	the	chain,	and	not	the	first,	your	entry	node.	You
can	configure	Tor	so	it	uses	exit	nodes	in	a	particular	country,	such	as	Spain,
or	even	a	specific	exit	node,	perhaps	in	Honolulu.
To	use	Tor	you	will	need	the	modified	Firefox	browser	from	the	Tor	site
(torproject.org).	Always	look	for	legitimate	Tor	browsers	for	your	operating

system	from	the	Tor	project	website.	Do	not	use	a	third-party	site.	For	Android
operating	systems,	Orbot	is	a	legitimate	
free	Tor	app	from	Google	Play	that
both	encrypts	your	traffic	and	obscures	your	IP	address.
11
	On	iOS	devices
(iPad,	iPhone),	install	the	Onion	Browser,	a	legitimate	app	from	the	iTunes	app
store.
You	might	be	thinking,	why	doesn’t	someone	just	build	an	e-mail	server
within	Tor?	Someone	did.	Tor	Mail	was	a	service	hosted	on	a	site	accessible
only	to	Tor	browsers.	However,	the	FBI	seized	that	server	in	an	unrelated	case
and	therefore	gained	access	to	all	the	encrypted	e-mail	stored	on	Tor	Mail.
This	is	a	cautionary	tale	showing	that	even	when	you	think	your	information	is
safe,	foolproof,	it	probably	isn’t.
12
Although	Tor	uses	a	special	network,	you	can	still	access	the	Internet	from
it,	but	the	pages	are	much	slower	to	load.	However,	in	addition	to	allowing	you
to	surf	the	searchable	Internet,	Tor	gives	you	access	to	a	world	of	sites	that	are
not	ordinarily	searchable—what’s	called	the	Dark	Web.	These	are	sites	that
don’t	resolve	to	common	names	such	as	Google.com	and	instead	end	with	the
.onion	extension.	Some	of	these	hidden	sites	offer,	sell,	or	provide	items	and
services	that	may	be	illegal.	Some	of	them	are	legitimate	sites	maintained	by
people	in	oppressed	parts	of	the	world.
It	should	be	noted,	however,	that	there	are	several	weaknesses	with	Tor:
	You	have	no	control	over	the	exit	nodes,	which	may	be	under	the	control
of	government	or	law	enforcement
13
	You	can	still	be	profiled	and	possibly	identified
14
	Tor	is	very	slow
That	being	said,	if	you	still	decide	to	use	Tor	you	should	not	run	it	in	the
same	physical	device	that	you	use	for	browsing.	In	other	words,	have	a	laptop
for	browsing	the	Web	and	a	separate	device	for	Tor	(for	instance,	a	Raspberry
Pi	minicomputer	running	Tor	software).	The	
idea	here	is	that	if	somebody	is
able	to	compromise	your	laptop	they	still	won’t	be	able	to	peel	off	your	Tor
transport	layer	as	it	is	running	on	a	separate	physical	box.
15
In	the	case	of	Snowden	and	Poitras,	as	I	said,	simply	connecting	to	each	other
over	encrypted	e-mail	wasn’t	good	enough.	After	Poitras	created	a	new	public

key	for	her	anonymous	e-mail	account,	she	could	have	sent	it	to	Snowden’s
previous	e-mail	address,	but	if	someone	were	watching	that	account,	then	her
new	identity	would	be	exposed.	A	very	basic	rule	is	that	you	have	to	keep	your
anonymous	accounts	completely	separate	from	anything	that	could	relate	back
to	your	true	identity.
To	be	invisible	you	will	need	to	start	with	a	clean	slate	for	each	new	secure
contact	you	make.	Legacy	e-mail	accounts	might	be	connected	in	various	ways
to	other	parts	of	your	life—friends,	hobbies,	work.	To	communicate	in
secrecy,	you	will	need	to	create	new	e-mail	accounts	using	Tor	so	that	the	IP
address	setting	up	the	account	is	not	associated	with	your	real	identity	in	any
way.
Creating	anonymous	e-mail	addresses	is	challenging	but	possible.
There	are	private	e-mail	services	you	can	use.	Since	you	will	leave	a	trail	if
you	pay	for	those	services,	you’re	actually	better	off	using	a	free	Web	service.
A	minor	hassle:	Gmail,	Microsoft,	Yahoo,	and	others	require	you	to	supply	a
phone	number	to	verify	your	identify.	Obviously	you	can’t	use	your	real	cell-
phone	number,	since	it	may	be	connected	to	your	real	name	and	real	address.
You	might	be	able	to	set	up	a	Skype	phone	number	if	it	supports	voice
authentication	instead	of	SMS	authentication;	however,	you	will	still	need	an
existing	e-mail	account	and	a	prepaid	gift	card	to	set	up	a	Skype	number.
16
	If
you	think	using	a	prepaid	cell	phone	in	and	of	itself	will	protect	your
anonymity,	you’re	wrong.	If	you’ve	ever	used	a	prepaid	phone	to	make	calls
associated	with	your	real	identity,	it’s	child’s	play	to	discover	who	you	are.
Instead	you’ll	want	to	use	a	disposable	phone.	Some	people	think	of	burner
phones	as	devices	used	only	by	terrorists,	pimps,	and	drug	
dealers,	but	there
are	plenty	of	perfectly	legitimate	uses	for	them.	For	example,	a	business
reporter,	after	having	her	garbage	gone	through	by	private	investigators	hired
by	Hewlett-Packard,	who	was	eager	to	find	out	who	might	be	leaking	critical
board-of-directors	information,	switched	over	to	burner	phones	so	that	the
private	investigators	would	have	a	harder	time	identifying	her	calls.	After	that
experience	she	only	spoke	to	her	source	on	that	burner	phone.
17
Similarly,	a	woman	who	is	avoiding	an	abusive	ex	might	gain	a	little	peace
of	mind	by	using	a	phone	that	doesn’t	require	a	contract	or,	for	that	matter,	a
Google	or	an	Apple	account.	A	burner	phone	typically	has	few	or	very	limited
Internet	capabilities.	Burner	phones	mostly	provide	voice,	text,	and	e-mail
service,	and	that’s	about	all	some	people	need.	You,	however,	should	also	get
data	because	you	can	tether	this	burner	phone	to	your	laptop	and	use	it	to	surf

the	Internet.	(
Here
	I	tell	you	how	to	change	the	media	access	control—MAC—
address	on	your	laptop	so	that	each	time	you	tether	with	a	burner	phone	it
appears	to	be	new	device.)
However,	purchasing	a	burner	phone	anonymously	will	be	tricky.	Actions
taken	in	the	real	world	can	be	used	to	identify	you	in	the	virtual	world.	Sure,	I
could	walk	into	Walmart	and	pay	cash	for	a	burner	phone	and	one	hundred
minutes	of	airtime.	Who	would	know?	Well,	lots	of	people	would.
First,	how	did	I	get	to	Walmart?	Did	I	take	an	Uber	car?	Did	I	take	a	taxi?
These	records	can	all	be	subpoenaed.
I	could	drive	my	own	car,	but	law	enforcement	uses	automatic	license	plate
recognition	technology	(ALPR)	in	large	public	parking	lots	to	look	for
missing	and	stolen	vehicles	as	well	as	people	on	whom	there	are	outstanding
warrants.	The	ALPR	records	can	be	subpoenaed.
Even	if	I	walked	to	Walmart,	once	I	entered	the	store	my	face	would	be
visible	on	several	security	cameras	within	the	store	itself,	and	that	video	can	be
subpoenaed.
Okay,	so	let’s	say	I	send	someone	else	to	the	store—someone	I	don’t	know,
maybe	a	homeless	person	I	hired	on	the	spot.	That	person	walks	in	and	buys	the
phone	and	several	data	refill	cards	with	cash.	That	would	be	the	safest
approach.	Maybe	you	arrange	to	meet	this	person	later	away	from	the	store.
This	would	help	physically	distance	yourself	from	the	actual	sales	transaction.
In	this	case	the	weakest	link	could	still	be	the	person	you	sent—how
trustworthy	is	he?	If	you	pay	him	more	than	the	value	of	the	phone,	he	will
probably	be	happy	to	deliver	the	phone	as	promised.
Activation	of	the	prepaid	phone	requires	either	calling	the	mobile
operator’s	customer	service	department	or	activating	it	on	the	provider’s
website.	To	avoid	being	recorded	for	“quality	assurance,”	it’s	safer	to	activate
over	the	Web.	Using	Tor	over	an	open	wireless	network	after	you’ve	changed
your	MAC	address	should	be	the	minimum	safeguards.	You	should	make	up	all
the	subscriber	information	you	enter	on	the	website.	For	your	address,	just
Google	the	address	of	a	major	hotel	and	use	that.	Make	up	a	birth	date	and	PIN
that	you’ll	remember	in	case	you	need	to	contact	customer	service	in	the
future.
There	are	e-mail	services	that	don’t	require	verification,	and	if	you	don’t
need	to	worry	about	authorities,	Skype	numbers	work	well	for	Google	account
registration	and	similar	stuff,	but	for	the	sake	of	illustration,	let’s	say	that	after
using	Tor	to	randomize	your	IP	address,	and	after	creating	a	Gmail	account

that	has	nothing	to	do	with	your	real	phone	number,	Google	sends	your	phone
a	verification	code	or	a	voice	call.	Now	you	have	a	Gmail	account	that	is
virtually	untraceable.
So	we	have	an	anonymous	e-mail	address	established	using	familiar	and
common	services.	We	can	produce	reasonably	secure	e-mails	whose	IP	address
—thanks	to	Tor—is	anonymous	(although	you	don’t	have	control	over	the	exit
nodes)	and	whose	contents,	thanks	to	PGP,	can’t	be	read	except	by	the	intended
recipient.
Note	that	to	keep	this	account	anonymous	you	can	only	access	the	
account
from	within	Tor	so	that	your	IP	address	will	never	be	associated	with	it.
Further,	you	should	never	perform	any	Internet	searches	while	logged	in	to
that	anonymous	Gmail	account;	you	might	inadvertently	search	for	something
that	is	related	to	your	true	identity.	Even	searching	for	weather	information
could	reveal	your	location.
18
As	you	can	see,	becoming	invisible	and	keeping	yourself	invisible	require
tremendous	discipline	and	perpetual	diligence.	But	it	is	worth	it	in	order	to	be
invisible.
The	most	important	takeaways	are:	first,	be	aware	of	all	the	ways	that
someone	can	identify	you	even	if	you	undertake	some	but	not	all	of	the
precautions	I’ve	described.	And	if	you	do	undertake	all	these	precautions,
know	that	you	need	to	perform	due	diligence	every	time	you	use	your
anonymous	accounts.	No	exceptions.
It’s	also	worth	reiterating	that	end-to-end	encryption—keeping	your
message	unreadable	and	secure	until	it	reaches	the	recipient	as	opposed	to
simply	encrypting	it—is	very	important.	End-to-end	encryption	can	be	used	for
other	purposes,	such	as	encrypted	phone	calls	and	instant	messaging,	which
we’ll	discuss	in	the	next	two	chapters.

CHAPTER	THREE
Wiretapping	101
You	spend	countless	hours	on
	your	cell	phone	every	day,	chatting,
texting,	surfing	the	Internet.	But	do	you	actually	know	how	your	cell	phone
works?
Cellular	service,	which	we	use	on	our	mobile	devices,	is	wireless	and	relies
upon	cellular	towers,	or	base	stations.	To	maintain	connectivity,	cell	phones
continually	send	out	tiny	beacons	to	the	tower	or	towers	physically	closest	to
them.	The	signal	response	to	those	beacons	from	the	towers	translates	into	the
number	of	“bars”	you	have—no	bars,	no	signal.
To	protect	the	identity	of	the	user	somewhat,	these	beacons	from	your	cell
phone	use	what	is	known	as	international	mobile	subscriber	identity,	or	IMSI,	a
unique	number	assigned	to	your	SIM	card.	This	was	originally	from	the	time
when	cellular	networks	needed	to	know	when	you	were	on	their	towers	and
when	you	were	roaming	(using	other	carriers’	cell	towers).	The	first	part	of
the	IMSI	code	uniquely	identifies	the	mobile	network	operator,	and	the
remaining	part	identifies	your	mobile	phone	to	that	network	operator.
Law	enforcement	has	created	devices	that	pretend	to	be	cellular	base
stations.	These	are	designed	to	intercept	voice	and	text	messages.	
In	the	United
States,	law	enforcement	and	intelligence	agencies	also	use	other	devices	to
catch	IMSIs	(see	
here
).	The	IMSI	is	captured	instantly,	in	less	than	a	second,	and
without	warning.	Typically	IMSI	catchers	are	used	at	large	rallies,	allowing
law	enforcement	to	later	identify	who	was	in	attendance,	particularly	if	those

individuals	were	actively	calling	others	to	join	in.
Devices	like	these	can	also	be	used	by	commuting	services	and	apps	to	create
traffic	reports.	Here	the	actual	account	number,	or	IMSI,	doesn’t	matter,	only
how	fast	your	cell	phone	moves	from	tower	to	tower	or	geographic	region	to
geographic	region.	The	amount	of	time	it	takes	a	cell	phone	to	come	and	go
from	each	tower	determines	the	traffic	status:	red,	yellow,	or	green.
1
Your	mobile	device	connects	to	a	series	of	cellular	towers	whenever	it’s
powered	up.	The	closest	tower	actually	handles	your	call,	text,	or	Internet
session.	As	you	move	around,	your	phone	pings	the	nearest	tower	and,	if
necessary,	your	call	moves	from	tower	to	tower,	all	the	while	maintaining
consistency.	The	other	nearby	towers	are	all	on	standby,	so	that	if	you	move
from	point	A	to	point	B	and	another	tower	comes	into	range	for	a	better	signal,
then	the	handoff	is	smooth	and	you	shouldn’t	experience	a	dropped	call.
Suffice	it	to	say	that	your	mobile	device	emits	a	unique	sequence	that	is
logged	on	a	number	of	individual	cellular	towers.	So	anyone	looking	at	the
logs	of	a	specific	tower	would	see	the	temporary	mobile	subscriber	identity
(TMSI)	of	all	the	people	in	the	general	area	at	any	given	moment,	whether	they
made	calls	or	not.	Law	enforcement	can	and	does	request	this	information
from	cellular	carriers,	including	the	back-end	account	identities	of	specific
holders.
Ordinarily,	if	you	look	at	just	one	cell	tower’s	log,	the	data	might	only
show	that	someone	was	passing	through	and	that	his	or	her	device	contacted	a
specific	cell	tower	as	a	standby.	If	a	call	was	made	or	if	data	was	exchanged,
there	would	also	be	a	record	of	that	call	and	its	duration.
Data	from	multiple	cell-tower	logs,	however,	can	be	used	to	geographically
pinpoint	a	user.	Most	mobile	devices	ping	three	or	more	towers	at	a	time.
Using	logs	from	those	cell	towers,	someone	can	triangulate,	based	on	the
relative	strength	of	each	ping,	a	fairly	exact	location	of	the	phone’s	user.	So	the
phone	you	carry	around	every	day	is	essentially	a	tracking	device.
How	can	you	avoid	being	tracked?
Signing	a	contract	with	a	cell-phone	carrier	requires	a	name,	address,	and	a
Social	Security	number.	Additionally,	there’s	a	credit	check	to	make	sure	you
can	pay	your	monthly	bill.	You	can’t	avoid	this	if	you	go	with	a	commercial
carrier.
A	burner	phone	seems	like	a	reasonable	option.	A	prepaid	cell	phone,
perhaps	one	that	you	replace	frequently	(say,	weekly	or	even	monthly),	avoids
leaving	much	of	a	trail.	Your	TMSI	will	show	up	on	cell	tower	logs,	then

disappear.	If	you	purchased	the	phone	discreetly,	it	won’t	be	traceable	back	to	a
subscriber	account.	Prepaid	cell	services	are	still	subscriber	accounts,	so	the
IMSI	will	always	be	assigned	to	an	account.	Therefore,	a	person’s	anonymity
depends	on	how	he	or	she	acquired	the	burner	device.
For	the	sake	of	argument,	let’s	assume	you	have	successfully	disconnected
yourself	from	the	purchase	of	a	burner	phone.	You	followed	the	steps	outlined
here
	and	used	a	person	unrelated	to	you	to	purchase	the	phone	for	cash.	Is	the
use	of	that	disposable	phone	untraceable?	The	short	answer	is	no.
Here’s	a	cautionary	tale:	one	afternoon	in	2007,	a	$500	million	container
loaded	with	the	drug	ecstasy	went	missing	from	a	port	in	Melbourne,	Australia.
The	owner	of	the	container,	Pat	Barbaro,	a	known	drug	dealer,	reached	into	his
pocket,	pulled	out	one	of	his	twelve	cell	phones,	and	dialed	the	number	of	a
local	reporter,	Nick	McKenzie,	who	would	only	know	the	caller	by	the	name
Stan.
Barbaro	would	later	use	his	other	burner	phones	to	text	McKenzie,
attempting	to	anonymously	obtain	information	from	the	investigative	reporter
about	the	missing	container.	As	we	will	see,	this	didn’t	work.
Burner	phones,	despite	what	many	people	may	think,	are	not	truly
anonymous.	Under	the	US	Communications	Assistance	for	Law	Enforcement
Act	(CALEA),	all	IMSIs	connected	with	burner	phones	are	reported,	just	as
those	subscribers	under	contract	with	major	carriers	are.	In	other	words,	a	law
enforcement	official	can	spot	a	burner	phone	from	a	log	file	just	as	easily	as
he	can	spot	a	registered	contract	phone.	While	the	IMSI	won’t	identify	who
owns	the	phone,	patterns	of	usage	might.
In	Australia,	where	CALEA	does	not	exist,	law	enforcement	was	still	able	to
keep	tabs	on	Barbaro’s	many	phones	using	rather	traditional	methods.	For
instance,	they	might	have	noticed	a	call	made	with	his	personal	phone	and	then
a	few	seconds	later	seen	in	the	log	files	another	call	or	text	from	one	of	his
burner	phones	in	the	same	cell	site.	Over	time,	the	fact	that	these	IMSIs	more
often	than	not	appeared	together	on	the	same	cell	sites	might	suggest	that	they
belonged	to	a	single	individual.
The	problem	with	Barbaro’s	having	many	cell	phones	at	his	disposal	was
that	no	matter	which	phone	he	used,	personal	or	burner,	so	long	as	he	stayed	in
the	same	spot,	the	signal	would	hit	the	same	cellular	tower.	The	burner-phone
calls	always	appeared	next	to	his	registered-phone	calls.	The	registered	phone,
listed	in	his	name	with	a	carrier,	was	entirely	traceable	and	helped	law
enforcement	identify	him.	It	established	a	solid	case	against	him,	particularly

because	this	pattern	was	repeated	at	other	locations.	This	helped	Australian
authorities	convict	Barbaro	of	orchestrating	one	of	the	largest	ecstasy
shipments	in	Australia’s	history.
McKenzie	concluded,	“Ever	since	the	phone	buzzed	that	day	in	
my	pocket,
and	‘Stan’	briefly	entered	my	life,	I’ve	been	especially	conscious	about	how	a
person’s	communications	leave	a	trail,	no	matter	how	careful	they	are.”
2
You	could,	of	course,	have	only	a	burner	phone.	This	would	mean	that	you
would	need	to	purchase	additional	minutes	anonymously	using	prepaid	cards
or	Bitcoin	from	time	to	time,	which	you	can	do	by	using	an	open	Wi-Fi	safely
after	changing	your	media	access	control	(MAC)	address	on	your	wireless
card	(see	
here
),	and	being	out	of	any	camera	view.	Or	you	could,	as	suggested
in	the	previous	chapter,	hire	a	stranger	to	pay	cash	at	the	store	to	purchase	the
prepaid	phone	and	several	refill	cards.
3
	This	adds	cost	and	perhaps
inconvenience,	but	you	would	have	an	anonymous	phone.
Although	it	may	seem	brand	new,	cellular	technology	is	more	than	forty	years
old,	and	it,	like	copper-wire	telephone	systems,	contains	legacy	technologies
that	can	compromise	your	privacy.
Each	generation	of	cell-phone	technology	has	offered	new	features,	mostly
intended	to	move	more	data	more	efficiently.	First-generation	phones,	or	1G,
had	the	telephone	technology	available	in	the	1980s.	These	early	1G	networks
and	handsets	were	analog-based,	and	they	used	a	variety	of	now	discontinued
mobile	standards.	In	1991,	the	second-generation	(2G)	digital	network	was
introduced.	This	2G	network	offered	two	standards:	global	system	for	mobile
communications	(GSM)	and	code	division	multiple	access	(CDMA).	It	also
introduced	short	message	service	(SMS),	unstructured	supplementary	services
data	(USSD),	and	other	simple	communications	protocols	that	are	still	in	use
today.	We’re	currently	in	the	middle	of	4G/LTE	and	on	the	way	toward	5G.
No	matter	what	generation	of	technology	a	given	carrier	is	using	(2G,	3G,
4G,	or	4G/LTE),	there	is	an	underlying	international	signal	protocol	known	as
the	signaling	system.	The	signaling	system	
protocol	(currently	in	version	7),
among	other	things,	keeps	mobile	calls	connected	when	you	drive	along	a
freeway	and	switch	from	cell	tower	to	cell	tower.	It	can	also	be	used	for
surveillance.	Signaling	system	7	(SS7)	does	basically	everything	necessary	to
route	a	call,	such	as:

	Setting	up	a	new	connection	for	a	call
	Tearing	down	that	connection	when	the	call	ends
	Billing	the	appropriate	party	making	the	call
	Managing	extra	features	such	as	call-forwarding,	calling	party	name	and
number	display,	three-way	calling,	and	other	Intelligent	Network	(IN)
services
	Toll-free	(800	and	888)	as	well	as	toll	(900)	calls
	Wireless	services,	including	subscriber	identification,	carrier,	and
mobile	roaming
Speaking	at	the	Chaos	Communication	Congress,	an	annual	computer
hacker	conference	held	in	Berlin,	Germany,	Tobias	Engel,	founder	of
Sternraute,	and	Karsten	Nohl,	chief	scientist	for	Security	Research	Labs,
explained	that	they	could	not	only	locate	cell-phone	callers	anywhere	in	the
world,	they	could	also	listen	in	on	their	phone	conversations.	And	if	they
couldn’t	listen	in	real	time,	they	could	record	the	encrypted	calls	and	texts	for
later	decryption.
In	security,	you	are	only	as	secure	as	the	weakest	link.	What	Engel	and	Nohl
found	was	that	while	developed	countries	in	North	America	and	Europe	have
invested	billions	in	creating	relatively	secure	and	private	3G	and	4G	networks,
they	must	still	use	signaling	system	7	(SS7)	as	an	underlying	protocol.
SS7	handles	the	process	for	call-establishment,	billing,	routing,	and
information-exchange	functions.	Which	means	if	you	can	tap	into	SS7,	you	can
manipulate	the	call.	SS7	allows	an	attacker	to	use	a	small	carrier	in,	say,
Nigeria	to	access	calls	made	in	Europe	or	the	
United	States.	“It’s	like	you
secure	the	front	door	of	the	house,	but	the	back	door	is	wide	open,”	said	Engel.
The	two	researchers	tested	a	method	in	which	an	attacker	uses	a	phone’s
call-forwarding	function	and	SS7	to	forward	a	target’s	outgoing	calls	to
himself	before	conferencing	(three-way	calling)	in	their	intended	recipient.
Once	the	attacker	has	established	himself,	he	can	listen	to	all	calls	made	by	the
targeted	individual	from	any	place	on	earth.
Another	strategy	would	be	for	the	attacker	to	set	up	radio	antennas	to
collect	all	cellular	calls	and	texts	within	a	given	area.	For	any	encrypted	3G
calls,	the	attacker	could	ask	SS7	to	provide	him	with	the	proper	decryption	key.
“It’s	all	automated,	at	the	push	of	a	button,”	Nohl	said.	“It	would	strike	me
as	a	perfect	spying	capability,	to	record	and	decrypt	pretty	much	any

network…	Any	network	we	have	tested,	it	works.”
4
	He	then	enumerated	almost
every	major	carrier	in	North	America	and	Europe,	around	twenty	in	all.
Nohl	and	Engel	also	found	that	they	could	locate	any	cell-phone	user	by
using	an	SS7	function	called	an	anytime	interrogation	query.	That	is,	they
could	do	so	until	the	function	was	shut	down	early	in	2015.	However,	since	all
carriers	must	track	their	users	in	order	to	provide	service,	SS7	provides	other
functions	that	still	allow	some	remote	surveillance.	It	should	be	noted	that	the
specific	flaws	identified	by	Nohl	and	Engel	have	been	mostly	mitigated	by	the
carriers	since	their	research	went	public.
You	might	think	that	encryption	alone	would	help	keep	cell-phone	calls
private.	Beginning	with	2G,	GSM-based	phone	calls	have	been	encrypted.
However,	the	initial	methods	used	to	encrypt	calls	in	2G	were	weak	and
eventually	broke	down.	Unfortunately,	the	cost	of	upgrading	cellular	networks
to	3G	proved	prohibitive	for	many	carriers,	so	a	weakened	2G	remained	in	use
until	around	2010	or	so.
In	the	summer	of	2010,	a	team	of	researchers	led	by	Nohl	divided	all	the
possible	encryption	keys	used	by	2G	GSM	networks	among	
themselves	and
crunched	the	numbers	to	produce	what’s	called	a	rainbow	table,	a	list	of
precomputed	keys	or	passwords.	They	published	the	table	to	show	carriers
around	the	world	just	how	insecure	2G	encryption	using	GSM	is.	Each	packet
—or	unit	of	data	between	source	and	destination—of	voice,	text,	or	data	sent
over	2G	GSM	could	be	decrypted	in	just	a	few	minutes	using	the	published
table	of	keys.
5
	This	was	an	extreme	example,	but	the	team	considered	it
necessary;	when	Nohl	and	others	had	previously	presented	their	findings	to	the
carriers,	their	warnings	fell	on	deaf	ears.	By	demonstrating	how	they	could
crack	2G	GSM	encryption,	they	more	or	less	forced	the	carriers	to	make	the
change.
It	is	important	to	note	that	2G	still	exists	today,	and	carriers	are	considering
selling	access	to	their	old	2G	networks	for	use	in	Internet	of	Things	devices
(devices	other	than	computers	that	connect	to	the	Internet,	such	as	your	TV	and
refrigerator),	which	only	need	occasional	data	transmission.	If	this	happens,
we	will	need	to	make	sure	the	devices	themselves	have	end-to-end	encryption
because	we	know	that	2G	will	not	provide	strong	enough	encryption	by	itself.
Of	course	eavesdropping	existed	before	mobile	devices	really	took	off.	For
Anita	Busch,	the	nightmare	started	the	morning	of	June	20,	2002,	when	she
awoke	to	a	neighbor’s	urgent	knock	on	her	door.	Someone	had	put	a	bullet

hole	in	the	windshield	of	her	car	as	it	sat	in	the	driveway.	Not	only	that,
someone	had	also	left	Busch	a	rose,	a	dead	fish,	and	a	one-word	note
—“Stop”—on	the	car’s	hood.
6
	Later	she	would	learn	that	her	phones	had	been
tapped,	and	not	by	law	enforcement.
The	fact	that	the	scene	with	a	bullet	hole	and	a	dead	fish	was	reminiscent	of
a	bad	Hollywood	gangster	movie	made	some	sense.	Busch,	a	seasoned
reporter,	was	at	the	time	only	a	few	weeks	into	a	freelance	assignment
chronicling	organized	crime’s	growing	influence	in	Hollywood	for	the	
Los
Angeles	Times
.	She	was	researching	
Steven	Seagal	and	his	former	business
partner,	Julius	R.	Nasso,	who	had	been	indicted	for	conspiring	with	the	New
York	Mafia	to	extort	money	from	Seagal.
7
What	followed	finding	the	note	on	her	car	was	a	series	of	phone	messages.
The	caller	apparently	wanted	to	share	some	information	about	Seagal.	Much
later	Busch	learned	that	the	caller	had	been	hired	by	Anthony	Pellicano,	a
former	high-profile	Los	Angeles	private	investigator	who	at	the	time	Busch’s
car	was	tampered	with	was	already	suspected	by	the	FBI	of	illegal	wiretapping,
bribery,	identity	theft,	and	obstruction	of	justice.	Busch’s	copper-wire	phone
had	been	tapped	by	Pellicano,	who	knew	by	eavesdropping	on	her	calls	that	she
was	writing	a	newspaper	story	about	his	clients.	The	fish	head	on	her	car	was
an	attempt	to	warn	her	off.
Typically	wiretapping	is	only	associated	with	phone	calls,	but	wiretapping
laws	in	the	United	States	can	also	cover	eavesdropping	on	e-mail	and	instant
messages.	For	the	moment	I’ll	focus	on	wiretapping’s	traditional	use,	in
copper-wire	landlines.
Landlines	are	the	hardwired	phones	in	your	home	or	business,	and
wiretapping	involves	literally	tapping	into	the	live	wire.	Back	in	the	day,	phone
companies	each	had	physical	banks	of	switches	on	which	they	performed	a
version	of	wiretapping.	What	that	means	is	that	the	phone	company	had	special
appliances	that	the	frame	techs	hooked	up	to	the	target	phone	number	on	the
mainframe	in	the	central	office.	There	is	additional	wiretapping	equipment	that
dials	into	this	appliance	and	is	used	to	monitor	the	target.	Today,	that	way	of
eavesdropping	is	retired:	phone	companies	are	all	required	to	implement	the
technical	requirements	mandated	by	CALEA.
Although	a	growing	number	of	people	today	have	shifted	to	mobile	phones,
many	still	retain	their	landlines	for	their	copper-wire	dependability.	Others	use
what’s	called	Voice	over	Internet	Protocol	(VoIP)	technology,	which	is
telephony	over	the	Internet	and	usually	bundled	in	the	home	or	office	with	your

cable	or	Internet	service.	
Whether	it’s	a	physical	switch	at	the	phone	company
or	a	digital	switch,	law	enforcement	does	have	the	ability	to	eavesdrop	on	calls.
The	1994	CALEA	requires	telecommunications	manufacturers	and	carriers
to	modify	their	equipment	for	the	purposes	of	allowing	law	enforcement	to
wiretap	the	line.	So	under	CALEA,	any	landline	call	in	the	United	States	is
theoretically	subject	to	interception.	And	under	CALEA,	all	law	enforcement
access	requires	a	Title	III	warrant.	That	said,	it’s	still	illegal	for	an	ordinary
citizen	to	conduct	a	wiretap,	which	is	what	Anthony	Pellicano	did	to	covertly
monitor	Anita	Busch	and	others.	His	list	of	eavesdropping	victims	happens	to
include	Hollywood	celebrities	such	as	Sylvester	Stallone,	David	Carradine,	and
Kevin	Nealon,	among	others.
His	list	of	wiretap	victims	also	includes	my	friend	Erin	Finn,	because	her
ex-boyfriend	was	obsessed	with	her	and	wanted	to	track	her	every	move.
Because	her	phone	line	had	been	tapped,	I,	too,	was	monitored	when	I	called
her.	The	coolest	part	of	the	saga	is	that	AT&T	paid	me	thousands	of	dollars	as
part	of	a	class-action	settlement	because	of	Pellicano’s	wiretapping	of	my	calls
to	Finn.	Which	is	somewhat	ironic,	because	on	another	occasion,	I	was	the	one
doing	the	tapping.	Pellicano’s	purpose	in	wiretapping	people	was	perhaps
more	malicious	than	mine;	he	was	trying	to	intimidate	witnesses	into	either	not
testifying	or	testifying	in	a	certain	way.
Back	in	the	mid-1990s,	a	wiretap	had	to	be	installed	by	technicians.	So
Pellicano,	or	one	of	his	people,	had	to	hire	someone	who	worked	at	PacBell	to
tap	Busch’s	and	Finn’s	telephone	lines.	The	technicians	were	able	to	set	up
extensions	of	the	target	phones	at	Pellicano’s	office,	in	Beverly	Hills.	In	this
case	there	were	no	taps	done	at	the	junction	box,	or	the	terminal	at	the	side	of
the	house	or	apartment	complex,	although	that	is	also	possible.
8
As	you	may	recall	from	reading	my	previous	book	
Ghost	in	the	Wires,
	I
once	drove	down	from	my	father’s	apartment	in	Calabasas	to	Long	Beach	to
set	up	a	physical	wiretap	on	a	phone	line	used	by	Kent,	
a	friend	of	my	late
brother.	There	were	many	questions	surrounding	my	brother’s	death,	from	a
drug	overdose,	and	I	believed	he	had	a	part	in	that	death,	though	I	later	learned
he	was	not	involved.	In	the	utility	space	within	the	apartment	complex	where
Kent	lived,	I	used	social	engineering	to	pretend	to	be	a	line	technician	calling	a
particular	unit	within	GTE	(General	Telephone	and	Electronics)	to	find	where
the	cable	and	pair	assigned	to	Kent’s	phone	were	located.	It	turned	out	that
Kent’s	phone	wires	ran	through	a	completely	separate	apartment	building.	And
so	in	a	second	utility	space,	I	was	ultimately	able	to	clip	my	voice-activated

microcassette	tape	recorder	to	his	phone	line	at	the	terminal	box	(the	place
where	phone	company	technicians	connect	the	lines	to	each	apartment).
After	that,	anytime	Kent	made	a	call,	I	could	record	both	sides	of	the
conversation	without	his	knowing	I	was	doing	so—though	I	should	note	that
while	the	recordings	were	in	real	time,	my	listening	to	them	was	not.	Every	day
over	the	next	ten	days	I	had	to	make	the	sixty-minute	drive	to	Kent’s	apartment,
afterward	listening	to	the	retrieved	tapes	for	any	mention	of	my	brother.
Unfortunately,	nothing	ever	came	of	it.	Years	later	I	learned	that	my	uncle	had
likely	been	responsible	for	my	brother’s	death.
Given	how	easy	it	was	for	Pellicano	and	me	to	tap	into	private	phone
conversations,	you	may	wonder	how	you	can	become	invisible	with	a	copper-
wire	landline	phone	that	is	apparently	open	to	surveillance?	You	can’t,	without
buying	special	equipment.	For	the	truly	paranoid,	there	are	landline	phones	that
will	encrypt	all	your	voice	conversations	over	copper	wires.
9
	These	phones	do
solve	the	problem	of	interception	of	private	phone	calls,	but	only	if	both	ends
of	the	call	use	encryption;	otherwise	they	may	be	easy	to	monitor.
10
	For	the
rest	of	us,	there	are	some	basic	telephone	choices	we	can	make	to	avoid	being
eavesdropped	on.
The	move	toward	digital	telephony	has	made	surveillance	easier,	not
harder.	Today,	if	a	tap	is	necessary	on	a	digital	phone	line,	it	can	be	done
remotely.	The	switching	computer	simply	creates	a	second,	parallel	stream	of
data;	no	additional	monitoring	equipment	is	required.	This	also	makes	it	much
harder	to	determine	whether	a	given	line	has	been	tapped.	And	in	most	cases
such	taps	are	only	discovered	by	accident.
Shortly	after	Greece	hosted	the	2004	Summer	Olympics,	engineers	at
Vodafone-Panafon	removed	some	rogue	software	that	had	been	discovered	to
be	running	in	the	company’s	cellular	network	for	more	than	a	year.	In	practice,
law	enforcement	intercepts	all	voice	and	text	data	sent	over	any	cellular
network	through	a	remote-controlled	system	called	RES	(remote-control
equipment	subsystem),	the	digital	equivalent	of	an	analog	wiretap.	When	a
subject	under	surveillance	makes	a	mobile	call,	the	RES	creates	a	second	data
stream	that	feeds	directly	to	a	law	enforcement	officer.
The	rogue	software	discovered	in	Greece	tapped	into	Vodafone’s	RES,
meaning	that	someone	other	than	a	legitimate	law	enforcement	officer	was
listening	to	conversations	conducted	over	its	cellular	network;	in	this	case,	the
wiretapper	was	interested	in	government	officials.	During	the	Olympics,	some

countries—such	as	the	United	States	and	Russia—provided	their	own	private
communications	systems	for	state-level	conversations.	Other	heads	of	state	and
business	executives	from	around	the	world	used	the	compromised	Vodafone
system.
An	investigation	showed	that	the	communications	of	the	Greek	prime
minister	and	his	wife—as	well	as	those	of	the	mayor	of	Athens,	the	Greek
European	Union	commissioner,	and	the	ministries	of	national	defense,	foreign
affairs,	the	mercantile	marine,	and	justice—had	been	monitored	during	the
Olympics.	Other	intercepted	phones	belonged	to	members	of	civil	rights
organizations,	antiglobalization	groups,	the	ruling	New	Democracy	party,	the
Hellenic	Navy	general	staff,	as	well	as	peace	activists	and	a	Greek-American
employee	at	the	United	States	embassy	in	Athens.
11
The	spying	might	have	continued	longer	had	Vodafone	not	called	in	the
hardware	vendor	for	its	RES	system,	Ericsson,	while	investigating	a	separate
complaint—that	its	text	messages	were	suffering	delivery	failures	at	a	higher
than	normal	rate.	After	diagnosing	the	problem,	Ericsson	notified	Vodafone
that	it	had	found	rogue	software.
Unfortunately,	more	than	a	decade	afterward,	we	still	don’t	know	who	did
this.	Or	why.	Or	even	how	common	this	activity	might	be.	To	make	matters
worse,	Vodafone	apparently	mishandled	the	investigation.
12
	For	one	thing,	key
log	files	covering	the	event	were	missing.	And	instead	of	letting	the	rogue
program	run	after	discovery—a	common	practice	in	computer	criminal
investigations—Vodafone	abruptly	removed	it	from	their	system,	which	may
have	tipped	off	the	perpetrators	and	allowed	them	to	further	cover	their	tracks.
The	Vodafone	case	is	an	unsettling	reminder	of	how	vulnerable	our	cell
phones	are	to	interception.	But	there	are	ways	you	can	still	be	invisible	with	a
digital	phone.
Besides	cell	phones	and	old-fashioned	landlines,	a	third	telephony	option,	as	I
mentioned	earlier,	is	Voice	over	Internet	Protocol	(VoIP).	VoIP	is	great	for	any
wireless	device	that	lacks	a	native	means	of	making	a	phone	call,	e.g.,	an	Apple
iPod	Touch;	it’s	more	like	surfing	the	Internet	than	making	a	classic	phone	call.
Landlines	require	copper	wire.	Mobile	phones	use	cell	towers.	VoIP	is	simply
transmitting	your	voice	over	the	Internet—either	using	wired	or	wireless
Internet	services.	VoIP	also	works	on	mobile	devices,	such	as	laptops	and
tablets,	whether	or	not	they	have	cellular	service.
To	save	money,	many	homes	and	offices	have	switched	to	the	VoIP	systems

being	offered	by	new	service	providers	and	existing	cable	companies.	VoIP
uses	the	same	coaxial	cable	that	brings	streaming	video	and	high-speed	Internet
into	your	home.
The	good	news	is	that	VoIP	phone	systems	do	use	encryption;	specifically,
something	called	session	description	protocol	security	
descriptions,	or	SDES.
The	bad	news	is	that	on	its	own,	SDES	is	not	very	secure.
Part	of	the	problem	with	SDES	is	the	encryption	key	is	not	shared	over
SSL/TLS	(a	network	cryptographic	protocol),	which	is	secure.	If	the	vendor
doesn’t	use	SSL/TLS,	however,	then	the	key	is	sent	in	the	clear.	Instead	of
asymmetric	encryption,	it	uses	symmetric	encryption,	which	means	that	the	key
generated	by	the	sender	must	somehow	be	passed	to	the	recipient	in	order	for
the	call	to	be	unscrambled.
Let’s	say	Bob	wants	to	make	a	call	to	Alice,	who	is	in	China.	Bob’s	SDES-
encrypted	VoIP	phone	generates	a	new	key	for	that	call.	Somehow	Bob	has	to
get	that	new	key	to	Alice	so	her	VoIP	equipment	can	decrypt	his	phone	call	and
they	can	have	a	conversation.	The	solution	SDES	offers	is	to	send	the	key	to
Bob’s	carrier,	which	then	passes	it	to	Alice’s	carrier,	which	then	shares	it	with
her.
Do	you	see	the	flaw?	Remember	what	I	said	about	end-to-end	encryption	in
the	previous	chapter?	The	conversation	stays	secure	until	the	recipient	opens	it
at	the	other	end.	But	SDES	shares	the	key	from	Bob	to	Bob’s	carrier	and,	if
Alice’s	carrier	is	different,	the	call	is	encrypted	from	Alice’s	carrier	to	Alice.
Whether	the	gap	is	significant	is	debatable.	Something	like	this	also	happens
with	Skype	and	Google	Voice.	New	keys	are	generated	whenever	a	call	is
initialized,	but	those	keys	are	then	given	over	to	Microsoft	and	Google.	So
much	for	wanting	to	have	a	private	conversation.
Fortunately,	there	are	ways	to	encrypt	mobile	VoIP	from	end	to	end.
Signal,	an	application	from	Open	Whisper	Systems,	is	a	free,	open-source
VoIP	system	for	mobile	phones	that	provides	true	end-to-end	encryption	for
both	iPhone	and	Android.
13
The	main	advantage	of	using	Signal	is	that	the	key	management	is	handled
only	between	the	calling	parties,	not	through	any	third	party.	That	means	that,
as	in	SDES,	new	keys	are	generated	with	each	call;	however,	the	only	copies	of
the	keys	are	stored	on	the	users’	devices.	Since	CALEA	allows	access	to	any
record	of	a	specific	call,	
law	enforcement	would	in	this	case	only	see	the
encrypted	traffic	across	the	mobile	carrier’s	line,	which	would	be
unintelligible.	And	Open	Whisper	Systems,	the	nonprofit	organization	that

makes	Signal,	does	not	have	the	keys,	so	a	warrant	would	be	useless.	The	keys
exist	only	on	the	devices	at	either	end	of	the	call.	And	once	the	call	ends,	those
session	keys	are	destroyed.
Currently	CALEA	does	not	extend	to	end	users	or	their	devices.
You	might	think	that	having	encryption	on	your	cell	phone	would	drain
your	battery.	It	does,	but	not	by	much.	Signal	uses	push	notifications,	as	do	the
apps	WhatsApp	and	Telegram.	Thus	you	only	see	a	call	when	it	is	incoming,
which	cuts	down	on	battery	use	while	you’re	listening	for	new	calls.	The
Android	and	iOS	apps	also	use	audio	codecs	and	buffer	algorithms	native	to
the	mobile	network,	so	again	the	encryption	is	not	draining	a	lot	of	power
while	you’re	making	a	call.
In	addition	to	using	end-to-end	encryption,	Signal	also	uses	perfect	forward
secrecy	(PFS).	What	is	PFS?	It’s	a	system	that	uses	a	slightly	different
encryption	key	for	every	call,	so	that	even	if	someone	does	manage	to	get	hold
of	your	encrypted	phone	call	and	the	key	that	was	used	to	encrypt	it,	your	other
calls	will	remain	secure.	All	PFS	keys	are	based	on	a	single	original	key,	but
the	important	thing	is	that	if	someone	compromises	one	key,	it	doesn’t	mean
your	potential	adversary	has	access	to	your	further	communications.

CHAPTER	FOUR
If	You	Don’t	Encrypt,	You’re	Unequipped
If	someone	were	to	pick
	up	your	unlocked	cell	phone	right	now,	that
person	could	gain	access	to	your	e-mail,	your	Facebook	account,	and	perhaps
even	your	Amazon	account.	On	our	mobile	devices,	we	no	longer	log	in
individually	to	services,	as	we	do	on	our	laptops	and	desktops;	we	have	mobile
apps,	and,	once	we’re	logged	in,	they	remain	open.	Besides	your	photos	and
your	music,	there	are	other	unique	features	on	your	cell	phone,	such	as	SMS
text	messages.	These,	too,	become	exposed	if	someone	gains	physical	access	to
your	unlocked	mobile	device.
Consider	this:	in	2009	Daniel	Lee	of	Longview,	Washington,	was	arrested
on	suspicion	of	selling	drugs.
1
	While	he	was	in	custody	the	police	went
through	his	non-password-protected	cell	phone	and	immediately	discovered
several	drug-related	text	messages.	One	such	thread	was	from	an	individual
called	Z-Jon.
It	read,	“I’ve	got	a	hundred	and	thirty	for	the	one-sixty	I	owe	you	from	last
night.”	According	to	court	testimony,	the	Longview	police	didn’t	just	read	Z-
Jon’s	messages	to	Lee,	they	also	actively	responded,	arranging	their	own	drug
deal.	Posing	as	Lee,	the	police	sent	Z-Jon	a	text	message	in	reply,	asking	him	if
he	“needed	more.”	Z-Jon	responded,	
“Yeah,	that	would	be	cool.”	When	Z-Jon
(whose	real	name	is	Jonathan	Roden)	showed	up	for	that	meeting,	the
Longview	police	arrested	him	for	attempted	heroin	possession.
The	police	also	noticed	another	thread	of	text	messages	on	Lee’s	phone	and

arrested	Shawn	Daniel	Hinton	under	similar	circumstances.
2
Both	men	appealed,	and	in	2014,	with	the	help	of	the	American	Civil
Liberties	Union,	the	Washington	State	Supreme	Court	overturned	Roden’s	and
Hinton’s	convictions	by	a	lower	court,	asserting	that	the	police	had	violated	the
defendants’	expectation	of	privacy.
The	Washington	State	justices	said	that	had	Lee	seen	the	messages	from
Roden	and	Hinton	first	or	instructed	the	police	officers	to	respond	by	saying
“Daniel’s	not	here,”	that	would	have	changed	the	fundamentals	in	both	cases.
“Text	messages	can	encompass	the	same	intimate	subjects	as	phone	calls,
sealed	letters	and	other	traditional	forms	of	communication	that	have
historically	been	strongly	protected	under	Washington	law,”	Justice	Steven
Gonzalez	wrote	in	Hinton’s	case.
3
The	justices	ruled	that	the	expectation	of	privacy	should	extend	from	the
paper-letter	era	into	the	digital	age.	In	the	United	States,	law	enforcement	is	not
permitted	to	open	a	physically	sealed	letter	without	the	recipient’s	permission.
The	expectation	of	privacy	is	a	legal	test.	It	is	used	to	determine	whether	the
privacy	protections	within	the	Fourth	Amendment	to	the	United	States
Constitution	apply.	It	remains	to	be	seen	how	the	courts	decide	future	cases	and
whether	they	include	this	legal	test.
Text	technology—also	known	as	short	message	service,	or	SMS—has	been
around	since	1992.	Cell	phones,	even	feature	phones	(i.e.,	non-smartphones),
allow	for	sending	brief	text	messages.	Text	messages	are	not	necessarily	point-
to-point:	in	other	words,	the	messages	do	not	literally	travel	from	phone	to
phone.	Like	an	e-mail,	
the	message	you	type	out	on	your	phone	is	sent
unencrypted,	in	the	clear,	to	a	short	message	service	center	(SMSC),	part	of	the
mobile	network	designed	to	store,	forward,	and	deliver	the	SMS—sometimes
hours	later.
Native	mobile	text	messages—those	initiated	from	your	phone	and	not	an
app—pass	through	an	SMSC	at	the	carrier,	where	they	may	or	may	not	be	not
stored.	The	carriers	state	they	retain	texts	for	only	a	few	days.	After	that	time
has	expired,	the	carriers	insist	that	your	text	messages	are	stored	only	on	the
phones	that	send	and	receive	them,	and	the	number	of	messages	stored	varies
by	the	phone	model.	Despite	these	claims,	I	think	all	mobile	operators	in	the
United	States	retain	text	messages	regardless	of	what	they	tell	the	public.
4
There	is	some	doubt	surrounding	this	claim	by	the	carriers.	Documents
exposed	by	Edward	Snowden	suggest	a	tight	relationship	between	the	NSA	and

at	least	one	of	the	carriers,	AT&T.	According	to	
Wired,
	beginning	in	2002—
shortly	after	9/11—the	NSA	approached	AT&T	and	asked	them	to	begin
building	secret	rooms	in	some	of	the	carrier’s	facilities.	One	was	to	be	located
in	Bridgeton,	Missouri,	and	another	on	Folsom	Street	in	downtown	San
Francisco.	Eventually	other	cities	were	added,	including	Seattle,	San	Jose,	Los
Angeles,	and	San	Diego.	The	purpose	of	these	secret	rooms	was	to	channel	all
the	Internet,	e-mail,	and	phone	traffic	through	a	special	filter	that	would	look
for	keywords.	It	is	unclear	whether	text	messages	were	included,	although	it
seems	reasonable	to	think	they	were.	It	is	also	unclear	whether	this	practice	still
exists	at	AT&T	or	any	other	carrier	post-Snowden.
5
One	clue	suggests	that	this	practice	does	not	continue.
In	the	2015	AFC	championship	game,	leading	up	to	Super	Bowl	XLIX,	the
New	England	Patriots	ignited	controversy	with	their	victory	over	the
Indianapolis	Colts,	45–7.	At	the	heart	of	the	controversy	was	whether	the	New
England	team	had	knowingly	underinflated	their	footballs.	The	National
Football	League	has	strict	rules	
around	the	proper	inflation	of	its	footballs,	and
after	that	playoff	game	it	was	determined	that	the	balls	contributed	by	the	New
England	team	did	not	meet	the	criteria.	Central	to	the	investigation	were	text
messages	sent	by	the	Patriots’	star	quarterback,	Tom	Brady.
Publicly	Brady	denied	involvement.	Showing	investigators	the	text
messages	he	sent	and	received	before	and	during	the	game	would	have	perhaps
confirmed	this.	Unfortunately,	the	day	he	met	with	key	investigators,	Brady
abruptly	switched	cell	phones,	discarding	the	one	he	had	used	between
November	2014	and	approximately	March	6,	2015,	to	a	brand-new	phone.
Brady	later	told	the	committee	that	he	had	destroyed	his	original	phone	and	all
the	data	on	it,	including	his	stored	text	messages.	As	a	result	Brady	received	a
four-game	suspension	from	the	NFL,	which	was	later	lifted	by	court	order.
6
“During	the	four	months	that	the	cell	phone	was	in	use,	Brady	had
exchanged	nearly	10,000	text	messages,	none	of	which	can	now	be	retrieved
from	that	device,”	the	league	said.	“Following	the	appeal	hearing,	Mr.	Brady’s
representatives	provided	a	letter	from	his	cellphone	carrier	confirming	that	the
text	messages	sent	from	or	received	by	the	destroyed	cellphone	could	no
longer	be	recovered.”
7
So	if	Tom	Brady	had	a	note	from	his	carrier	saying	that	his	text	messages
were	all	destroyed,	and	the	carriers	themselves	say	they	don’t	retain	them,	the
only	way	to	prolong	the	life	of	a	text	is	to	back	up	your	mobile	device	to	the
cloud.	If	you	use	a	service	from	your	carrier,	or	even	from	Google	or	Apple,

those	companies	may	have	access	to	your	text	messages.	Apparently	Tom
Brady	didn’t	have	time	to	back	up	the	contents	of	his	old	phone	to	the	cloud
before	his	emergency	upgrade.
Congress	has	not	addressed	the	issue	of	data	retention	in	general	and
mobile	phones	in	particular.	In	fact,	Congress	has	debated	in	recent	years
whether	to	require	all	mobile	carriers	to	archive	text	
messages	for	up	to	two
years.	Australia	decided	to	do	this	in	2015,	so	it	remains	to	be	seen	if	this
works	there.
So	how	can	you	keep	your	text	messages	private?	First	of	all,	don’t	use	the
native	text	messaging	service	that	goes	through	your	wireless	carrier.	Instead
use	a	third-party	app.	But	which	one?
To	mask	our	online	identities—to	enjoy	the	Internet	anonymously—we	will
need	to	trust	
some
	software	and	software	services.	That	trust	is	hard	to	verify.
In	general,	open-source	and	nonprofit	organizations	provide	perhaps	the	most
secure	software	and	services	because	there	are	literally	thousands	of	eyes
poring	over	the	code	and	flagging	anything	that	looks	suspicious	or
vulnerable.	When	you	use	proprietary	software,	you	more	or	less	have	to	take
the	vendor’s	word.
Software	reviews,	by	their	nature,	can	only	tell	you	so	much—such	as	how
a	particular	interface	feature	works.	The	reviewers	spend	a	few	days	with	the
software	and	write	their	impressions.	They	don’t	actually	use	the	software,	nor
can	they	report	on	what	happens	over	the	long	term.	They	only	record	their
initial	impressions.
In	addition,	reviewers	do	not	tell	you	whether	you	can	trust	the	software.
They	don’t	vet	the	security	and	privacy	aspects	of	the	product.	And	just	because
a	product	comes	from	a	well-known	brand	name	doesn’t	mean	it	is	secure.	In
fact	we	should	be	wary	of	popular	brand	names	because	they	may	lure	us	into	a
false	sense	of	security.	You	shouldn’t	take	the	vendor	at	its	word.
Back	in	the	1990s,	when	I	needed	to	encrypt	my	Windows	95	laptop,	I
chose	a	now	discontinued	utility	product	from	Norton	called	Norton	Diskreet.
Peter	Norton	is	a	genius.	His	first	computer	utility	automated	the	process	of
undeleting	a	file.	He	went	on	to	create	a	lot	of	great	system	utilities	back	in	the
1980s,	at	a	time	when	few	people	could	understand	a	command	prompt.	But
then	he	sold	the	
company	to	Symantec,	and	someone	else	started	writing	the
software	in	his	name.
At	the	time	I	acquired	Diskreet,	a	product	that	is	no	longer	available,	56-bit

DES	encryption	(DES	stands	for	“data	encryption	standard”)	was	a	big	deal.	It
was	the	strongest	encryption	you	could	hope	for.	To	give	you	some	context,
today	we	use	AES	256-bit	encryption	(AES	stands	for	“advanced	encryption
standard”).	Each	added	bit	of	encryption	adds	exponentially	more	encryption
keys	and	therefore	more	security.	DES	56-bit	encryption	was	considered	state-
of-the-art	secure	until	it	was	cracked	in	1998.
8
Anyway,	I	wanted	to	see	whether	the	Diskreet	program	was	robust	enough
to	hide	my	data.	I	also	wanted	to	challenge	the	FBI	if	they	ever	seized	my
computer.	After	purchasing	the	program	I	hacked	into	Symantec	and	located
the	program’s	source	code.
9
	After	I	analyzed	what	it	did	and	how	it	did	it,	I
discovered	that	Diskreet	only	used	thirty	bits	of	the	56-bit	key—the	rest	was
just	padding	with	zeros.
10
	That’s	even	less	secure	than	the	forty	bits	that	was
allowed	to	be	exported	outside	the	United	States.
What	that	meant	in	practical	terms	was	that	someone—the	NSA,	law
enforcement,	or	an	enemy	with	a	very	fast	computer—could	crack	the	Diskreet
product	much	more	easily	than	advertised,	since	it	didn’t	really	use	56-bit
encryption	at	all.	Yet	the	company	was	marketing	the	product	as	having	56-bit
encryption.	I	decided	to	use	something	else	instead.
How	would	the	public	know	this?	They	wouldn’t.
Although	social	networks	such	as	Facebook,	Snapchat,	and	Instagram	rank	at
the	top	when	it	comes	to	popularity	among	teens,	text	messaging	reigns
supreme	overall,	according	to	data	supplied	by	Niche.com.
11
	A	recent	study
found	that	87	percent	of	teenagers	text	daily,	compared	to	the	61	percent	who
say	they	use	Facebook,	the	next	most	popular	choice.	Girls	send,	on	average,
about	3,952	text	
messages	per	month,	and	boys	send	closer	to	2,815	text
messages	per	month,	according	to	the	study.
12
The	good	news	is	that	today	all	the	popular	messaging	apps	provide	some
form	of	encryption	when	sending	and	receiving	your	texts—that	is,	they
protect	what’s	called	“data	in	motion.”	The	bad	news	is	that	not	all	the
encryption	being	used	is	strong.	In	2014,	researcher	Paul	Jauregui	of	the
security	firm	Praetorian	found	that	it	was	possible	to	circumvent	the	encryption
used	by	WhatsApp	and	engage	in	a	man-in-the-middle	(MitM)	attack,	in	which
the	attacker	intercepts	messages	between	the	victim	and	his	recipient	and	is	able
to	see	every	message.	“This	is	the	kind	of	stuff	the	NSA	would	love,”	Jauregui
observed.
13
	As	of	this	writing,	the	encryption	used	in	WhatsApp	has	been

updated	and	uses	end-to-end	encryption	on	both	iOS	and	Android	devices.	And
the	parent	company	for	WhatsApp,	Facebook,	has	added	encryption	to	its	900
million	Messenger	users,	although	it	is	an	opt-in,	meaning	you	have	to
configure	“Secret	Conversations”	to	work.
14
The	worse	news	is	what	happens	to	data	that’s	archived,	or	“data	at	rest.”
Most	mobile	text	apps	do	not	encrypt	archived	data,	either	on	your	device	or
on	a	third-party	system.	Apps	such	as	AIM,	BlackBerry	Messenger,	and	Skype
all	store	your	messages	without	encrypting	them.	That	means	the	service
provider	can	read	the	content	(if	it’s	stored	in	the	cloud)	and	use	it	for
advertising.	It	also	means	that	if	law	enforcement—or	criminal	hackers—were
to	gain	access	to	the	physical	device,	they	could	also	read	those	messages.
Another	issue	is	data	retention,	which	we	mentioned	above—how	long	does
data	at	rest	stay	at	rest?	If	apps	such	as	AIM	and	Skype	archive	your	messages
without	encryption,	how	long	do	they	keep	them?	Microsoft,	which	owns
Skype,	has	said	that	“Skype	uses	automated	scanning	within	Instant	Messages
and	SMS	to	(a)	identify	suspected	spam	and/or	(b)	identify	URLs	that	have	been
previously	flagged	as	spam,	fraud,	or	phishing	links.”	So	far	this	sounds	like
the	anti-malware	scanning	activity	that	companies	perform	on	our	
e-mails.
However,	the	privacy	policy	goes	on	to	say:	“Skype	will	retain	your
information	for	as	long	as	is	necessary	to:	(1)	fulfill	any	of	the	Purposes	(as
defined	in	article	2	of	this	Privacy	Policy)	or	(2)	comply	with	applicable
legislation,	regulatory	requests	and	relevant	orders	from	competent	courts.”
15
That	doesn’t	sound	so	good.	How	long	is	“as	long	as	is	necessary”?
AOL	Instant	Messenger	(AIM)	may	have	been	the	first	instant	message
service	that	any	of	us	used.	It’s	been	around	a	long	while.	Designed	for	desktop
or	traditional	PCs,	AIM	originally	took	the	form	of	a	little	pop-up	window	that
appeared	in	the	lower	right-hand	corner	of	the	desktop.	Today	it	is	available	as
a	mobile	app	as	well.	But	in	terms	of	privacy,	AIM	raises	some	red	flags.	First,
AIM	keeps	an	archive	of	all	messages	sent	through	its	service.	And,	like	Skype,
it	also	scans	the	contents	of	those	messages.	A	third	concern	is	that	AOL	keeps
records	of	the	messages	in	the	cloud	in	case	you	ever	want	to	access	a	chat
history	from	any	terminal	or	device	different	from	the	one	where	you	had
your	last	session.
16
Since	your	AOL	chat	data	is	not	encrypted	and	is	available	from	any
terminal	because	it	lives	in	the	cloud,	it	is	easy	for	law	enforcement	and
criminal	hackers	to	get	a	copy.	For	example,	my	AOL	account	was	hacked	by	a
script	kiddie	whose	online	handle	is	Virus—his	real	name	is	Michael	Nieves.
17

He	was	able	to	social-engineer	(in	other	words,	get	on	the	phone	and	sweet-
talk)	AOL	and	gain	access	to	their	internal	customer-database	system,	called
Merlin,	which	allowed	him	to	change	my	e-mail	address	to	one	associated	with
a	separate	account	under	his	control.	Once	he	did	that	he	was	able	to	reset	my
password	and	gain	access	to	all	my	past	messages.	In	2007	Nieves	was	charged
with	four	felonies	and	a	misdemeanor	for,	according	to	the	complaint,	hacking
into	“internal	AOL	computer	networks	and	databases,	including	customer
billing	records,	addresses	and	credit	card	information.”
As	the	Electronic	Frontier	Foundation	has	said,	“no	logs	are	good	logs.”
AOL	has	logs.
Non-native	text	apps	may	say	they	have	encryption,	but	it	might	not	be	good	or
strong	encryption.	What	should	you	look	for?	A	text	app	that	provides	end-to-
end	encryption,	meaning	that	no	third-party	has	access	to	the	keys.	The	keys
should	exist	on	each	device	only.	Note,	too,	if	either	device	is	compromised
with	malware,	then	using	any	type	of	encryption	is	worthless.
There	are	three	basic	“flavors”	of	text	apps:
	Those	that	provide	no	encryption	at	all—meaning	that	anyone	can	read
your	text	messages.
	Those	that	provide	encryption,	but	not	from	end	to	end—meaning	that	the
communication	can	be	intercepted	by	third	parties	such	as	the	service
provider,	which	has	knowledge	of	the	encryption	keys.
	Those	that	provide	encryption	from	end	to	end—meaning	that	the
communication	can’t	be	read	by	third	parties	because	the	keys	are	stored
on	the	individual	devices.
Unfortunately	the	most	popular	text-messaging	apps—like	AIM—are	not
very	private.	Even	Whisper	and	Secret	may	not	be	totally	private.	Whisper	is
used	by	millions	and	markets	itself	as	anonymous,	but	researchers	have	poked
holes	in	these	claims.	Whisper	tracks	its	users,	while	the	identities	of	Secret
users	are	sometimes	revealed.
Telegram	is	another	messaging	app	that	offers	encryption,	and	it	is
considered	a	popular	alternative	to	WhatsApp.	It	runs	on	Android,	iOS,	and
Windows	devices.	Researchers	have,	however,	found	an	adversary	can

compromise	Telegram	servers	and	get	access	to	critical	data.
18
	And
researchers	have	found	it	easy	to	retrieve	encrypted	Telegram	messages,	even
after	they	have	been	deleted	from	the	device.
19
So	now	that	we’ve	eliminated	some	popular	choices,	what	remains?
Plenty.	When	you’re	on	the	app	store	or	Google	Play,	look	for	apps	
that	use
something	called	off-the-record	messaging,	or	OTR.	It	is	a	higher-standard
end-to-end	encryption	protocol	used	for	text	messages,	and	it	can	be	found	in	a
number	of	products.
20
Your	ideal	text	message	app	should	also	include	perfect	forward	secrecy
(PFS).	Remember	that	this	employs	a	randomly	generated	session	key	that	is
designed	to	be	resilient	in	the	future.	That	means	if	one	key	is	compromised,	it
can’t	be	used	to	read	your	future	text	messages.
There	are	several	apps	that	use	both	OTR	and	PFS.
ChatSecure	is	a	secure	text-messaging	app	that	works	on	both	Android	and
iPhones.
21
	It	also	provides	something	called	certificate	pinning.	That	means	it
includes	a	proof-of-identity	certificate,	which	is	stored	on	the	device.	Upon
each	contact	with	the	servers	at	ChatSecure,	the	certificate	within	the	app	on
your	device	is	compared	with	the	certificate	at	the	mother	ship.	If	the	stored
certificate	does	not	match,	the	session	does	not	continue.	Another	nice	touch	is
that	ChatSecure	also	encrypts	the	conversation	logs	stored	on	the	device—the
data	at	rest.
22
Perhaps	the	best	open-source	option	is	Signal	from	Open	Whisper	Systems,
which	works	on	both	iOS	and	Android	(see	
here
).
Another	text-messaging	app	to	consider	is	Cryptocat.	It	is	available	for
iPhone	and	most	major	browsers	on	your	traditional	PC.	It	is	not,	however,
available	for	Android.
23
And,	at	the	time	of	this	writing,	the	Tor	project,	which	maintains	the	Tor
browser	(see	
here
),	has	just	released	Tor	Messenger.	Like	the	Tor	browser,	the
app	anonymizes	your	IP	address,	which	means	that	messages	are	difficult	to
trace	(however,	please	note	that,	like	with	the	Tor	browser,	exit	nodes	are	not
by	default	under	your	control;	see	
here
).	Instant	messages	are	encrypted	using
end-to-end	encryption.	Like	Tor,	the	app	is	a	little	difficult	for	the	first-time
user,	but	eventually	it	should	work	to	provide	truly	private	text	messages.
24
There	are	also	commercial	apps	that	provide	end-to-end	
encryption.	The
only	caveat	is	that	their	software	is	proprietary,	and	without	independent
review	their	security	and	integrity	cannot	be	confirmed.	Silent	Phone	offers

end-to-end	encryption	text	messaging.	It	does,	however,	log	some	data,	but
only	to	improve	its	services.	The	encryption	keys	are	stored	on	the	device.
Having	the	keys	on	the	device	means	that	the	government	or	law	enforcement
can’t	compel	Silent	Circle,	its	manufacturer,	to	release	the	encryption	keys	for
any	of	its	subscribers.
I’ve	discussed	encrypting	data	in	motion	and	data	at	rest	as	well	as	using
end-to-end	encryption,	PFS,	and	OTR	to	do	so.	What	about	non-app-based
services,	such	as	Web	mail?	What	about	passwords?

CHAPTER	FIVE
Now	You	See	Me,	Now	You	Don’t
In	April	of	2013,	Khairullozhon	Matanov
,	a	twenty-two-year-
old	former	cab	driver	from	Quincy,	Massachusetts,	went	to	dinner	with	a
couple	of	friends—a	pair	of	brothers,	in	fact.	Among	other	topics,	the	three
men	talked	about	events	earlier	in	the	day	that	occurred	near	the	finish	line	of
the	Boston	Marathon,	where	someone	had	planted	rice	cookers	packed	with
nails	and	gunpowder	and	a	timer.	The	resulting	blasts	claimed	three	lives	and
left	more	than	two	hundred	people	injured.	The	brothers	at	Matanov’s	table,
Tamerlan	and	Dzhokhar	Tsarnaev,	would	later	be	identified	as	the	prime
suspects.
Although	Matanov	said	later	that	he	had	no	prior	knowledge	of	the
bombing,	he	allegedly	left	an	early	post-bombing	meeting	with	law
enforcement	officers	and	promptly	deleted	the	browser	history	from	his
personal	computer.	That	simple	act—erasing	his	laptop’s	browser	history—
resulted	in	charges	against	him.
1
Deleting	browser	history	was	also	one	of	the	charges	against	David
Kernell,	the	college	student	who	hacked	Sarah	Palin’s	e-mail	account.	What’s
chilling	is	that	when	Kernell	cleared	his	browser,	ran	a	disk	defragmenter,	and
deleted	the	Palin	photos	he	had	downloaded,	he	wasn’t	yet	under	investigation.
The	message	here	is	that	in	
the	United	States	you	are	not	allowed	to	erase
anything	you	do	on	your	computer.	Prosecutors	want	to	see	your	entire
browser	history.

The	charges	leveled	against	Matanov	and	Kernell	stem	from	a	nearly
fifteen-year-old	law—the	Public	Company	Accounting	Reform	and	Investor
Protection	Act	(as	it’s	known	in	the	Senate),	or	the	Corporate	and	Auditing
Accountability	and	Responsibility	Act	(as	it’s	known	in	the	House),	more
commonly	called	the	Sarbanes-Oxley	Act	of	2002.	The	law	was	a	direct	result
of	corporate	mismanagement	at	Enron,	a	natural	gas	company	later	found	to
be	lying	and	cheating	investors	and	the	US	government.	Investigators	in	the
Enron	case	discovered	that	a	lot	of	data	had	been	deleted	at	the	outset	of	the
investigation,	preventing	prosecutors	from	seeing	exactly	what	had	gone	on
within	the	company.	As	a	result,	Senator	Paul	Sarbanes	(D-MD)	and
Representative	Michael	G.	Oxley	(R-OH)	sponsored	legislation	that	imposed	a
series	of	requirements	aimed	at	preserving	data.	One	was	that	browser
histories	must	be	retained.
According	to	a	grand	jury	indictment,	Matanov	deleted	his	Google	Chrome
browser	history	selectively,	leaving	behind	activity	from	certain	days	during
the	week	of	April	15,	2013.
2
	Officially	he	was	indicted	on	two	counts:	“(1)
destroying,	altering,	and	falsifying	records,	documents,	and	tangible	objects	in
a	federal	investigation,	and	(2)	making	a	materially	false,	fictitious,	and
fraudulent	statement	in	a	federal	investigation	involving	international	and
domestic	terrorism.”
3
	He	was	sentenced	to	thirty	months	in	prison.
To	date,	the	browser-history	provision	of	Sarbanes-Oxley	has	rarely	been
invoked—either	against	businesses	or	individuals.	And	yes,	Matanov’s	case	is
an	anomaly,	a	high-profile	national	security	case.	In	its	wake,	though,
prosecutors,	aware	of	its	potential,	have	started	invoking	it	more	frequently.
If	you	can’t	stop	someone	from	monitoring	your	e-mail,	phone	calls,	and
instant	messages,	and	if	you	can’t	lawfully	delete	your	browser	
history,	what
can	you	do?	Perhaps	you	can	avoid	collecting	such	history	in	the	first	place.
Browsers	such	as	Mozilla’s	Firefox,	Google’s	Chrome,	Apple’s	Safari,	and
Microsoft’s	Internet	Explorer	and	Edge	all	offer	a	built-in	alternative	way	to
search	anonymously	on	whatever	device	you	prefer—whether	you	use	a
traditional	PC	or	a	mobile	device.	In	each	case	the	browser	itself	will	open	a
new	window	and	not	record	what	you	searched	or	where	you	went	on	the
Internet	during	that	open	session.	Shut	down	the	private	browser	window,	and
all	traces	of	the	sites	you	visited	will	disappear	from	your	PC	or	device.	What
you	exchange	for	privacy	is	that	unless	you	bookmark	a	site	while	using
private	browsing,	you	can’t	go	back	to	it;	there’s	no	history—at	least	not	on

your	machine.
As	much	as	you	may	feel	invincible	using	a	private	window	on	Firefox	or
the	incognito	mode	on	Chrome,	your	request	for	private	website	access,	like
your	e-mails,	still	has	to	travel	through	your	ISP—your	Internet	service
provider,	the	company	you	pay	for	Internet	or	cellular	service—and	your
provider	can	intercept	any	information	that’s	sent	without	being	encrypted.	If
you	access	a	website	that	uses	encryption,	then	the	ISP	can	obtain	the	metadata
—that	you	visited	such	and	such	site	at	such	and	such	date	and	time.
When	an	Internet	browser—either	on	a	traditional	PC	or	a	mobile	device—
connects	to	a	website,	it	first	determines	whether	there’s	encryption,	and	if
there	is,	what	kind.	The	protocol	for	Web	communications	is	known	as	http.
The	protocol	is	specified	before	the	address,	which	means	that	a	typical	URL
might	look	like	this:	http://www.mitnicksecurity.com.	Even	the	“www”	is
superfluous	in	some	cases.
When	you	connect	to	a	site	using	encryption,	the	protocol	changes	slightly.
Instead	of	“http,”	you	see	“https.”	So	now	it’s	https://www.mitnicksecurity.com.
This	https	connection	is	more	secure.	For	one	thing,	it’s	point-to-point,	though
only	if	you’re	connecting	directly	to	
the	site	itself.	There	are	also	a	lot	of
Content	Delivery	Networks	(CDNs)	that	cache	pages	for	their	clients	to	deliver
them	faster,	no	matter	where	you	are	in	the	world,	and	therefore	come	between
you	and	the	desired	website.
Keep	in	mind,	too,	that	if	you	are	logged	in	to	your	Google,	Yahoo,	or
Microsoft	accounts,	these	accounts	may	record	the	Web	traffic	on	your	PC	or
mobile	device—perhaps	building	your	online	behavioral	profile	so	the
companies	can	better	target	the	ads	you	see.	One	way	to	avoid	this	is	to	always
log	out	of	Google,	Yahoo,	and	Microsoft	accounts	when	you	are	finished
using	them.	You	can	log	back	in	to	them	the	next	time	you	need	to.
Moreover,	there	are	default	browsers	built	in	to	your	mobile	devices.	These
are	not	good	browsers.	They’re	crap,	because	they’re	mini	versions	of	the
desktop	and	laptop	browsers	and	lack	some	of	the	security	and	privacy
protections	the	more	robust	versions	have.	For	example,	iPhones	ship	with
Safari,	but	you	might	also	want	to	consider	going	to	the	online	Apple	store	and
downloading	the	mobile	version	of	Chrome	or	Firefox,	browsers	that	were
designed	for	the	mobile	environment.	Newer	versions	of	Android	do	ship	with
Chrome	as	the	default.	All	mobile	browsers	at	least	support	private	browsing.
And	if	you	use	a	Kindle	Fire,	neither	Firefox	nor	Chrome	are	download
options	through	Amazon.	Instead	you	have	to	use	a	few	manual	tricks	to	install

Mozilla’s	Firefox	or	Chrome	through	Amazon’s	Silk	browser.	To	install
Firefox	on	the	Kindle	Fire,	open	the	Silk	browser	and	go	to	the	Mozilla	FTP
site.	Select	“Go,”	then	select	the	file	that	ends	with	the	extension	.apk.
Private	browsing	doesn’t	create	temporary	files,	and	therefore	it	keeps	your
browsing	history	off	your	laptop	or	mobile	device.	Could	a	third	party	still	see
your	interaction	with	a	given	website?	Yes,	unless	that	interaction	is	first
encrypted.	To	accomplish	this,	the	Electronic	Frontier	Foundation	has	created	a
browser	plug-in	called	HTTPS	
Everywhere.
4
	This	is	a	plug-in	for	the	Firefox
and	Chrome	browsers	on	your	traditional	PC	and	for	the	Firefox	browser	on
your	Android	device.	There’s	no	iOS	version	at	the	time	of	this	writing.	But
HTTPS	Everywhere	can	confer	a	distinct	advantage:	consider	that	in	the	first
few	seconds	of	connection,	the	browser	and	the	site	negotiate	what	kind	of
security	to	use.	You	want	perfect	forward	secrecy,	which	I	talked	about	in	the
previous	chapter.	Not	all	sites	use	PFS.	And	not	all	negotiations	end	with	PFS—
even	if	it	is	offered.	HTTPS	Everywhere	can	force	https	usage	whenever
possible,	even	if	PFS	is	not	in	use.
Here’s	one	more	criterion	for	a	safe	connection:	every	website	should	have
a	certificate,	a	third-party	guarantee	that	when	you	connect,	say,	to	the	Bank	of
America	website	it	truly	is	the	Bank	of	America	site	and	not	something
fraudulent.	Modern	browsers	work	with	these	third	parties,	known	as
certificate	authorities,	to	keep	updated	lists.	Whenever	you	connect	to	a	site	that
is	not	properly	credentialed,	your	browser	should	issue	a	warning	asking	if
you	trust	the	site	enough	to	continue.	It’s	up	to	you	to	make	an	exception.	In
general,	unless	you	know	the	site,	don’t	make	exceptions.
Additionally,	there	isn’t	just	one	type	of	certificate	on	the	Internet;	there	are
levels	of	certificates.	The	most	common	certificate,	one	you	see	all	the	time,
identifies	only	that	the	domain	name	belongs	to	someone	who	requested	the
certificate,	using	e-mail	verification.	It	could	be	anyone,	but	that	doesn’t	matter
—the	site	has	a	certificate	that	is	recognized	by	your	browser.	The	same	is	true
of	the	second	kind	of	certificate,	an	organizational	certificate.	This	means	that
the	site	shares	its	certificate	with	other	sites	related	to	the	same	domain—in
other	words,	all	the	subdomains	on	mitnicksecurity.com	would	share	the	same
certificate.
The	most	stringent	level	of	certificate	verification,	however,	is	what’s
called	an	extended	verification	certificate.	On	all	browsers,	some	part	of	the
URL	turns	green	(ordinarily	it’s	gray,	like	the	rest	of	the	URL)	when	an

extended	verification	certificate	has	been	issued.	Clicking	over	
the	address—
https://www.mitnicksecurity.com—should	reveal	additional	details	about	the
certificate	and	its	owner,	usually	the	city	and	state	of	the	server	providing	the
website.	This	physical-world	confirmation	indicates	that	the	company	holding
the	URL	is	legitimate	and	has	been	confirmed	by	a	trusted	third-party
certificate	authority.
You	might	expect	the	browser	on	your	mobile	device	to	track	your	location,
but	you	might	be	surprised	that	the	browser	on	your	traditional	PC	does	the
same	thing.	It	does.	How?
Remember	when	I	explained	that	e-mail	metadata	contains	the	IP	address	of
all	the	servers	that	handle	the	e-mails	on	their	way	to	you?	Well,	once	again,
the	IP	address	coming	from	your	browser	can	identify	which	ISP	you	are	using
and	narrow	down	the	possible	geographical	areas	where	you	might	be	located.
The	very	first	time	you	access	a	site	that	specifically	requests	your	location
data	(such	as	a	weather	site),	your	browser	should	ask	whether	you	want	to
share	your	location	with	the	site.	The	advantage	of	sharing	is	that	the	site	can
customize	its	listing	for	you.	For	example,	you	might	see	ads	on
washingtonpost.com	for	businesses	in	the	town	where	you	live	rather	than	in
the	DC	area.
Unsure	whether	you	answered	that	browser	question	in	the	past?	Then	try
the	test	page	at	http://benwerd.com/lab/geo.php.	This	is	one	of	many	test	sites
that	will	tell	you	whether	your	browser	is	reporting	your	location.	If	it	is	and
you	want	to	be	invisible,	then	disable	the	feature.	Fortunately,	you	can	turn	off
browser	location	tracking.	In	Firefox,	type	“about:	config”	in	the	URL	address
bar.	Scroll	down	to	“geo”	and	change	the	setting	to	“disable.”	Save	your
changes.	In	Chrome,	go	to	Options>Under	the	Hood>Content
Settings>Location.	There’s	a	“Do	not	allow	any	site	to	track	my	physical
location”	option	that	will	disable	geolocation	in	Chrome.	Other	browsers	have
similar	configuration	options.
You	might	also	want	to	fake	your	location—if	only	just	for	fun.	If	
you	want
to	send	out	false	coordinates—say,	the	White	House—in	Firefox,	you	can
install	a	browser	plug-in	called	Geolocator.	In	Google	Chrome,	check	the
plug-in’s	built-in	setting	called	“emulate	geolocation	coordinates.”	While	in
Chrome,	press	Ctrl+Shift+I	on	Windows	or	Cmd+Option+I	on	Mac	to	open	the
Chrome	Developer	Tools.	The	Console	window	will	open,	and	you	can	click
the	three	vertical	dots	at	the	top	right	of	the	Console,	then	select	more

tools>sensors.	A	sensor	tab	will	open.	This	allows	you	to	define	the	exact
latitude	and	longitude	you	want	to	share.	You	can	use	the	location	of	a	famous
landmark	or	you	can	choose	a	site	in	the	middle	of	one	of	the	oceans.	Either
way,	the	website	won’t	know	where	you	really	are.
You	can	obscure	not	only	your	physical	location	but	also	your	IP	address
while	online.	Earlier	I	mentioned	Tor,	which	randomizes	the	IP	address	seen	by
the	website	you	are	visiting.	But	not	all	sites	accept	Tor	traffic.	Until	recently,
Facebook	did	not.	For	those	sites	that	don’t	accept	Tor	connections,	you	can
use	a	proxy.
An	open	proxy	is	a	server	that	sits	between	you	and	the	Internet.	In	
chapter	2
I	explained	that	a	proxy	is	like	a	foreign-language	translator—you	speak	to	the
translator,	and	the	translator	speaks	to	the	foreign-language	speaker,	but	the
message	remains	exactly	the	same.	I	used	the	term	to	describe	the	way	someone
in	a	hostile	country	might	try	to	send	you	an	e-mail	pretending	to	be	from	a
friendly	company.
You	can	also	use	a	proxy	to	allow	you	to	access	georestricted	websites—
for	example,	if	you	live	in	a	country	that	limits	Google	search	access.	Or
perhaps	you	need	to	hide	your	identity	for	downloading	illegal	or	copyrighted
content	through	BitTorrent.
Proxies	are	not	bulletproof,	however.	When	you	use	a	proxy,	remember
that	each	browser	must	be	manually	configured	to	point	to	the	proxy	service.
And	even	the	best	proxy	sites	admit	that	clever	Flash	or	JavaScript	tricks	can
still	detect	your	underlying	IP	address—the	IP	address	you	use	to	connect	to	the
proxy	in	the	first	place.	You	can	limit	the	effectiveness	of	these	tricks	by
blocking	or	
restricting	the	use	of	Flash	and	JavaScript	in	your	browser.	But	the
best	way	to	prevent	JavaScript	injection	from	monitoring	you	via	your
browser	is	to	use	the	HTTPS	Everywhere	plug-in	(see	
here
).
There	are	many	commercial	proxy	services.	But	be	sure	to	read	the	privacy
policy	of	any	service	you	sign	up	for.	Pay	attention	to	the	way	it	handles
encryption	of	data	in	motion	and	whether	it	complies	with	law	enforcement	and
government	requests	for	information.
There	are	also	some	free	proxies,	but	you	must	contend	with	a	stream	of
useless	advertising	in	exchange	for	the	use	of	the	service.	My	advice	is	to
beware	of	free	proxies.	In	his	presentation	at	DEF	CON	20,	my	friend	and
security	expert	Chema	Alonso	set	up	a	proxy	as	an	experiment:	he	wanted	to
attract	bad	guys	to	the	proxy,	so	he	advertised	the	IP	address	on	xroxy.com.
After	a	few	days	more	than	five	thousand	people	were	using	his	free

“anonymous”	proxy.	Unfortunately	most	of	them	were	using	it	to	conduct
scams.
The	flip	side,	though,	is	that	Alonso	could	easily	use	the	free	proxy	to	push
malware	into	the	bad	guy’s	browser	and	monitor	his	or	her	activities.	He	did	so
using	what’s	called	a	BeEF	hook,	a	browser	exploitation	framework.	He	also
used	an	end	user	license	agreement	(EULA)	that	people	had	to	accept	to	
allow
him	to	do	it.	That’s	how	he	was	able	to	read	the	e-mails	being	sent	through	the
proxy	and	determine	that	it	was	handling	traffic	related	to	criminal	activity.
The	moral	here	is	that	when	something’s	free,	you	get	what	you	pay	for.
If	you	use	a	proxy	with	https	protocol,	a	law	enforcement	or	government
agency	would	only	see	the	proxy’s	IP	address,	not	the	activities	on	the	websites
you	visit—that	information	would	be	encrypted.	As	I	mentioned,	normal	http
Internet	traffic	is	not	encrypted;	therefore	you	must	also	use	HTTPS
Everywhere	(yes,	this	is	my	answer	to	most	browser	invisibility	woes).
For	the	sake	of	convenience,	people	often	synchronize	their	browser	settings
among	different	devices.	For	example,	when	you	sign	in	to	
the	Chrome
browser	or	a	Chromebook,	your	bookmarks,	tabs,	history,	and	other	browser
preferences	are	all	synced	via	your	Google	account.	These	settings	load
automatically	every	time	you	use	Chrome,	whether	on	traditional	PCs	or
mobile	devices.	To	choose	what	information	should	be	synced	to	your	account,
go	to	the	settings	page	on	your	Chrome	browser.	The	Google	Dashboard	gives
you	full	control	should	you	ever	want	to	remove	synced	information	from
your	account.	Ensure	that	sensitive	information	is	not	auto-synced.	Mozilla’s
Firefox	also	has	a	sync	option.
The	downside	is	that	all	an	attacker	needs	to	do	is	lure	you	into	signing	in
to	your	Google	account	on	a	Chrome	or	Firefox	browser,	then	all	your	search
history	will	load	on	their	device.	Imagine	your	friend	using	your	computer	and
choosing	to	log	in	to	the	browser.	Your	friend’s	history,	bookmarks,	etc.,	will
now	be	synced.	That	means	that	your	friend’s	surfing	history,	among	other
information,	is	now	viewable	on	your	computer.	Plus,	if	you	sign	in	to	a
synchronized	browser	account	using	a	public	terminal	and	forget	to	sign	out,
all	your	browser’s	bookmarks	and	history	will	be	available	to	the	next	user.	If
you’re	signed	in	to	Google	Chrome,	then	even	your	Google	calendar,
YouTube,	and	other	aspects	of	your	Google	account	become	exposed.	If	you
must	use	a	public	terminal,	be	vigilant	about	signing	out	before	you	leave.
Another	downside	of	syncing	is	that	all	interconnected	devices	will	show

the	same	content.	If	you	live	alone,	that	may	be	fine.	But	if	you	share	an	iCloud
account,	bad	things	can	happen.	Parents	who	allow	their	children	to	use	the
family	iPad,	for	example,	might	unintentionally	expose	them	to	adult	content.
5
In	an	Apple	store	in	Denver,	Colorado,	Elliot	Rodriguez,	a	local	account
executive,	registered	his	new	tablet	with	his	existing	iCloud	account.	Instantly
all	his	photos,	texts,	and	music	and	video	downloads	were	available	to	him	on
the	new	tablet.	This	convenience	
saved	him	time;	he	didn’t	have	to	manually
copy	and	save	all	that	material	to	multiple	devices.	And	it	allowed	him	access
to	the	items	no	matter	what	device	he	chose	to	use.
At	some	point	later	on	Elliot	thought	it	was	a	good	idea	to	give	his	older-
technology	tablet	to	his	eight-year-old	daughter.	The	fact	that	she	was
connected	to	his	devices	was	a	short-term	plus.	Occasionally	on	his	tablet
Elliot	would	notice	a	new	app	his	daughter	had	downloaded	to	her	tablet.
Sometimes	they	would	even	share	family	photos.	Then	Elliot	took	a	trip	to
New	York	City,	where	he	traveled	often	for	business.
Without	thinking,	Elliot	took	out	his	iPhone	and	captured	several	moments
with	his	New	York–based	mistress,	some	of	them	quite…	intimate.	The	images
from	his	iPhone	synced	automatically	to	his	daughter’s	iPad	back	in	Colorado.
And	of	course	his	daughter	asked	her	mother	about	the	woman	who	was	with
Daddy.	Needless	to	say,	Elliot	had	some	serious	explaining	to	do	when	he	got
home.
And	then	there’s	the	birthday-present	problem.	If	you	share	devices	or
synced	accounts,	your	visits	to	sites	might	tip	gift	recipients	off	to	what	they’ll
be	getting	for	their	birthdays.	Or,	worse,	what	they	might	have	gotten.	Yet
another	reason	why	sharing	a	family	PC	or	tablet	can	present	a	privacy
problem.
One	way	to	avoid	this	is	to	set	up	different	users,	a	relatively	easy	step	in
Windows.	Keep	the	administrator	privileges	for	yourself	so	that	you	can	add
software	to	the	system	and	set	up	additional	family	or	household	members	with
their	own	accounts.	All	users	will	log	in	with	their	own	passwords	and	have
access	to	only	their	own	content	and	their	own	browser	bookmarks	and
histories.
Apple	allows	for	similar	divisions	within	its	OSX	operating	systems.
However,	not	many	people	remember	to	segment	their	iCloud	space.	And
sometimes,	seemingly	through	no	fault	of	our	own,	technology	simply	betrays
us.
After	years	of	dating	several	women,	Dylan	Monroe,	an	LA-based	
TV

producer,	finally	found	“the	one”	and	decided	to	settle	down.	His	fiancée
moved	in,	and,	as	part	of	their	new	life	together,	he	innocently	connected	his
future	wife	to	his	iCloud	account.
When	you	want	to	start	a	family,	it	makes	sense	to	connect	everyone	to	one
account.	Doing	so	allows	you	to	share	all	your	videos,	texts,	and	music	with
the	ones	you	love.	Except	that’s	in	the	present	tense.	What	about	your	digitally
stored	past?
Sometimes	having	an	automatic	cloud	backup	service	like	iCloud	means
that	we	accumulate	many	years’	worth	of	photos,	texts,	and	music,	some	of
which	we	tend	to	forget,	just	as	we	forget	the	contents	of	old	boxes	in	the	attic.
Photos	are	the	closest	thing	we	have	to	memories.	And	yes,	spouses	have
been	coming	across	shoe	boxes	of	old	letters	and	photographs	for	generations
now.	But	a	digital	medium	that	allows	you	to	take	literally	thousands	of	high-
definition	photos	without	too	much	effort	creates	new	problems.	Suddenly
Dylan’s	old	memories—some	of	them	very	private	indeed—came	back	to
haunt	him	in	the	form	of	photos	that	were	now	on	his	fiancée’s	iPhone	and
iPad.
There	were	items	of	furniture	that	had	to	be	removed	from	the	house
because	other	women	had	performed	intimate	acts	on	that	sofa,	table,	or	bed.
There	were	restaurants	where	his	fiancée	refused	to	go	to	because	she	had	seen
photos	of	other	women	there	with	him,	at	that	table	by	the	window	or	in	that
corner	booth.
Dylan	obliged	his	fiancée	lovingly,	even	when	she	asked	him	to	make	the
ultimate	sacrifice—selling	his	house	once	the	two	of	them	were	married.	All
because	he’d	connected	his	iPhone	to	hers.
The	cloud	creates	another	interesting	problem.	Even	if	you	delete	your
browser	history	on	your	desktop,	laptop,	or	mobile	device,	a	copy	of	your
search	history	remains	in	the	cloud.	Stored	on	the	search	engine	company’s
servers,	your	history	is	a	bit	harder	to	delete	and	harder	to	not	have	stored	in
the	first	place.	This	is	just	one	example	
of	how	surreptitious	data	collection
without	the	proper	context	can	be	easily	misinterpreted	at	a	later	date	and	time.
It’s	easy	to	see	how	an	innocent	set	of	searches	can	go	awry.
One	morning	in	the	late	summer	of	2013,	just	weeks	after	the	Boston
Marathon	bombing,	Michele	Catalano’s	husband	saw	two	black	SUVs	pull	up
in	front	of	their	house	on	Long	Island.	When	he	went	outside	to	greet	the
officers,	they	asked	him	to	confirm	his	identity	and	requested	his	permission	to

search	the	house.	Having	nothing	to	hide,	although	uncertain	why	they	were
there,	he	allowed	them	to	enter.	After	a	cursory	check	of	the	rooms,	the	federal
agents	got	down	to	business.
“Has	anyone	in	this	household	searched	for	information	on	pressure
cookers?”
“Has	anyone	in	this	household	searched	for	information	on	backpacks?”
Apparently	the	family’s	online	searches	through	Google	had	triggered	a
preemptive	investigation	by	the	Department	of	Homeland	Security.	Without
knowing	the	exact	nature	of	the	Catalano	family	investigation,	one	might
imagine	that	in	the	weeks	following	the	Boston	Marathon	bombing	certain
online	searches,	when	combined,	suggested	the	potential	for	terrorism	and	so
were	flagged.	Within	two	hours	the	Catalano	household	was	cleared	of	any
potential	wrongdoing.	Michele	later	wrote	about	the	experience	for	
Medium
—
if	only	as	a	warning	that	what	you	search	for	today	might	come	back	to	haunt
you	tomorrow.
6
In	her	article,	Catalano	pointed	out	that	the	investigators	must	have
discounted	her	searches	for	“What	the	hell	do	I	do	with	quinoa?”	and	“Is	A-
Rod	suspended	yet?”	She	said	her	pressure-cooker	query	was	about	nothing
more	than	making	quinoa.	And	the	backpack	query?	Her	husband	wanted	a
backpack.
At	least	one	search	engine	company,	Google,	has	created	several	privacy
tools	that	allow	you	to	specify	what	information	you	feel	comfortable
keeping.
7
	For	example,	you	can	turn	off	personalized	ad	tracking	
so	that	if	you
look	up	Patagonia	(the	region	in	South	America)	you	don’t	start	seeing	ads	for
South	American	travel.	You	can	also	turn	off	your	search	history	altogether.
Or	you	could	not	log	in	to	Gmail,	YouTube,	or	any	of	your	Google	accounts
while	you	search	online.
Even	if	you	are	not	logged	in	to	your	Microsoft,	Yahoo,	or	Google
accounts,	your	IP	address	is	still	tied	to	each	search	engine	request.	One	way	to
avoid	this	one-to-one	match	is	to	use	the	Google-proxy	startpage.com	or	the
search	engine	DuckDuckGo	instead.
DuckDuckGo	is	already	a	default	option	within	Firefox	and	Safari.	Unlike
Google,	Yahoo,	and	Microsoft,	DuckDuckGo	has	no	provision	for	user
accounts,	and	the	company	says	your	IP	address	is	not	logged	by	default.	The
company	also	maintains	its	own	Tor	exit	relay,	meaning	that	you	can	search
DuckDuckGo	while	using	Tor	without	much	of	a	performance	lag.
8
Because	DuckDuckGo	doesn’t	track	your	use,	your	search	results	won’t	be

filtered	by	your	past	searches.	Most	people	don’t	realize	it,	but	the	results	you
see	within	Google,	Yahoo,	and	Bing	are	filtered	by	everything	you	searched
for	on	those	sites	in	the	past.	For	example,	if	the	search	engine	sees	that	you’re
searching	for	sites	related	to	health	issues,	it	will	start	to	filter	the	search
results	and	push	the	results	related	to	health	issues	to	the	very	top.	Why?
Because	very	few	of	us	bother	to	advance	to	the	second	page	of	a	search	result.
There’s	an	Internet	joke	that	says	that	if	you	want	to	know	the	best	place	to	bury
a	dead	body,	try	
here
	of	the	search	results.
Some	people	might	like	the	convenience	of	not	having	to	scroll	through
seemingly	unrelated	results,	but	at	the	same	time	it	is	patronizing	for	a	search
engine	to	decide	what	you	may	or	may	not	be	interested	in.	By	most	measures,
that	is	censorship.	DuckDuckGo	does	return	relevant	search	results,	but	filtered
by	topic,	not	by	your	past	history.
In	the	next	chapter	I’ll	talk	about	specific	ways	websites	make	it	hard	for
you	to	be	invisible	to	them	and	what	you	can	do	to	surf	the	Web	anonymously.

CHAPTER	SIX
Every	Mouse	Click	You	Make,	I’ll	Be
Watching	You
Be	very	careful	what	you
	search	for	on	the	Internet.	It’s	not	just	search
engines	that	track	your	online	habits;	every	website	you	visit	does	as	well.	And
you’d	think	that	some	of	them	would	know	better	than	to	expose	private
matters	to	others.	For	example,	a	2015	report	found	that	“70	percent	of	health
sites’	URLs	contain	information	exposing	specific	conditions,	treatments,	and
diseases.”
1
In	other	words,	if	I’m	on	WebMD	and	searching	for	“athlete’s	foot,”	the
unencrypted	words	
athlete’s	foot
	will	appear	within	the	URL	visible	in	my
browser’s	address	bar.	This	means	that	anyone—my	browser,	my	ISP,	my
cellular	carrier—can	see	that	I	am	looking	for	information	about	athlete’s	foot.
Having	HTTPS	Everywhere	enabled	on	your	browser	would	encrypt	the
contents	of	the	site	you	are	visiting,	assuming	the	site	supports	https,	but	it
doesn’t	encrypt	the	URL.	As	even	the	Electronic	Frontier	Foundation	notes,
https	was	never	designed	to	conceal	the	identity	of	the	sites	you	visit.
Additionally,	the	study	found	that	91	percent	of	health-related	sites	make
requests	to	third	parties.	These	calls	are	embedded	in	the	pages	themselves,	and
they	make	requests	for	tiny	images	(which	
may	or	may	not	be	visible	on	the
browser	page),	which	informs	these	other	third-party	sites	that	you	are	visiting
a	particular	page.	Do	a	search	for	“athlete’s	foot,”	and	as	many	as	twenty

different	entities—ranging	from	pharmaceuticals	companies	to	Facebook,
Pinterest,	Twitter,	and	Google—are	contacted	as	soon	as	the	search	results	load
in	your	browser.	Now	all	those	parties	know	you	have	been	searching	for
information	about	athlete’s	foot.
2
These	third	parties	use	this	information	to	target	you	with	online
advertising.	Also,	if	you	logged	in	to	the	health-care	site,	they	might	be	able	to
obtain	your	e-mail	address.	Fortunately	I	can	help	you	prevent	these	entities
from	learning	more	about	you.
On	the	health-care	sites	analyzed	in	the	2015	study,	the	top	ten	third	parties
were	Google,	comScore,	Facebook,	AppNexus,	AddThis,	Twitter,	Quantcast,
Amazon,	Adobe,	and	Yahoo.	Some—comScore,	AppNexus,	and	Quantcast—
measure	Web	traffic,	as	does	Google.	Of	the	third	parties	listed	above,	Google,
Facebook,	Twitter,	Amazon,	Adobe,	and	Yahoo	are	spying	on	your	activity	for
commercial	reasons,	so	they	can,	for	example,	load	ads	for	athlete’s	foot
remedies	in	future	searches.
Also	mentioned	in	the	study	were	the	third	parties	Experian	and	Axiom,
which	are	simply	data	warehouses—they	collect	as	much	data	about	a	person
as	they	possibly	can.	And	then	they	sell	it.	Remember	the	security	questions	and
the	creative	answers	I	suggested	that	you	use?	Often	companies	like	Experian
and	Axiom	collect,	provide,	and	use	those	security	questions	to	build	online
profiles.	These	profiles	are	valuable	to	marketers	that	want	to	target	their
products	to	certain	demographics.
How	does	that	work?
Whether	you	type	the	URL	in	manually	or	use	a	search	engine,	every	site	on
the	Internet	has	both	a	hostname	and	a	numerical	IP	address	(some	sites	exist
only	as	numerical	addresses).	But	you	almost	never	see	the	numerical	address.
Your	browser	hides	it	and	uses	a	
domain	name	service	(DNS)	to	translate	a
site’s	hostname	name—say,	Google—in	to	a	specific	address,	in	Google’s	case
https://74.125.224.72/.
DNS	is	like	a	global	phone	book,	cross-referencing	the	hostname	with	the
numerical	address	of	the	server	of	the	site	you	just	requested.	Type
“Google.com”	into	your	browser,	and	the	DNS	contacts	their	server	at
https://74.125.224.72.	Then	you	see	the	familiar	white	screen	with	the	day’s
Google	Doodle	above	a	blank	search	field.	That,	in	theory,	is	how	all	Web
browsers	work.	In	practice	there	is	more	to	it.
After	the	site	has	been	identified	through	its	numerical	address,	it	will	send
information	back	to	your	Web	browser	so	that	it	can	start	“building”	the	Web

page	you	see.	When	the	page	is	returned	to	your	browser,	you	see	the	elements
you	would	expect—the	information	you	want	retrieved,	any	related	images,
and	ways	to	navigate	to	other	parts	of	the	site.	But	often	there	are	elements	that
are	returned	to	your	browser	that	call	out	to	other	websites	for	additional
images	or	scripts.	Some,	if	not	all,	of	these	scripts	are	for	tracking	purposes,
and	in	most	cases	you	simply	do	not	need	them.
Almost	every	digital	technology	produces	metadata,	and,	as	you’ve	no	doubt
already	guessed,	browsers	are	no	different.	Your	browser	can	reveal
information	about	your	computer’s	configuration	if	queried	by	the	site	you	are
visiting.	For	example,	what	version	of	what	browser	and	operating	system
you’re	using,	what	add-ons	you	have	for	that	browser,	and	what	other
programs	you’re	running	on	your	computer	(such	as	Adobe	products)	while
you	search.	It	can	even	reveal	details	of	your	computer’s	hardware,	such	as	the
resolution	of	the	screen	and	the	capacity	of	the	onboard	memory.
You	might	think	after	reading	this	far	that	you	have	taken	great	strides	in
becoming	invisible	online.	And	you	have.	But	there’s	more	work	to	be	done.
Take	a	moment	and	surf	over	to	Panopticlick.com.	This	is	a	site	
built	by	the
Electronic	Frontier	Foundation	that	will	determine	just	how	common	or	unique
your	browser	configuration	is	compared	to	others,	based	on	what’s	running	on
your	PC	or	mobile	device’s	operating	system	and	the	plug-ins	you	may	have
installed.	In	other	words,	do	you	have	any	plug-ins	that	can	be	used	to	limit	or
otherwise	protect	the	information	that	Panopticlick	can	glean	from	your
browser	alone?
If	the	numbers	on	the	left-hand	side,	the	results	from	Panopticlick,	are	high
—say,	a	six-digit	number—then	you	are	somewhat	unique,	because	your
browser	settings	are	found	in	fewer	than	one	in	one	hundred	thousand
computers.	Congratulations.	However,	if	your	numbers	are	low—say,	less	than
three	digits—then	your	browser	settings	are	fairly	common.	You’re	just	one	in
a	few	hundred.	And	that	means	if	I’m	going	to	target	you—with	ads	or
malware—I	don’t	have	to	work	very	hard,	because	you	have	a	common
browser	configuration.
3
You	might	think	that	having	a	common	configuration	can	help	you	become
invisible—you’re	part	of	the	crowd;	you	blend	in.	But	from	a	technical
perspective,	this	opens	you	up	to	malicious	activities.	A	criminal	hacker
doesn’t	want	to	expend	a	lot	of	effort.	If	a	house	has	a	door	open	and	the	house
next	to	it	has	a	door	closed,	which	do	you	think	a	thief	would	rob?	If	a	criminal

hacker	knows	that	you	have	common	settings,	then	perhaps	you	also	lack
certain	protections	that	could	enhance	your	security.
I	understand	I	just	jumped	from	discussing	marketers	trying	to	track	what
you	view	online	to	criminal	hackers	who	may	or	may	not	use	your	personal
information	to	steal	your	identity.	These	are	very	different.	Marketers	collect
information	in	order	to	create	ads	that	keep	websites	profitable.	Without
advertising,	some	sites	simply	could	not	continue.	However,	marketers,
criminal	hackers,	and,	for	that	matter,	governments	are	all	trying	to	get
information	that	you	
may	not	want	to	give,	and	so,	for	the	sake	of	argument,
they	are	often	lumped	together	in	discussions	about	the	invasion	of	privacy.
One	way	to	be	common	yet	also	safe	from	online	eavesdropping	is	to	use	a
virtual	machine	(VM;	see	
here
),	an	operating	system	like	Mac	OSX	running	as
a	guest	on	top	of	your	Windows	operating	system.	You	can	install	VMware	on
your	desktop	and	use	it	to	run	another	operating	system.	When	you’re	done,
you	simply	shut	it	down.	The	operating	system	and	everything	you	did	within	it
will	disappear.	The	files	you	save,	however,	will	remain	wherever	you	saved
them.
Something	else	to	watch	out	for	is	that	marketers	and	criminal	hackers	alike
learn	something	about	visitors	to	a	website	through	what’s	known	as	a	one-
pixel	image	file	or	web	bug.	Like	a	blank	browser	pop-up	window,	this	is	a
1×1-pixel	image	placed	somewhere	on	a	Web	page	that,	although	invisible,
nonetheless	calls	back	to	the	third-party	site	that	placed	it	there.	The	backend
server	records	the	IP	address	that	tried	to	render	that	image.	A	one-pixel	image
placed	on	a	health-care	site	could	tell	a	pharmaceuticals	company	that	I	was
interested	in	athlete’s	foot	remedies.
The	2015	study	I	mentioned	at	the	beginning	of	this	chapter	found	that
almost	half	of	third-party	requests	simply	open	pop-up	windows	containing	no
content	whatsoever.	These	“blank”	windows	generate	silent	http	requests	to
third-party	hosts	that	are	used	only	for	tracking	purposes.	You	can	avoid	these
by	instructing	your	browser	not	to	allow	pop-up	windows	(and	this	will	also
eliminate	those	annoying	ads	as	well).
Nearly	a	third	of	the	remaining	third-party	requests,	according	to	the	study,
consisted	of	small	lines	of	code,	JavaScript	files,	which	usually	just	execute
animations	on	a	Web	page.	A	website	can	identify	the	computer	accessing	the
site,	mostly	by	reading	the	IP	address	that	is	requesting	the	JavaScript	file.
Even	without	a	one-pixel	image	or	a	blank	pop-up	window,	your	
Web
surfing	can	still	be	tracked	by	the	sites	you	visit.	For	example,	Amazon	might

know	that	the	last	site	you	visited	was	a	health-care	site,	so	it	will	make
recommendations	for	health-care	products	for	you	on	its	own	site.	The	way
Amazon	might	do	this	is	to	actually	see	the	last	site	you	visited	in	your	browser
request.
Amazon	accomplishes	this	by	using	third-party	referrers—text	in	the
request	for	a	Web	page	that	tells	the	new	page	where	the	request	originated.	For
example,	if	I’m	reading	an	article	on	
Wired
	and	it	contains	a	link,	when	I	click
that	link	the	new	site	will	know	that	I	was	previously	on	a	page	within
Wired.com.	You	can	see	how	this	third-party	tracking	can	affect	your	privacy.
To	avoid	this,	you	can	always	go	to	Google.com	first,	so	the	site	you	want
to	visit	doesn’t	know	where	you	were	previously.	I	don’t	believe	third-party
referrers	are	such	a	big	deal,	except	when	you’re	trying	to	mask	your	identity.
This	is	one	more	example	of	a	trade-off	between	convenience	(simply	going	to
the	next	website)	and	invisibility	(always	starting	from	Google.com).
Mozilla’s	Firefox	offers	one	of	the	best	defenses	against	third-party
tracking	through	a	plug-in	called	NoScript.
4
	This	add-on	effectively	blocks
just	about	everything	considered	harmful	to	your	computer	and	browser,
namely,	Flash	and	JavaScript.	Adding	security	plug-ins	will	change	the	look
and	feel	of	your	browsing	session,	although	you	can	cherry-pick	and	enable
specific	features	or	permanently	trust	some	sites.
One	result	of	enabling	NoScript	is	that	the	page	you	visit	will	have	no	ads
and	certainly	no	third-party	referrers.	As	a	result	of	the	blocking,	the	Web	page
looks	slightly	duller	than	the	version	without	NoScript	enabled.	However,
should	you	want	to	see	that	Flash-encoded	video	in	the	upper	left-hand	corner
of	the	page,	you	can	specifically	allow	that	one	element	to	render	while
continuing	to	block	everything	else.	Or,	if	you	feel	you	can	trust	the	site,	you
can	temporarily	or	
permanently	allow	all	elements	on	that	page	to	load—
something	you	might	want	to	do	on	a	banking	site,	for	example.
For	its	part,	Chrome	has	ScriptBlock,
5
	which	allows	you	to	defensively
block	the	use	of	scripts	on	a	Web	page.	This	is	useful	for	kids	who	may	surf	to
a	site	that	allows	pop-up	adult	entertainment	ads.
Blocking	potentially	harmful	(and	certainly	privacy-compromising)
elements	on	these	pages	will	keep	your	computer	from	being	overrun	with	ad-
generating	malware.	For	example,	you	may	have	noticed	that	ads	appear	on
your	Google	home	page.	In	fact,	you	should	have	no	flashing	ads	on	your
Google	home	page.	If	you	see	them,	your	computer	and	browser	may	have
been	compromised	(perhaps	some	time	ago),	and	as	a	result	you’re	seeing

third-party	ads	that	may	contain	Trojan	horses—keyloggers,	which	record
every	keystroke	you	make,	and	other	malware—if	you	click	on	them.	Even	if
the	ads	don’t	contain	malware,	the	advertisers’	revenue	comes	from	the
number	of	clicks	they	receive.	The	more	people	they	dupe	into	clicking,	the
more	money	they	make.
As	good	as	they	are,	NoScript	and	ScriptBlock	don’t	block	everything.	For
complete	protection	against	browser	threats,	you	might	want	to	install	Adblock
Plus.	The	only	problem	is	that	Adblock	records	everything:	this	is	another
company	that	tracks	your	surfing	history,	despite	your	use	of	private	browsing.
However,	in	this	case	the	good—blocking	potentially	dangerous	ads—
outweighs	the	bad:	they	know	where	you’ve	been	online.
Another	useful	plug-in	is	Ghostery,	available	for	both	Chrome	and	Firefox.
Ghostery	identifies	all	the	Web	traffic	trackers	(such	as	DoubleClick	and
Google	AdSense)	that	sites	use	to	follow	your	activity.	Like	NoScript,
Ghostery	gives	you	granular	control	over	which	trackers	you	want	to	allow	on
each	page.	The	site	says,	“Blocking	trackers	will	prevent	them	from	running	in
your	browser,	which	can	help	control	how	your	behavioral	data	is	tracked.
Keep	in	mind	
that	some	trackers	are	potentially	useful,	such	as	social	network
feed	widgets	or	browser-based	games.	Blocking	may	have	an	unintended	effect
on	the	sites	you	visit.”	Meaning	that	some	sites	will	no	longer	work	with
Ghostery	installed.	Fortunately,	you	can	disable	it	on	a	site-by-site	basis.
6
In	addition	to	using	plug-ins	to	block	sites	from	identifying	you,	you	might
want	to	confuse	potential	hackers	further	by	using	a	variety	of	e-mail	addresses
tailored	for	individual	purposes.	For	example,	in	
chapter	2
	I	discussed	ways	of
creating	anonymous	e-mail	accounts	in	order	to	communicate	without
detection.	Similarly,	for	simple	day-to-day	browsing,	it’s	also	a	good	idea	to
create	multiple	e-mail	accounts—not	to	hide	but	to	make	yourself	less
interesting	to	third	parties	on	the	Internet.	Having	multiple	online	personality
profiles	dilutes	the	privacy	impact	of	having	only	one	identifiable	address.	It
makes	it	harder	for	anyone	to	build	an	online	profile	of	you.
Let’s	say	you	want	to	purchase	something	online.	You	might	want	to	create
an	e-mail	address	that	you	use	exclusively	for	shopping.	You	might	also	want
to	have	anything	you	purchase	with	this	e-mail	address	sent	to	your	mail	drop
instead	of	your	home	address.
7
	In	addition,	you	might	want	to	use	a	gift	card
for	your	purchase,	perhaps	one	you	reload	from	time	to	time.
This	way	the	company	selling	you	products	will	only	have	your

nonprimary	e-mail	address,	your	nonprimary	real-world	address,	and	your
more-or-less	throwaway	gift	card.	If	there’s	ever	a	data	breach	at	that	company,
at	least	the	attackers	won’t	have	your	real	e-mail	address,	real-world	address,
or	credit	card	number.	This	kind	of	disconnection	from	an	online	purchasing
event	is	good	privacy	practice.
You	might	also	want	to	create	another	nonprimary	e-mail	address	for	social
networks.	This	address	might	become	your	“public”	e-mail	address,	which
strangers	and	mere	acquaintances	can	use	to	get	in	
touch	with	you.	The
advantage	to	this	is	that,	once	again,	people	won’t	learn	much	about	you.	At
least	not	directly.	You	can	further	protect	yourself	by	giving	each	nonprimary
address	a	unique	name,	either	a	variation	on	your	real	name	or	another	name
entirely.
Be	careful	if	you	go	with	the	former	option.	You	might	not	want	to	list	a
middle	name—or,	if	you	always	go	by	your	middle	name,	you	might	not	want
to	list	your	first	name.	Even	something	innocent	like	JohnQDoe@xyz.com	just
tipped	us	off	that	you	have	a	middle	name	and	that	it	begins	with	
Q
.	This	is	an
example	of	giving	out	personal	information	when	it	isn’t	necessary.	Remember
that	you	are	trying	to	blend	into	the	background,	not	call	attention	to	yourself.
If	you	use	a	word	or	phrase	unrelated	to	your	name,	make	it	as	unrevealing
as	possible.	If	your	e-mail	address	is	snowboarder@xyz.com,	we	may	not
know	your	name,	but	we	do	know	one	of	your	hobbies.	Better	to	choose
something	generic,	like	silverfox@xyz.com.
You’ll	of	course	also	want	to	have	a	personal	e-mail	address.	You	should
only	share	this	one	with	close	friends	and	family.	And	the	safest	practices	often
come	with	nice	bonuses:	you’ll	find	that	not	using	your	personal	e-mail
address	for	online	purchasing	will	prevent	you	from	receiving	a	ton	of	spam.
Cell	phones	are	not	immune	from	corporate	tracking.	In	the	summer	of	2015,
an	eagle-eyed	researcher	caught	AT&T	and	Verizon	appending	additional	code
to	every	Web	page	request	made	through	a	mobile	browser.	This	is	not	the
IMSI—international	mobile	subscriber	identity—I	talked	about	in	
chapter	3
(see	
here
);	rather,	it’s	a	unique	identification	code	sent	with	each	Web	page
request.	The	code,	known	as	a	unique	identifier	header,	or	UIDH,	is	a
temporary	serial	number	that	advertisers	can	use	to	identify	you	on	the	Web.
The	researcher	discovered	what	was	going	on	because	he	configured	his
mobile	phone	to	log	all	web	traffic	(which	not	many	people	do).	Then	he
noticed	the	additional	data	tacked	on	to	Verizon	customers	and,	later,	AT&T

customers.
8
The	problem	with	this	additional	code	is	that	customers	were	not	told	about
it.	For	instance,	those	who	had	downloaded	the	Firefox	mobile	app	and	used
plug-ins	to	increase	their	privacy	were,	if	they	used	AT&T	or	Verizon,
nonetheless	being	tracked	by	the	UIDH	codes.
Thanks	to	these	UIDH	codes,	Verizon	and	AT&T	could	take	the	traffic
associated	with	your	Web	requests	and	either	use	it	to	build	a	profile	of	your
mobile	online	presence	for	future	advertising	or	simply	sell	the	raw	data	to
others.
AT&T	has	suspended	the	operation—for	now.
9
	Verizon	has	made	it	yet
another	option	for	the	end	user	to	configure.
10
	Note:	by	
not
	opting	out,	you
give	Verizon	permission	to	continue.
Even	if	you	turn	off	JavaScript,	a	website	may	still	pass	a	text	file	with	data
called	an	http	cookie	back	to	your	browser.	This	cookie	could	be	stored	for	a
long	time.	The	term	
cookie
	is	short	for	
magic	cookie,
	a	piece	of	text	that	is	sent
from	a	website	and	stored	in	the	user’s	browser	to	keep	track	of	things,	such	as
items	in	a	shopping	cart,	or	even	to	authenticate	a	user.	Cookies	were	first	used
on	the	Web	by	Netscape	and	were	originally	intended	to	help	with	creating
virtual	shopping	carts	and	e-commerce	functions.	Cookies	are	typically	stored
in	the	browser	on	a	traditional	PC	and	have	expiration	dates,	although	these
dates	could	be	decades	in	the	future.
Are	cookies	dangerous?	No—at	least	not	by	themselves.	However,	cookies
would	provide	third	parties	with	information	about	your	account	and	your
specific	preferences,	such	as	your	favorite	cities	on	a	weather	site	or	your
airline	preferences	on	a	travel	site.	The	next	time	your	browser	connects	to	that
site,	if	a	cookie	already	exists,	the	site	will	remember	you	and	perhaps	say
“Hello,	Friend.”	And	if	it	is	an	e-commerce	site,	it	may	also	remember	your
last	few	purchases.
Cookies	do	not	actually	store	this	information	on	your	traditional	PC	or
mobile	device.	Like	cell	phones	that	use	IMSIs	as	proxies,	the	
cookie	contains	a
proxy	for	the	data	that	lives	on	the	back	end	at	the	site.	When	your	browser
loads	a	Web	page	with	a	cookie	attached,	additional	data	is	pulled	from	the	site
that	is	specific	to	you.
Not	only	do	cookies	store	your	personal	site	preferences,	they	also	provide
valuable	tracking	data	for	the	site	they	came	from.	For	example,	if	you	are	a
prospective	customer	of	a	company	and	you	have	previously	entered	your	e-

mail	address	or	other	information	to	access	a	white	paper,	chances	are	there	is
a	cookie	in	your	browser	for	that	company’s	site	that	matches,	on	the	back	end,
information	about	you	in	a	customer	record	management	(CRM)	system—say,
Salesforce	or	HubSpot.	Now	every	time	you	access	that	company’s	site,	you
will	be	identified	through	the	cookie	in	your	browser,	and	that	visit	will	be
recorded	within	the	CRM.
Cookies	are	segmented,	meaning	that	website	A	can’t	necessarily	see	the
contents	of	a	cookie	for	website	B.	There	have	been	exceptions,	but	generally
the	information	is	separate	and	reasonably	secure.	From	a	privacy	perspective,
however,	cookies	do	not	make	you	very	invisible.
You	can	only	access	cookies	in	the	same	domain,	a	set	of	resources
assigned	to	a	specific	group	of	people.	Ad	agencies	get	around	this	by	loading
a	cookie	that	can	track	your	activity	on	several	sites	that	are	part	of	their	larger
networks.	In	general,	though,	cookies	cannot	access	another	site’s	cookies.
Modern	browsers	provide	a	way	for	the	user	to	control	cookies.	For	example,
if	you	surf	the	Web	using	incognito	or	private	browsing	features,	you	will	not
retain	a	historical	record	within	the	browser	of	your	visit	to	a	given	site,	nor
will	you	acquire	a	new	cookie	for	that	session.	If	you	had	a	cookie	from	an
earlier	visit,	however,	it	will	still	apply	in	private	mode.	If	you	are	using	the
normal	browsing	feature,	on	the	other	hand,	you	may	from	time	to	time	want
to	manually	remove	some	or	all	of	the	cookies	you	acquired	over	the	years.
I	should	note	that	removing	all	cookies	may	not	be	advisable.	
Selectively
removing	the	cookies	that	are	associated	with	one-off	visits	to	sites	you	don’t
care	about	will	help	remove	traces	of	you	from	the	Internet.	Sites	you	revisit
won’t	be	able	to	see	you,	for	example.	But	for	some	sites,	such	as	a	weather
site,	it	might	be	tedious	to	keep	typing	in	your	zip	code	every	time	you	visit
when	a	simple	cookie	might	suffice.
Removing	cookies	can	be	accomplished	by	using	an	add-on	or	by	going
into	the	settings	or	preferences	section	of	your	browser,	where	there	is	usually
an	option	to	delete	one	or	more	(even	all)	of	the	cookies.	You	may	want	to
determine	the	fate	of	your	cookies	on	a	case-by-case	basis.
Some	advertisers	use	cookies	to	track	how	long	you	spend	on	the	sites
where	they’ve	placed	their	ads.	Some	even	record	your	visits	to	previous	sites,
what’s	known	as	the	referrer	site.	You	should	delete	these	cookies	immediately.
You	will	recognize	some	of	them	because	their	names	won’t	contain	the	names
of	the	sites	you	visited.	For	example,	instead	of	“CNN,”	a	referrer	cookie	will
identify	itself	as	“Ad321.”	You	may	also	want	to	consider	using	a	cookie

cleaner	software	tool,	such	as	the	one	at	piriform.com/ccleaner,	to	help
manage	your	cookies	easily.
There	are,	however,	some	cookies	that	are	impervious	to	whatever
decisions	you	make	on	the	browser	side.	These	are	called	super	cookies
because	they	exist	on	your	computer,	outside	of	your	browser.	Super	cookies
access	a	site’s	preferences	and	tracking	data	no	matter	what	browser	you	use
(Chrome	today,	Firefox	tomorrow).	And	you	should	delete	super	cookies	from
your	browser,	otherwise	your	traditional	PC	will	attempt	to	re-create	http
cookies	from	memory	the	next	time	your	browser	accesses	the	site.
There	are	two	specific	super	cookies	that	live	outside	your	browser	that
you	can	delete—Flash,	from	Adobe,	and	Silverlight,	from	Microsoft.	Neither
of	these	super	cookies	expires.	And	it	is	generally	safe	to	delete	them.
11
Then	there’s	the	toughest	cookie	of	them	all.	Samy	Kamkar,	once	
famous
for	creating	the	rapidly	spreading	Myspace	worm	called	Samy,	has	created
something	he	calls	Evercookie,	which	is	simply	a	very,	very	persistent
cookie.
12
	Kamkar	achieved	this	persistence	by	storing	the	cookie	data	in	as
many	browser	storage	systems	as	possible	throughout	the	Windows	operating
system.	As	long	as	one	of	the	storage	sites	remains	intact,	Evercookie	will
attempt	to	restore	the	cookie	everywhere	else.
13
	Thus	simply	deleting	an
Evercookie	from	the	browser’s	cookie	storage	cache	is	not	enough.	Like	the
kids’	game	whack-a-mole,	Evercookies	will	keep	popping	up.	You	will	need	to
delete	them	completely	from	your	machine	in	order	to	win.
If	you	consider	how	many	cookies	you	might	already	have	on	your
browser,	and	if	you	multiply	that	by	the	number	of	potential	storage	areas	on
your	machine,	you	can	see	that	you’ll	be	in	for	a	long	afternoon	and	evening.
It’s	not	just	websites	and	mobile	carriers	that	want	to	track	your	activities
online.	Facebook	has	become	ubiquitous—a	platform	beyond	just	social
media.	You	can	sign	in	to	Facebook	and	then	use	that	same	Facebook	log-in	to
sign	in	to	various	other	apps.
How	popular	is	this	practice?	At	least	one	marketing	report	finds	that	88
percent	of	US	consumers	have	logged	in	to	a	website	or	mobile	application
using	an	existing	digital	identity	from	a	social	network	such	as	Facebook,
Twitter,	and	Google	Plus.
14
There	are	pros	and	cons	to	this	convenience—known	as	OAuth,	an
authentication	protocol	that	allows	a	site	to	trust	you	even	if	you	don’t	enter	a

password.	On	the	one	hand,	it’s	a	shortcut:	you	can	quickly	access	new	sites
using	your	existing	social	media	password.	On	the	other	hand,	this	allows	the
social	media	site	to	glean	information	about	you	for	its	marketing	profiles.
Instead	of	just	knowing	about	your	visit	to	a	single	site,	it	knows	about	all	the
sites,	all	the	brands	you	use	its	log-in	information	for.	When	we	use	OAuth,
we’re	giving	up	a	lot	of	privacy	for	the	sake	of	convenience.
Facebook	is	perhaps	the	most	“sticky”	of	all	social	media	platforms.
Logging	out	of	Facebook	may	deauthorize	your	browser	from	accessing
Facebook	and	its	Web	applications.	Furthermore,	Facebook	adds	trackers	for
monitoring	user	activity	that	function	even	after	you’re	logged	out,	requesting
information	such	as	your	geographic	location,	which	sites	you	visit,	what	you
click	on	within	individual	sites,	and	your	Facebook	username.	Privacy	groups
have	expressed	concern	about	Facebook’s	intent	to	start	tracking	information
from	some	of	the	websites	and	apps	its	users	are	visiting	in	order	to	display
more	personalized	ads.
The	point	is	that	Facebook,	like	Google,	wants	data	about	you.	It	may	not
come	right	out	and	ask,	but	it	will	find	ways	to	get	it.	If	you	link	your	Facebook
account	to	other	services,	the	platform	will	have	information	about	you	
and
that	other	service	or	app.	Maybe	you	use	Facebook	to	access	your	bank	account
—if	you	do,	it	knows	what	financial	institution	you	use.	Using	just	one
authentication	means	that	if	someone	gets	into	your	Facebook	account,	that
person	will	have	access	to	every	other	website	linked	to	that	account—even
your	bank	account.	In	the	security	business,	having	what	we	call	a	single	point
of	failure	is	never	a	good	idea.	Although	it	takes	a	few	seconds	more,	it’s
worth	signing	in	to	Facebook	only	when	you	need	to	and	signing	in	to	each
app	you	use	separately.
In	addition,	Facebook	has	deliberately	chosen	not	to	honor	the	“do	not
track”	signal	sent	by	Internet	Explorer	on	the	grounds	that	there’s	“no	industry
consensus”	behind	it.
15
	The	Facebook	trackers	come	in	the	classic	forms:
cookies,	JavaScript,	one-pixel	images,	and	iframes.	This	allows	targeted
advertisers	to	scan	and	access	specific	browser	cookies	and	trackers	to	deliver
products,	services,	and	ads,	both	on	and	off	Facebook.
Fortunately	there	are	browser	extensions	that	block	Facebook	services	on
third-party	sites,	e.g.,	Facebook	Disconnect	for	Chrome
16
	and	Facebook
Privacy	List	for	Adblock	Plus	(which	works	with	both	
Firefox	and	Chrome).
17
Ultimately	the	goal	of	all	of	these	plug-in	tools	is	to	give	you	control	over
what	you	share	with	Facebook	and	any	other	social	networks	as	opposed	to

forcing	you	to	take	a	backseat	and	allowing	the	service	you’re	using	to	govern
these	things	for	you.
Given	what	Facebook	knows	about	its	1.65	billion	subscribers,	the	company
has	been	fairly	benevolent—so	far.
18
	It	has	a	ton	of	data,	but	it,	like	Google,
has	chosen	not	to	act	on	all	of	it.	But	that	doesn’t	mean	it	won’t.
More	overt	than	cookies—and	equally	parasitic—are	toolbars.	The	additional
toolbar	you	see	at	the	top	of	your	traditional	PC	browser	might	be	labeled
YAHOO
	or	
MCAFEE
	or	
ASK
.	Or	it	may	carry	the	name	of	any	number	of	other
companies.	Chances	are	you	don’t	remember	how	the	toolbar	got	there.	Nor	do
you	ever	use	it.	Nor	do	you	know	how	to	remove	it.
Toolbars	like	this	draw	your	attention	away	from	the	toolbar	that	came	with
your	browser.	The	native	toolbar	allows	you	to	choose	which	search	engine	to
use	as	the	default.	The	parasitic	one	will	take	you	to	its	own	search	site,	and	the
results	may	be	filled	with	sponsored	content.	This	happened	to	Gary	More,	a
West	Hollywood	resident,	who	found	himself	with	the	Ask.com	toolbar	and	no
clear	way	to	remove	it.	“It’s	like	a	bad	houseguest,”	said	More.	“It	will	not
leave.”
19
If	you	have	a	second	or	third	toolbar,	it	may	be	because	you’ve	downloaded
new	software	or	had	to	update	existing	software.	For	example,	if	you	have	Java
installed	on	your	computer,	Oracle,	the	maker	of	Java,	will	automatically
include	a	toolbar	unless	you	specifically	tell	it	not	to.	When	you	were	clicking
through	the	download	or	update	screens,	you	probably	didn’t	notice	the	tiny
check	box	that	by	default	indicated	your	consent	to	the	installation	of	a	toolbar.
There’s	nothing	illegal	about	this;	you	did	give	consent,	even	if	it	means	that
you	didn’t	opt	out	of	having	it	install	automatically.	But	
that	toolbar	allows
another	company	to	track	your	Web	habits	and	perhaps	change	your	default
search	engine	to	its	own	service	as	well.
The	best	way	to	remove	a	toolbar	is	to	uninstall	it	the	way	you	would
uninstall	any	program	on	your	traditional	PC.	But	some	of	the	most	persistent
and	parasitic	toolbars	may	require	you	to	download	a	removal	tool,	and	often
the	process	of	uninstalling	can	leave	behind	enough	information	to	allow
advertising	agents	related	to	the	toolbar	to	reinstall	it.
When	installing	new	software	or	updating	existing	software,	pay	attention
to	all	the	check	boxes.	You	can	avoid	a	lot	of	hassle	if	you	don’t	agree	to	the
installation	of	these	toolbars	in	the	first	place.

What	if	you	do	use	private	browsing,	have	NoScript,	HTTPS	Everywhere,	and
you	periodically	delete	your	browser’s	cookies	and	extraneous	toolbars?	You
should	be	safe,	right?	Nope.	You	can	
still
	be	tracked	online.
Websites	are	coded	using	something	called	Hypertext	Markup	Language,	or
HTML.	There	are	many	new	features	available	in	the	current	version,	HTML5.
Some	of	the	features	have	hastened	the	demise	of	the	super	cookies	Silverlight
and	Flash—which	is	a	good	thing.	HTML5	has,	however,	enabled	new	tracking
technologies,	perhaps	by	accident.
One	of	these	is	canvas	fingerprinting,	an	online	tracking	tool	that	is	cool	in
a	very	creepy	way.	Canvas	fingerprinting	uses	the	HTML5	canvas	element	to
draw	a	simple	image.	That’s	it.	The	drawing	of	the	image	takes	place	within	the
browser	and	is	not	visible	to	you.	It	takes	only	a	fraction	of	a	second.	But	the
result	is	visible	to	the	requesting	website.
The	idea	is	that	your	hardware	and	software,	when	combined	as	resources
for	the	browser,	will	render	the	image	uniquely.	The	image—it	could	be	a
series	of	variously	colored	shapes—is	then	converted	into	a	unique	number,
roughly	the	way	passwords	are.	
This	number	is	then	matched	to	previous
instances	of	that	number	seen	on	other	websites	around	the	Internet.	And	from
that—the	number	of	places	where	that	unique	number	is	seen—a	profile	of
websites	you	visit	can	be	built	up.	This	number,	or	canvas	fingerprint,	can	be
used	to	identify	your	browser	whenever	it	returns	to	any	particular	website	that
requested	it,	even	if	you	have	removed	all	cookies	or	blocked	future	cookies
from	installing,	because	it	uses	an	element	built	into	HTML5	itself.
20
Canvas	fingerprinting	is	a	drive-by	process;	it	does	not	require	you	to	click
or	do	anything	but	simply	view	a	Web	page.	Fortunately	there	are	plug-ins	for
your	browser	that	can	block	it.	For	Firefox	there’s	CanvasBlocker.
21
	For
Google	Chrome	there’s	CanvasFingerprintBlock.
22
	Even	the	Tor	project	has
added	its	own	anticanvas	technology	to	its	browser.
23
If	you	use	these	plug-ins	and	follow	all	my	other	recommendations,	you
might	think	that	you’re	finally	free	of	online	tracking.	And	you’d	be	wrong.
Firms	such	as	Drawbridge	and	Tapad,	and	Oracle’s	Crosswise,	take	online
tracking	a	step	further.	They	claim	to	have	technologies	that	can	track	your
interests	across	multiple	devices,	including	sites	you	visit	only	on	your	cell
phones	and	tablets.
Some	of	this	tracking	is	the	result	of	machine	learning	and	fuzzy	logic.	For
example,	if	a	mobile	device	and	a	traditional	PC	both	contact	a	site	using	the
same	IP	address,	it’s	very	possible	that	they	are	owned	by	a	single	person.	For

example,	say	you	search	for	a	particular	item	of	clothing	on	your	cell	phone,
then	when	you	get	home	and	are	on	your	traditional	PC,	you	find	that	same
item	of	clothing	in	the	“recently	viewed”	section	of	the	retailer’s	website.
Better	yet,	let’s	say	you	buy	the	item	of	clothing	using	your	traditional	PC.	The
more	matches	created	between	distinct	devices,	the	more	likely	it	is	that	a
single	individual	is	using	both	of	them.	Drawbridge	alone	claims	it	linked	1.2
billion	users	across	3.6	billion	devices	in	2015.
24
Google,	of	course,	does	the	same	thing,	as	do	Apple	and	Microsoft.
Android	phones	require	the	use	of	a	Google	account.	Apple	devices	use	an
Apple	ID.	Whether	a	user	has	a	smartphone	or	a	laptop,	the	Web	traffic
generated	by	each	is	associated	with	a	specific	user.	And	the	latest	Microsoft
operating	systems	require	a	Microsoft	account	in	order	to	download	apps	or	to
store	photos	and	documents	using	the	company’s	cloud	service.
The	big	difference	is	that	Google,	Apple,	and	Microsoft	allow	you	to
disable	some	or	all	of	this	data	collection	activity	and	retroactively	delete
collected	data.	Drawbridge,	Crosswise,	and	Tapad	make	the	process	of
disabling	and	deletion	less	clear.	Or	it	may	simply	not	be	available.
Although	using	a	proxy	service	or	Tor	is	a	convenient	way	to	obscure	your
true	location	when	accessing	the	Internet,	this	masking	can	create	interesting
problems	or	even	backfire	on	you,	because	sometimes	online	tracking	can	be
justified—especially	when	a	credit	card	company	is	trying	to	fight	fraud.	For
example,	just	days	before	Edward	Snowden	went	public,	he	wanted	to	create	a
website	to	support	online	rights.	He	had	trouble,	however,	paying	the	host
company	for	the	registration	with	his	credit	card.
At	the	time,	he	was	still	using	his	real	name,	real	e-mail	address,	and
personal	credit	cards—this	was	just	before	he	became	a	whistle-blower.	He	was
also	using	Tor,	which	sometimes	triggers	fraud	warnings	from	credit	card
companies	when	they	want	to	verify	your	identity	and	can’t	reconcile	some	of
the	information	you	provided	with	what	they	have	on	file.	If,	say,	your	credit
card	account	says	you	live	in	New	York,	why	does	your	Tor	exit	node	say	you
are	in	Germany?	A	geolocation	discrepancy	like	this	often	flags	an	attempt	to
purchase	as	possible	abuse	and	invites	additional	scrutiny.
Credit	card	companies	certainly	track	us	online.	They	know	all	our
purchases.	They	know	where	we	have	subscriptions.	They	know	
when	we	leave
the	country.	And	they	know	whenever	we	use	a	new	machine	to	make	a
purchase	online.

According	to	Micah	Lee	of	the	EFF,	at	one	point	Snowden	was	in	his	Hong
Kong	hotel	room	discussing	government	secrets	with	Laura	Poitras	and	Glenn
Greenwald,	a	reporter	from	the	
Guardian,
	and	at	the	same	time	he	was	on	hold
with	the	customer	support	department	at	DreamHost,	an	Internet	provider	based
in	Los	Angeles.	Apparently	Snowden	explained	to	DreamHost	that	he	was
overseas	and	didn’t	trust	the	local	Internet	service,	hence	his	use	of	Tor.
Ultimately	DreamHost	accepted	his	credit	card	over	Tor.
25
One	way	to	avoid	this	hassle	with	Tor	is	to	configure	the	torrec	config	file
to	use	exit	nodes	located	in	your	home	country.	That	should	keep	the	credit
card	companies	happy.	On	the	other	hand,	constantly	using	the	same	exit	nodes
might	ultimately	reveal	who	you	are.	There	is	some	serious	speculation	that
government	agencies	might	control	some	exit	nodes,	so	using	different	ones
makes	sense.
Another	way	to	pay	without	leaving	a	trace	is	to	use	Bitcoin,	a	virtual
currency.	Like	most	currencies,	it	fluctuates	in	value	based	on	the	confidence
people	have	in	it.
Bitcoin	is	an	algorithm	that	allows	people	to	create—or,	in	Bitcoin
terminology,	mine—their	own	currency.	But	if	it	were	easy,	everyone	would
do	it.	So	it’s	not.	The	process	is	computationally	intensive,	and	it	takes	a	long
while	just	to	create	one	Bitcoin.	Thus	there	is	a	finite	amount	of	Bitcoin	in
existence	on	any	given	day,	and	that,	in	addition	to	consumer	confidence,
influences	its	value.
Each	Bitcoin	has	a	cryptographic	signature	that	identifies	it	as	original	and
unique.	Transactions	made	with	that	cryptographic	signature	can	be	traced	back
to	the	coin,	but	the	method	by	which	you	obtain	the	coin	can	be	obscured—for
example,	by	setting	up	a	rock-solid	anonymous	e-mail	address	and	using	that
e-mail	address	to	set	up	an	anonymous	Bitcoin	wallet	using	the	Tor	network.
You	buy	Bitcoin	in	person,	or	anonymously	online	using	prepaid	
gift	cards,
or	find	a	Bitcoin	ATM	without	camera	surveillance.	Depending	on	what
surveillance	factors	could	potentially	reveal	your	true	identity,	every	risk
needs	to	be	taken	into	account	when	choosing	which	purchasing	method	to	use.
You	can	then	put	these	Bitcoins	into	what’s	known	as	a	tumbler.	A	tumbler	takes
some	Bitcoins	from	me,	some	from	you,	and	some	from	other	people	chosen
at	random	and	mixes	them	together.	You	keep	the	value	of	the	coins	minus	the
tumbling	fee—it’s	just	that	the	cryptographic	signature	of	each	coin	may	be
different	after	it’s	mixed	with	others.	That	anonymizes	the	system	somewhat.
Once	you	have	them,	how	do	you	store	Bitcoins?	Because	there	are	no

Bitcoin	banks,	and	because	Bitcoin	is	not	physical	currency,	you	will	need	to
use	a	Bitcoin	wallet	set	up	anonymously	using	the	detailed	instructions
described	later	in	this	book.
Now	that	you’ve	bought	and	stored	it,	how	do	you	use	Bitcoin?	Exchanges
allow	you	to	invest	in	Bitcoin	and	change	it	into	other	currencies,	such	as	US
dollars,	or	purchase	goods	on	sites	such	as	Amazon.	Say	you	have	one	Bitcoin,
valued	at	$618.	If	you	only	need	around	$80	for	a	purchase,	then	you	will
retain	a	certain	percentage	of	the	original	value,	depending	on	the	exchange
rate,	after	the	transaction.
Transactions	are	verified	in	a	public	ledger	known	as	a	blockchain	and
identified	by	IP	address.	But	as	we	have	seen,	IP	addresses	can	be	changed	or
faked.	And	although	merchants	have	started	accepting	Bitcoin,	the	service	fees,
typically	paid	by	the	merchant,	have	been	transferred	to	the	purchaser.
Furthermore,	unlike	credit	cards,	Bitcoin	permits	no	refunds	or
reimbursements.
You	can	accumulate	as	much	Bitcoin	as	you	would	hard	currency.	But
despite	its	overall	success	(the	Winklevoss	brothers,	famous	for	challenging
Mark	Zuckerberg	over	the	founding	of	Facebook,	are	major	investors	in
Bitcoin),	the	system	has	had	some	monumental	failures	as	well.	In	2004,	Mt.
Gox,	a	Tokyo-based	Bitcoin	exchange,	declared	bankruptcy	after	announcing
that	its	Bitcoin	had	been	stolen.	There	have	
been	other	reports	of	theft	among
Bitcoin	exchanges,	which,	unlike	most	US	bank	accounts,	are	not	insured.
Still,	although	there	have	been	various	attempts	at	virtual	currency	in	the
past,	Bitcoin	has	become	the	Internet’s	standard	anonymous	currency.	A	work
in	progress,	yes,	but	an	option	for	anyone	looking	for	privacy.
You	might	feel	invisible	right	now—obscuring	your	IP	address	with	Tor;
encrypting	your	e-mail	and	text	messages	with	PGP	and	Signal.	I	haven’t,
however,	talked	much	about	hardware—which	can	be	used	to	both	find	you	and
hide	you	on	the	Internet.

CHAPTER	SEVEN
Pay	Up	or	Else!
The	nightmare	began	online	and
	ended	with	federal	agents
storming	a	house	in	suburban	Blaine,	Minnesota.	The	agents	had	only	an	IP
address	associated	with	child	pornography	downloads	and	even	a	death	threat
against	Vice	President	Joe	Biden.	By	contacting	the	Internet	service	provider
associated	with	that	IP	address,	the	agents	acquired	the	user’s	physical	address.
That	sort	of	tracking	was	very	successful	back	in	the	days	when	everyone	still
had	a	wired	connection	to	their	modems	or	routers.	At	that	time,	each	IP
address	could	be	physically	traced	to	a	given	machine.
But	today	most	people	use	wireless	connections	within	their	homes.
Wireless	allows	everyone	inside	to	move	around	the	house	with	mobile
devices	and	remain	connected	to	the	Internet.	And	if	you’re	not	careful,	it	also
allows	neighbors	to	access	that	same	signal.	In	this	case	the	federal	agents
stormed	the	wrong	house	in	Minnesota.	They	really	wanted	the	house	next
door	to	it.
In	2010,	Barry	Vincent	Ardolf	pleaded	guilty	to	charges	of	hacking,
identity	theft,	possession	of	child	pornography,	and	making	threats	against
Vice	President	Biden.	Court	records	show	that	the	trouble	between	Ardolf	and
his	neighbor	began	when	the	neighbor,	
who	was	in	fact	a	lawyer	and	was	not
named,	filed	a	police	report	saying	that	Ardolf	allegedly	“inappropriately
touched	and	kissed”	the	lawyer’s	toddler	on	the	mouth.
1
Ardolf	then	used	the	IP	address	of	his	neighbor’s	wireless	home	router	to

open	Yahoo	and	Myspace	accounts	in	his	victim’s	name.	It	was	from	these	fake
accounts	that	Ardolf	launched	a	campaign	to	embarrass	and	cause	legal
troubles	for	the	lawyer.
Many	ISPs	now	provide	their	home	routers	with	wireless	capabilities	built
in.
2
	Some	ISPs,	such	as	Comcast,	are	creating	a	second	open	Wi-Fi	service
over	which	you	have	limited	control.	For	example,	you	may	be	able	to	change
a	few	settings,	such	as	the	ability	to	turn	it	off.	You	should	be	aware	of	it.
Someone	in	a	van	parked	in	front	of	your	house	might	be	using	your	free
wireless.	Although	you	don’t	have	to	pay	extra	for	that,	you	might	still	notice	a
slight	degradation	in	Wi-Fi	speed	if	there	is	heavy	use	of	the	second	signal.
You	can	disable	Comcast’s	Xfinity	Home	Hotspot	if	you	don’t	think	you	will
ever	need	to	give	visitors	to	your	home	free	Internet	access.
3
While	built-in	wireless	is	great	for	getting	you	up	and	running	with	a	new
service,	often	these	broadband	routers	are	not	configured	properly	and	can
create	problems	when	they	are	not	secured.	For	one	thing,	unsecured	wireless
access	could	provide	a	digital	point	of	entry	into	your	home,	as	it	did	for
Ardolf.	While	intruders	might	not	be	after	your	digital	files,	they	might	be
looking	to	cause	problems	nonetheless.
Ardolf	was	no	computer	genius.	He	confessed	in	court	that	he	didn’t	know
the	difference	between	WEP	(wired	equivalent	privacy)	encryption,	which	was
what	the	neighbor’s	router	used,	and	WPA	(Wi-Fi	protected	access)	encryption,
which	is	much	more	secure.	He	was	just	angry.	This	is	just	one	more	reason
why	you	should	take	a	moment	to	consider	the	security	of	your	own	household
wireless	network.	You	never	know	when	an	angry	neighbor	might	try	to	use
your	home	network	against	you.
If	someone	does	do	something	bad	on	your	home	network,	there	
is	some
protection	for	the	router	owner.	According	to	the	EFF,	federal	judges	have
rejected	BitTorrent	lawsuits	brought	by	copyright	holders	because	the
defendants	successfully	claimed	that	someone	else	downloaded	the	movies
using	their	wireless	networks.
4
	The	EFF	states	that	an	IP	address	is	not	a
person,	meaning	that	wireless	subscribers	may	not	be	responsible	for	the
actions	of	others	using	their	wireless	networks.
5
Although	computer	forensics	will	clear	an	innocent	person	whose	Wi-Fi
was	used	in	the	commission	of	a	felony—as	it	did	in	the	case	of	the	Minnesota
lawyer—why	go	through	all	that?

Even	if	you	use	a	telephone-based	dial-up	modem	or	a	cable-based	ASM	(any-
source	multicast)	router	(available	from	Cisco	and	Belkin,	among	others),
these	devices	have	had	their	share	of	software	and	configuration	problems.
First	and	foremost,	download	the	latest	firmware	(software	installed	in	a
hardware	device).	You	can	do	that	by	accessing	the	router’s	configuration
screen	(see	below)	or	by	visiting	the	manufacturer’s	website	and	searching	for
updates	for	your	particular	make	and	model.	Do	this	as	often	as	possible.	One
easy	way	to	update	your	router’s	firmware	is	to	buy	a	new	one	every	year.	This
can	get	expensive,	but	it	will	ensure	that	you	have	the	latest	and	greatest
firmware.	Second,	update	your	router’s	configuration	settings.	You	don’t	want
the	default	settings.
But	first:	what’s	in	a	name?	More	than	you	think.	Common	to	both	the	ISP-
provided	router	and	a	router	you	bought	at	Best	Buy	is	the	naming.	All
wireless	routers	broadcast	by	default	what’s	called	a	service	set	identifier
(SSID).
6
	The	SSID	is	commonly	the	name	and	model	of	your	router,	e.g.,
“Linksys	WRT54GL.”	If	you	look	at	the	available	wireless	connections	in	your
area,	you’ll	see	what	I	mean.
Broadcasting	the	default	SSID	out	to	the	world	may	mask	the	fact	that	the
Wi-Fi	signal	is	actually	coming	from	a	specific	household,	
but	it	also	allows
someone	on	the	street	to	know	the	exact	make	and	model	of	the	router	you
own.	Why	is	that	bad?	That	person	might	also	know	the	vulnerabilities	of	that
make	and	model	and	be	able	to	exploit	them.
So	how	do	you	change	the	name	of	the	router	and	update	its	firmware?
Accessing	the	router	is	easy;	you	do	so	from	your	Internet	browser.	If	you
don’t	have	the	instructions	for	your	router,	there’s	an	online	list	of	URLs	that
tells	you	what	to	type	into	your	browser	window	so	you	can	connect	directly	to
the	router	on	your	home	network.
7
	After	typing	in	the	local	URL	(you’re	just
talking	to	the	router,	remember,	not	to	the	Internet	at	large),	you	should	see	a
log-in	screen.	So	what’s	the	username	and	password	for	the	log-in?
Turns	out	there’s	a	list	of	default	log-ins	published	on	the	Internet	as	well.
8
In	the	Linksys	example	above,	the	username	is	blank	and	the	password	is
“admin.”	Needless	to	say,	once	you’re	inside	the	router’s	configuration	screen,
you	should	immediately	change	its	default	password,	following	the	advice	I
gave	you	earlier	about	creating	unique	and	strong	passwords	(see	
here
)	or
using	a	password	manager.
Remember	to	store	this	password	in	your	password	manager	or	write	it
down,	as	you	probably	won’t	need	to	access	your	router	very	often.	Should

you	forget	the	password	(really,	how	often	are	you	going	to	be	in	the
configuration	screen	for	your	router?),	don’t	worry.	There	is	a	physical	reset
button	that	will	restore	the	default	settings.	However,	in	conducting	a	physical,
or	hard,	reset,	you	will	also	have	to	reenter	all	the	configuration	settings	I’m
about	to	explain	below.	So	write	down	the	router	settings	or	take	screenshots
and	print	them	out	whenever	you	establish	router	settings	that	are	different
from	the	default.	These	screenshots	will	be	valuable	when	you	need	to
reconfigure	your	router.
I	suggest	you	change	“Linksys	WRT54GL”	to	something	innocuous,	such
as	“HP	Inkjet,”	so	it	won’t	be	obvious	to	strangers	which	
house	the	Wi-Fi
signal	might	be	coming	from.	I	often	use	a	generic	name,	such	as	the	name	of
my	apartment	complex	or	even	the	name	of	my	neighbor.
There	is	also	an	option	to	hide	your	SSID	entirely.	That	means	others	will
not	be	able	to	easily	see	it	listed	as	a	wireless	network	connection.
While	you’re	inside	your	basic	router	configuration	settings,	there	are	several
types	of	wireless	security	to	consider.	These	are	generally	not	enabled	by
default.	And	not	all	wireless	encryption	is	created	equal,	nor	is	it	supported	by
all	devices.
The	most	basic	form	of	wireless	encryption,	wired	equivalent	privacy
(WEP),	is	useless.	If	you	see	it	as	an	option,	don’t	even	consider	it.	WEP	has
been	cracked	for	years,	and	is	therefore	no	longer	recommended.	Only	old
routers	and	devices	still	offer	it	as	a	legacy	option.	Instead,	choose	one	of	the
newer,	stronger	encryption	standards,	such	as	Wi-Fi	protected	access,	or	WPA.
WPA2	is	even	more	secure.
Turning	on	encryption	at	the	router	means	that	the	devices	connecting	to	it
will	also	need	to	match	encryption	settings.	Most	new	devices	automatically
sense	the	type	of	encryption	being	used,	but	older	models	still	require	you	to
indicate	manually	which	encryption	level	you	are	using.	Always	use	the	highest
level	possible.	You’re	only	as	secure	as	your	weakest	link,	so	make	sure	to
max	out	the	oldest	device	in	terms	of	its	available	encryption.
Enabling	WPA2	means	that	when	you	connect	your	laptop	or	mobile
device,	you	will	also	need	to	set	it	to	WPA2,	although	some	new	operating
systems	will	recognize	the	type	of	encryption	automatically.	Modern	operating
systems	on	your	phone	or	laptop	will	identify	the	Wi-Fi	available	in	your	area.
Your	SSID	broadcast	(now	“HP	Inkjet”)	should	appear	on	the	list	at	or	close	to
the	top.	Padlock	icons	within	the	list	of	available	Wi-Fi	connections	(usually


[Note: PDF has 259 pages, only first 100 pages extracted]